<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12&nbsp; Causal Modeling – Models Demystified</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./data.html" rel="next">
<link href="./ml_more.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-3a01e2046221230fdceeea94b1ec5d67.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-74e8c4dbc3b38357afd5009b93c858b0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="12&nbsp; Causal Modeling – Models Demystified">
<meta property="og:description" content="">
<meta property="og:site_name" content="Models Demystified">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-causal" class="quarto-section-identifier"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Causal Modeling</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Models Demystified</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/m-clark/book-of-models" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Thinking About Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Foundation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Understanding the Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding_features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Understanding the Features</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model Estimation and Optimization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generalized_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_model_extensions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extending the Linear Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Core Concepts in Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_common_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Common Models in Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_more.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">More Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./causal.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Causal Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Dealing with Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./danger_zone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Danger Zone</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Until Next Time…</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Additional Topics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Acknowledgments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_operations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Matrix Operations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./more_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">More Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">References &amp; Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataset_descriptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Dataset Descriptions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-causal-key-ideas" id="toc-sec-causal-key-ideas" class="nav-link active" data-scroll-target="#sec-causal-key-ideas"><span class="header-section-number">12.1</span> Key Ideas</a>
  <ul class="collapse">
  <li><a href="#sec-causal-why" id="toc-sec-causal-why" class="nav-link" data-scroll-target="#sec-causal-why"><span class="header-section-number">12.1.1</span> Why it matters</a></li>
  <li><a href="#sec-causal-good-to-know" id="toc-sec-causal-good-to-know" class="nav-link" data-scroll-target="#sec-causal-good-to-know"><span class="header-section-number">12.1.2</span> Helpful context</a></li>
  </ul></li>
  <li><a href="#sec-causal-prediction-explanation" id="toc-sec-causal-prediction-explanation" class="nav-link" data-scroll-target="#sec-causal-prediction-explanation"><span class="header-section-number">12.2</span> Prediction and Explanation Revisited</a></li>
  <li><a href="#sec-causal-classic" id="toc-sec-causal-classic" class="nav-link" data-scroll-target="#sec-causal-classic"><span class="header-section-number">12.3</span> Classic Experimental Design</a>
  <ul class="collapse">
  <li><a href="#sec-causal-experiments" id="toc-sec-causal-experiments" class="nav-link" data-scroll-target="#sec-causal-experiments"><span class="header-section-number">12.3.1</span> Analysis of Experiments</a></li>
  </ul></li>
  <li><a href="#sec-causal-natural" id="toc-sec-causal-natural" class="nav-link" data-scroll-target="#sec-causal-natural"><span class="header-section-number">12.4</span> Natural Experiments</a></li>
  <li><a href="#sec-causal-inference" id="toc-sec-causal-inference" class="nav-link" data-scroll-target="#sec-causal-inference"><span class="header-section-number">12.5</span> Causal Inference</a>
  <ul class="collapse">
  <li><a href="#sec-causal-assumptions" id="toc-sec-causal-assumptions" class="nav-link" data-scroll-target="#sec-causal-assumptions"><span class="header-section-number">12.5.1</span> Key assumptions of causal inference</a></li>
  </ul></li>
  <li><a href="#sec-causal-models" id="toc-sec-causal-models" class="nav-link" data-scroll-target="#sec-causal-models"><span class="header-section-number">12.6</span> Models for Causal Inference</a>
  <ul class="collapse">
  <li><a href="#sec-causal-lm" id="toc-sec-causal-lm" class="nav-link" data-scroll-target="#sec-causal-lm"><span class="header-section-number">12.6.1</span> Linear regression</a></li>
  <li><a href="#sec-causal-graphical-sem" id="toc-sec-causal-graphical-sem" class="nav-link" data-scroll-target="#sec-causal-graphical-sem"><span class="header-section-number">12.6.2</span> Graphical models &amp; structural equation models</a></li>
  <li><a href="#sec-causal-counterfactual" id="toc-sec-causal-counterfactual" class="nav-link" data-scroll-target="#sec-causal-counterfactual"><span class="header-section-number">12.6.3</span> Counterfactual thinking</a></li>
  <li><a href="#sec-causal-uplift" id="toc-sec-causal-uplift" class="nav-link" data-scroll-target="#sec-causal-uplift"><span class="header-section-number">12.6.4</span> Uplift modeling</a></li>
  <li><a href="#sec-causal-meta" id="toc-sec-causal-meta" class="nav-link" data-scroll-target="#sec-causal-meta"><span class="header-section-number">12.6.5</span> Meta-Learning</a></li>
  <li><a href="#sec-causal-others" id="toc-sec-causal-others" class="nav-link" data-scroll-target="#sec-causal-others"><span class="header-section-number">12.6.6</span> Others models used for causal inference</a></li>
  </ul></li>
  <li><a href="#causal-wrap" id="toc-causal-wrap" class="nav-link" data-scroll-target="#causal-wrap"><span class="header-section-number">12.7</span> Wrapping Up</a>
  <ul class="collapse">
  <li><a href="#causal-common" id="toc-causal-common" class="nav-link" data-scroll-target="#causal-common"><span class="header-section-number">12.7.1</span> The common thread</a></li>
  <li><a href="#causal-adventure" id="toc-causal-adventure" class="nav-link" data-scroll-target="#causal-adventure"><span class="header-section-number">12.7.2</span> Choose your own adventure</a></li>
  <li><a href="#causal-resources" id="toc-causal-resources" class="nav-link" data-scroll-target="#causal-resources"><span class="header-section-number">12.7.3</span> Additional resources</a></li>
  </ul></li>
  <li><a href="#causal-exercise" id="toc-causal-exercise" class="nav-link" data-scroll-target="#causal-exercise"><span class="header-section-number">12.8</span> Guided Exploration</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/m-clark/book-of-models/edit/dev/causal.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-causal" class="quarto-section-identifier"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Causal Modeling</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><img src="img/chapter_gp_plots/gp_plot_10.svg" class="img-fluid" style="width:75.0%"></p>
<blockquote class="blockquote">
<dl>
<dt>All those causal effects will be lost in time, like tears in rain… without adequate counterfactual considerations.</dt>
<dd>
Roy Batty (paraphrased)
</dd>
</dl>
</blockquote>
<p>Causal inference is a very important topic in machine learning and statistical modeling approaches. It is also a very difficult one to understand well, or consistently, because <em>not everyone agrees on how to define a cause in the first place</em>. Our focus here is merely practical- we just want to discuss some of the modeling approaches commonly used when attempting to answer causal questions. But causal modeling in general is such a deep topic that we won’t be able to go into as much detail as it deserves. However, we will try to give you a sense of the landscape and some of the key ideas.</p>
<section id="sec-causal-key-ideas" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="sec-causal-key-ideas"><span class="header-section-number">12.1</span> Key Ideas</h2>
<ul>
<li>No model can tell you whether a relationship is causal or not. Causality is inferred, not proven, based on the available evidence.</li>
<li>The same models could be used for similar data settings to answer a causal question or a purely predictive question. A key difference is in the interpretation of the results.</li>
<li>Experimental design, such as randomized control trials, are considered the gold standard for causal inference. But the gold standard is often not practical, and not without its limitations even when it is.</li>
<li>Causal inference is often done with observational data, which is often the only option, and that’s okay.</li>
<li>Counterfactual thinking is at the heart of causal inference, but can be useful for all modeling contexts.</li>
<li>Several models exist which are typically employed to answer a more causal-oriented question. These include graphical models, uplift modeling, and more.</li>
<li>Interactions are the norm for most modeling scenarios, while causal inference generally regards a single effect. If an effect varies depending on other features, you should be cautious trying to aggregate your results to a single effect, since that effect would be potentially misleading.</li>
</ul>
<section id="sec-causal-why" class="level3" data-number="12.1.1">
<h3 data-number="12.1.1" class="anchored" data-anchor-id="sec-causal-why"><span class="header-section-number">12.1.1</span> Why it matters</h3>
<p>Often we need a precise statement about the feature-target relationship, not just a declaration that there is ‘some’ relationship. For example, we might want to know how well a drug works and for whom, or show that an advertisement results in a certain amount of new sales. We generally need to know whether the effect is real, and the size of the effect, and often, the uncertainty in that estimate.</p>
<p>Causal modeling is, like machine learning, more of an approach than a specific model, and that approach may involve the design or implementation of models we’ve already seen, but conducted in a different way to answer the key question. Without more precision in our understanding, we could miss the effect, or overstate it, and make bad decisions as a result.</p>
</section>
<section id="sec-causal-good-to-know" class="level3" data-number="12.1.2">
<h3 data-number="12.1.2" class="anchored" data-anchor-id="sec-causal-good-to-know"><span class="header-section-number">12.1.2</span> Helpful context</h3>
<p>This section is pretty high level, and we are not going to go into much detail here, so even just some understanding of correlation and modeling would likely be enough.</p>
</section>
</section>
<section id="sec-causal-prediction-explanation" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="sec-causal-prediction-explanation"><span class="header-section-number">12.2</span> Prediction and Explanation Revisited</h2>
<p>We introduced the idea of prediction and explanation in the context of linear models in <a href="linear_models.html#sec-lm-prediction-vs-explanation" class="quarto-xref"><span>Section 3.4.3</span></a>, and it’s worth revisiting here. One attribute of a causal model is an intense focus on the explanatory power of the model. We want to demonstrate that there is a relationship between (usually) a single feature and the target, and we want to know the precise manner of this relationship as much as possible. Even if we use complex models, the endeavor is to explain the specifics.</p>
<p>Let’s say that we used some particular causal modeling approach to explain a feature-target relationship in a classification setting. We have 10,000 observations, and the baseline rate of the target is about ~50%. We have a model that predicts the target <code>y</code> based on the feature of interest <code>x</code>, and we may have used some causal technique like propensity score weighting or some other approach to help control for confounding (we’ll discuss these later).</p>
<p>The coefficient, though small with an odds ratio of 1.05, is statistically significant (take our word for it), so we have a slight positive relationship. Under certain settings such as this, where we are interested in causal effects and where we have controlled for various other factors to obtain this result, we might be satisfied with interpreting this relationship as is.</p>
<div id="fig-prediction-vs-explanation-demo-plot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-prediction-vs-explanation-demo-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/causal-prediction-vs-explanation-demo-plot.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-prediction-vs-explanation-demo-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.1: Results from a hypothetical causal model
</figcaption>
</figure>
</div>
<p>But if we are interested in predictive performance, we would be disappointed with this model. It predicts the target at about the same rate as guessing, even on the data it’s fit on, and does even worse with new data. Even the effect as shown is quite small by typical standards, as it would take a standard deviation change in the feature to get a ~1% change in the probability of the target (x is standardized).</p>
<p>If we are concerned solely with explanation, we now would want to ask ourselves first if we can trust our result based on the data, model, and various issues that went into producing it. If so, we can then see if the effect is large enough to be of interest, and if the result is useful in making decisions<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. It may very well be, maybe the target concerns the rate of survival, where any increase is worthwhile. Or perhaps the data circumstances demand such interpretation, because it is costly to obtain more. For more exploratory efforts however, this sort of result would likely not be enough to come to any strong conclusion, even if explanation is the only goal.</p>
<p>As another example, consider the world happiness data we’ve used in previous demonstrations. We want to explain the association of country level characteristics and the population’s happiness. We likely aren’t going to be as interested in predicting next year’s happiness score, but rather what attributes are correlated with a happy populace in general. For another example, in the U.S., we might be interested in specific factors related to presidential elections, of which there are relatively very few data points. In these cases, explanation is the focus, and we may not even need a model at all to come to our conclusions.</p>
<p>So we can see that in some settings we may be more interested in understanding the underlying mechanisms of the data, and in others we may be more interested in predictive performance. However, the distinction between prediction and explanation in the end is a bit problematic, not the least of which is that we often want to do both.</p>
<p>Although it’s often implied as such, <em>prediction is not just what we do with new data</em>. It is the very means by which we get any explanation of effects via coefficients, marginal effects, visualizations, and other model results. Additionally, when the focus is on predictive performance, if we can’t explain the results we get, we will typically feel dissatisfied, and may still question how well the model is actually doing.</p>
<p>Here are some ways we might think about different modeling contexts:</p>
<ul>
<li><strong>Descriptive Analysis</strong>: Here we have an exploration of data with no modeling focus. We’ll use descriptive statistics and visualizations to help us understand what’s going on. An end product may be an infographic or a highly visual report. Even here, we might use models to aid visualizations, or otherwise to help us understand the data better, but their specific implementation or result is not of much interest.</li>
<li><strong>Exploratory Modeling</strong>: When using models for exploration, focus should probably be on both prediction and explanation. The former can help inform the strength of the results for future exploration, while the latter will often provide useful insights.</li>
<li><strong>Causal Modeling</strong>: Here the focus is on understanding causal effects. We focus on explanation, and prediction on the current data. We may very well be interested in predictive performance also, and often are in industry.</li>
<li><strong>Generalization</strong>: When our goal is generalizing to unseen data as we have discussed elsewhere, the focus is mostly on predictive performance<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, as we need something to help us predict things in the future. This does not mean we can’t use the model to understand the data though, and explanation could still possibly be as important depending on the context.</li>
</ul>
<p>Depending on the context, we may be more interested explanation or predictive performance, but in practice we often want both. It is crucial to remind yourself why you are interested in the problem, what a model is capable of telling you about it, and to be clear about what you want to get out of the result.</p>
</section>
<section id="sec-causal-classic" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="sec-causal-classic"><span class="header-section-number">12.3</span> Classic Experimental Design</h2>
<div id="fig-random-assignment" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-random-assignment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/causal-random-assignment.svg" class="img-fluid figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-random-assignment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.2: Random Assignment
</figcaption>
</figure>
</div>
<p>Many are familiar with the basic idea of an experiment, where we have a <strong>treatment</strong> group and a <strong>control</strong> group, and we want to measure the difference between the two groups. The ‘treatment’ could regard a new drug, a marketing campaign, or a new app’s feature. If we randomly assign our observational units to the two groups, say, one that gets the new app feature and the other doesn’t, we can be more confident that the two groups are essentially the same aside from the treatment. Furthermore, any difference we see in the outcome, for example, customer satisfaction with the app, is probably due to the treatment.</p>
<p>This is the basic idea behind a <strong>randomized control trial</strong>, or <strong>RCT</strong>. We can randomly assign the groups in a variety of ways, but you can think of it as flipping a coin, and assigning each sample to the treatment when the coin comes up on one side, and to the control when it comes up on the other. The idea is that the only difference between the two groups is the treatment, and so any difference in the outcome can be attributed to the treatment. This is visualized in <a href="#fig-random-assignment" class="quarto-xref">Figure&nbsp;<span>12.2</span></a>, where the color/shapes represent different groups that are the same. Their distribution is roughly similar after assignment to the treatment groups, and would become more so with more data.</p>
<section id="sec-causal-experiments" class="level3" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="sec-causal-experiments"><span class="header-section-number">12.3.1</span> Analysis of Experiments</h3>
<p>Many of those who have taken a statistics course have been exposed to the simple <strong>t-test</strong> to determine whether two groups are different. For many this is their first introduction to statistical modeling. The t-test tells us whether the difference in means between the two groups is <em>statistically</em> significant. However, it definitely <em>does not</em> tell us whether the treatment itself caused the difference, whether the effect is large, nor whether the effect is real, or even if the treatment is a good idea to do in the first place. It just tells us whether the two groups are statistically different.</p>
<p>It turns out that a t-test is just a linear regression model. It’s a special case of linear regression where there is only one independent variable, and it is a categorical variable with two levels. The coefficient from the linear regression would tell you the mean difference of the outcome between the two groups. Under the same conditions, the t-statistic from the linear regression and the t-test from a separate function would have identical statistical results.</p>
<p>Analysis of variance, or <strong>ANOVA</strong>, allows the t-test to be extended to more than two groups, and multiple features, and is also commonly employed to analyze the results of experimental design settings. But ANOVA is still just a linear regression. Even when we get into more complicated design settings such as repeated measures and mixed design, it’s still just a linear model, we’d just be using mixed models (<a href="linear_model_extensions.html#sec-lm-extend-mixed-models" class="quarto-xref"><span>Section 8.3</span></a>). In general, we’re going to use similar tools to analyze the results of our experiments as we would for other modeling settings.</p>
<p>If linear regression didn’t suggest any notion of causality to you before, it shouldn’t now either. The model is <em>identical</em> whether there was an experimental design with random assignment or not. The only difference is that the data was collected in a different way, and the theoretical assumptions and motivations are different. Even the statistical assumptions are the same whether you use random assignment, or there are more than two groups, or whether the treatment is continuous or categorical.</p>
<p>Experimental design<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> can give us more confidence in the causal explanation of model results, whatever model is used, and this is why we like to use it when we can. It helps us control for the unobserved factors that might otherwise be influencing the results. If we can be fairly certain the observations are essentially the same <em>except</em> for the treatment, then we can be more confident that the treatment is the cause of an differences we see, and be more confident in a causal interpretation of the results. But it doesn’t change the model itself, and the results of a model don’t prove a causal relationship on their own. Your experimental study will also be limited by the quality of the data, and the population it generalizes to. Even with strong design and modeling, if care isn’t taken in the modeling process to even assess the generalization of the results (<a href="machine_learning.html#sec-ml-generalization" class="quarto-xref"><span>Section 9.4</span></a>), you may find they don’t hold up<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="A/B Testing">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
A/B Testing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>A/B testing</strong> is just marketing-speak for a project focused on comparing two groups. It implies randomized assignment, but you’d have to understand the context to know if that is actually the case.</p>
</div>
</div>
</div>
</section>
</section>
<section id="sec-causal-natural" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="sec-causal-natural"><span class="header-section-number">12.4</span> Natural Experiments</h2>
<div id="fig-covid-vax-deaths" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-covid-vax-deaths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/causal-covid-vax-deaths.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-covid-vax-deaths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.3: Covid Vaccinations and Deaths in the US
</figcaption>
</figure>
</div>
<p>As we noted, random assignment or a formal experiment is not always possible or practical to implement. But sometimes we get to do it anyway, or at least we can get pretty close! Occasionally, the world gives us a <strong>natural experiment</strong>, where the assignment to the groups is essentially random, or where there is clear break before and after some event occurs, such that we examine the change as we would in pre-post design.</p>
<p>The COVID-19 pandemic provides an example of a natural experiment. The pandemic introduced sudden and widespread changes that were not influenced by individuals’ prior characteristics or behaviors, such as lockdowns, remote work, and vaccination campaigns. The randomness in the timing and implementation of these changes allows researchers to compare outcomes before and after the policy implementation or pandemic, or between different regions with varying policies, to infer causal effects.</p>
<p>For instance, we could compare states or counties that had mask mandates to those that didn’t at the same time or with similar characteristics. Or we might compare areas that had high vaccination rates to those nearby that didn’t. But these still aren’t true experiments. So we’d need to control for as many additional factors that might influence the results, e.g.&nbsp;population density, age, wealth and so on, and eventually we might still get a pretty good idea of the causal impact of these interventions.</p>
</section>
<section id="sec-causal-inference" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="sec-causal-inference"><span class="header-section-number">12.5</span> Causal Inference</h2>
<p>While we all have a natural intuition about causality, it can actually be a fairly elusive notion to grasp. Causality is a very old topic, philosophically dating back millennia, and more formally <a href="https://plato.stanford.edu/entries/causation-medieval/">hundreds of years</a>. Random assignment is a relatively new idea, say <a href="https://plato.stanford.edu/entries/peirce/">150 years old</a>, and was posited even before Wright, Fisher, and Neyman, and the 20th century rise of statistics. But with stats and random assignment we had a way to start using models to help us reason about causal relationships. <a href="https://muse.jhu.edu/pub/56/article/867087/summary">Pearl and others</a> came along to provide an algorithmic perspective from computer science, and economists like Heckman also got into the game too. We were even using programming approaches to do causal inference back in the 1970s! Eventually most scientific academic disciplines were well acquainted with causal inference in some fashion, and things have been progressing along for some time.</p>
<p>Because of its long history, causal inference is a broad field, and there are many ways to approach it. We’ve already discussed some of the basics, but there are many other ways to reason about causality. And of course, we can use models to help us understand the causal effects we are interested in.</p>
<section id="sec-causal-assumptions" class="level3" data-number="12.5.1">
<h3 data-number="12.5.1" class="anchored" data-anchor-id="sec-causal-assumptions"><span class="header-section-number">12.5.1</span> Key assumptions of causal inference</h3>
<p>Causal inference at its core is the process of identifying and estimating causal effects. But like other scientific and modeling endeavors, it relies on several key assumptions to identify and estimate those effects. The main assumptions include:</p>
<ul>
<li><strong>Consistency</strong>: The <em>potential</em> outcome under the observed treatment is the same as the <em>observed</em> outcome. This suggests there is <em>no interference</em> between units, and that there are <em>no hidden variations of the treatment</em>.</li>
<li><strong>Exchangeability</strong>: The treatment assignment is independent of the potential outcomes, given the observed covariates. In other words, the treatment assignment is as good as random after conditioning on the covariates. This is often referred to as <em>no unmeasured <strong>confounding</strong></em>.</li>
<li><strong>Positivity</strong> : Every individual has a positive probability of receiving each treatment level.</li>
</ul>
<p>It can be difficult to meet these assumptions, and there is not always a clear path to a solution. As an example, say we want to assess a new curriculum’s effect on student performance. We can randomly assign students, but they can interact with one another both in and outside of the classroom. Those who receive the treatment may be more likely to talk to one another, and this could affect the outcome, enhancing its effects if it is beneficial. This would violate our assumption of no interference between units, and we’d need to maybe choose an alternative design or outcome to account for this.</p>
<p>The following demonstrates a common assumption that is regularly guarded against in causal modeling - confounding. The confounder <code>U</code>, is a variable that affects both treatment <code>X</code> and target <code>Y</code>. We’ll generate some synthetic data with a confounder, and fit two models, one with the confounder and one without. We’ll compare the coefficients of the feature of interest in both models.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">R</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> normal <span class="im">as</span> rnorm</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_coefs(n <span class="op">=</span> <span class="dv">100</span>, true <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> rnorm(size<span class="op">=</span>n)                 <span class="co"># Unmeasured confounder</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> U <span class="op">+</span> rnorm(size<span class="op">=</span>n)       <span class="co"># Treatment influenced by U</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> true <span class="op">*</span> X <span class="op">+</span> U <span class="op">+</span> rnorm(size<span class="op">=</span>n)  <span class="co"># Outcome influenced by X and U</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pd.DataFrame({<span class="st">'X'</span>: X, <span class="st">'U'</span>: U, <span class="st">'Y'</span>: Y})</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit a linear regression model with and </span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># without adjusting for the unmeasured confounder</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> sm.OLS(data[<span class="st">'Y'</span>], sm.add_constant(data[<span class="st">'X'</span>])).fit()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    model2 <span class="op">=</span> sm.OLS(data[<span class="st">'Y'</span>], sm.add_constant(data[[<span class="st">'X'</span>, <span class="st">'U'</span>]])).fit()</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model.params[<span class="st">'X'</span>], model2.params[<span class="st">'X'</span>]</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_confounding(nreps <span class="op">=</span> <span class="dv">100</span>, n <span class="op">=</span> <span class="dv">100</span>, true<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> []</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(nreps):</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        results.append(get_coefs(n, true))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> np.mean(results, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame({</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'true'</span>: true,</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'estimate_1'</span>: results[<span class="dv">0</span>],</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">'estimate_2'</span>: results[<span class="dv">1</span>],        </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    }, index<span class="op">=</span>[<span class="st">'X'</span>]).<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>simulate_confounding(n<span class="op">=</span><span class="dv">1000</span>, nreps<span class="op">=</span><span class="dv">500</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>get_coefficients <span class="ot">=</span> <span class="cf">function</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">true =</span> <span class="dv">1</span>) {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    U <span class="ot">=</span> <span class="fu">rnorm</span>(n)                 <span class="co"># Unmeasured confounder</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">*</span> U <span class="sc">+</span> <span class="fu">rnorm</span>(n)       <span class="co"># Treatment influenced by U</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    Y <span class="ot">=</span> true <span class="sc">*</span> X <span class="sc">+</span> U <span class="sc">+</span> <span class="fu">rnorm</span>(n)  <span class="co"># Outcome influenced by X and U</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    data <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">X =</span> X, <span class="at">Y =</span> Y)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit a linear regression model with and </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># without adjusting for the unmeasured confounder</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    model <span class="ot">=</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X, <span class="at">data =</span> data)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    model2 <span class="ot">=</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X <span class="sc">+</span> U, <span class="at">data =</span> data)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="fu">coef</span>(model)[<span class="st">'X'</span>], <span class="fu">coef</span>(model2)[<span class="st">'X'</span>])</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>simulate_confounding <span class="ot">=</span> <span class="cf">function</span>(nreps, n, true) { </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    results <span class="ot">=</span> <span class="fu">replicate</span>(nreps,  <span class="fu">get_coefficients</span>(n, true))</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    results <span class="ot">=</span> <span class="fu">rowMeans</span>(results)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>(</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        <span class="at">true =</span> true,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="at">estimate_1 =</span> results[<span class="dv">1</span>],</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="at">estimate_2 =</span> results[<span class="dv">2</span>]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="fu">simulate_confounding</span>(<span class="at">nreps =</span> <span class="dv">500</span>, <span class="at">n =</span> <span class="dv">1000</span>, <span class="at">true =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>Results suggest that the coefficient for <code>X</code> is different in the two models. If we don’t include the confounder, the feature’s relationship with the target is biased upwardly. The nature of the bias depends on the relationship between the confounder and the treatment and target, but in this case it’s pretty clear!</p>
<div class="cell">
<div id="tbl-r-causal-assumptions" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-r-causal-assumptions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.1: Coefficients with and without the confounder
</figcaption>
<div aria-describedby="tbl-r-causal-assumptions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="danpqynuxl" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
#danpqynuxl table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#danpqynuxl thead, #danpqynuxl tbody, #danpqynuxl tfoot, #danpqynuxl tr, #danpqynuxl td, #danpqynuxl th {
  border-style: none;
}

#danpqynuxl p {
  margin: 0;
  padding: 0;
}

#danpqynuxl .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#danpqynuxl .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#danpqynuxl .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#danpqynuxl .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#danpqynuxl .gt_heading {
  background-color: #FFFFFF;
  text-align: left;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#danpqynuxl .gt_bottom_border {
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#danpqynuxl .gt_col_headings {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#danpqynuxl .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#danpqynuxl .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#danpqynuxl .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#danpqynuxl .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#danpqynuxl .gt_column_spanner {
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#danpqynuxl .gt_spanner_row {
  border-bottom-style: hidden;
}

#danpqynuxl .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#danpqynuxl .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#danpqynuxl .gt_from_md > :first-child {
  margin-top: 0;
}

#danpqynuxl .gt_from_md > :last-child {
  margin-bottom: 0;
}

#danpqynuxl .gt_row {
  padding-top: 7px;
  padding-bottom: 7px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#danpqynuxl .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#danpqynuxl .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#danpqynuxl .gt_row_group_first td {
  border-top-width: 2px;
}

#danpqynuxl .gt_row_group_first th {
  border-top-width: 2px;
}

#danpqynuxl .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#danpqynuxl .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#danpqynuxl .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#danpqynuxl .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#danpqynuxl .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#danpqynuxl .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#danpqynuxl .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#danpqynuxl .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#danpqynuxl .gt_table_body {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #FFFFFF;
}

#danpqynuxl .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#danpqynuxl .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#danpqynuxl .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#danpqynuxl .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#danpqynuxl .gt_left {
  text-align: left;
}

#danpqynuxl .gt_center {
  text-align: center;
}

#danpqynuxl .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#danpqynuxl .gt_font_normal {
  font-weight: normal;
}

#danpqynuxl .gt_font_bold {
  font-weight: bold;
}

#danpqynuxl .gt_font_italic {
  font-style: italic;
}

#danpqynuxl .gt_super {
  font-size: 65%;
}

#danpqynuxl .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#danpqynuxl .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#danpqynuxl .gt_indent_1 {
  text-indent: 5px;
}

#danpqynuxl .gt_indent_2 {
  text-indent: 10px;
}

#danpqynuxl .gt_indent_3 {
  text-indent: 15px;
}

#danpqynuxl .gt_indent_4 {
  text-indent: 20px;
}

#danpqynuxl .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="true" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="true">true</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="estimate_1">estimate_1</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="estimate_2">estimate_2</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="true" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">1.00</td>
<td headers="estimate_1" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">1.40</td>
<td headers="estimate_2" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">1.00</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>Though this is a simple demonstration, it shows why we need to be careful in our modeling and analysis, and if we are interested in causal relationships, we need to be aware of our assumptions and help make them plausible. If we suspect something is a confounder, we can include it in our model to get a more accurate estimate of the effect of the treatment.</p>
<p>More generally, with causal approaches to modeling, we are expressly interested in interpreting the effect of one feature on another, and we are interested in the mechanisms that bring about that effect. We are not just interested in the mere correlation between variables, or just predictive capabilities of the model. As we’ll see though, we can use the same models we’ve seen already, but need these additional considerations to draw causal conclusions.</p>
</section>
</section>
<section id="sec-causal-models" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="sec-causal-models"><span class="header-section-number">12.6</span> Models for Causal Inference</h2>
<p>We can use many modeling approaches to help us reason about causal relationships, and this can be both a blessing and a curse. Our models can be more complex, and we can use more data, which can potentially give us more confidence in our conclusions. But we can still be easily fooled by our models, as well as by ourselves. We’ll need to be careful in how we go about things, but let’s see what some of our options are!</p>
<p>Any model can potentially be used to answer a causal question, and which one you use will depend on the data setting and the question you are asking. The following covers a few models that might be seen in various academic and professional settings.</p>
<section id="sec-causal-lm" class="level3" data-number="12.6.1">
<h3 data-number="12.6.1" class="anchored" data-anchor-id="sec-causal-lm"><span class="header-section-number">12.6.1</span> Linear regression</h3>
<p>Yep, <a href="https://matheusfacure.github.io/python-causality-handbook/05-The-Unreasonable-Effectiveness-of-Linear-Regression.html">linear regression</a>. The old standby is possibly the mostly widely used model for causal inference, historically speaking and even today. We’ve seen linear regression as a kind of graphical model <a href="linear_models.html#fig-graph-lm" class="quarto-xref">Figure&nbsp;<span>3.2</span></a>, and in that sense, it can serve as the starting point for structural equation models and others that we’ll talk about next that many consider to be true causal models. It can also be used as a baseline model for other more complex causal model approaches.</p>
<p>Linear regression can potentially tell us for any particular feature, what that feature’s relationship with the target is, holding the other features constant. This <strong>ceteris paribus</strong> interpretation - ‘all else being equal’ - already gets us into a causal mindset. If we had randomization and no confounding, and the feature-target relationship was linear, we could interpret the coefficient of the feature as the causal effect.</p>
<p>However, your standard linear model doesn’t care where the data came from or what the underlying structure <em>should</em> be. It only does what you ask of it, and will tell you about group differences whether they come from a randomized experiment or not. For example, as we saw earlier, if you don’t include potential confounders, you could get a biased estimate of the effect<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. It also cannot tell you whether X effects Y or vice versa. So linear regression by itself cannot save us from the difficulties of causal inference, nor really can be considered a causal model. But it can be useful as a starting point in conjunction with other approaches.</p>
<!-- 
As an example, let's consider a simple linear model with a confounder. We'll generate some synthetic data with a confounder, and fit two models, one with the confounder and one without. We'll compare the coefficients of the feature of interest, `x`, in both models.

:::{.panel-tabset}

##### R








::: {.cell}

```{.r .cell-code}
# Set seed for reproducibility
set.seed(42)

# Generate synthetic data
n = 100
z = rnorm(n)          # the confounder 
x = 2 * z + rnorm(n)  # the confounded feature
y = 3 * z + rnorm(n)  # the target

data = tibble(x = x, y = y, z = z)

# Fit linear models
model_without_z = lm(y ~ x, data = data)
model_with_z = lm(y ~ x + z, data = data)

# Compare x coefficients
c(coef(model_without_z)['x'], coef(model_with_z)['x'])
```

::: {.cell-output .cell-output-stdout}

```
      x       x 
1.20495 0.08529 
```


:::
:::








##### Python








::: {.cell}

```{.python .cell-code}
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

# Set seed for reproducibility
np.random.seed(42)

# Generate synthetic data
n = 100
z = np.random.normal(size=n)          # the confounder
x = 2 * z + np.random.normal(size=n)  # the confounded feature
y = 3 * z + np.random.normal(size=n)  # the target

data = pd.DataFrame({'x': x, 'y': y, 'z': z})

# Fit linear models
model_without_z = LinearRegression().fit(data[['x']], data['y'])
model_with_z = LinearRegression().fit(data[['x', 'z']], data['y'])

# Compare x coefficients
model_without_z.coef_[0].round(3), model_with_z.coef_[0].round(3)
```

::: {.cell-output .cell-output-stdout}

```
(1.32, -0.012)
```


:::
:::








:::

The results show that the coefficient of `x` is different in the two models. If we don't include the confounder, the feature's relationship with the target, which in this case is zero, is a reflection of the correlation it has with the confounder, which is also correlated with the target.  Without including the confounder, we can come away with the wrong conclusion about the relationship between `x` and `y`.

As we can see from this simple demo, linear regression by itself cannot save us from the difficulties of causal inference, nor really can be considered a causal model. But it can be useful as a starting point in conjunction with other approaches. 

-->
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Weighting and Sampling Methods">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Weighting and Sampling Methods
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Common techniques for traditional statistical models used for causal inference include a variety of <strong>weighting</strong> or <strong>sampling</strong> methods. These methods are used to adjust the data so that the ‘treatment’ groups are more similar, and a causal effect can be more accurately estimated. Sampling methods include techniques such as <strong>stratification</strong> and <strong>matching</strong>, which focus on the selection of the sample as a means to balance treatment and control groups. Weighting methods include <strong>inverse probability weighting</strong> and <strong>propensity score weighting</strong>, which focus on adjusting the weights of the observations to make the groups more similar. They have extensions to continuous treatments as well.</p>
<p>Sampling and weighting methods are not models themselves, and potentially can be used with just about any model that attempts to estimate the effect of a treatment. An nice overview of using such methods vs.&nbsp;standard regression/ML can be found on <a href="https://stats.stackexchange.com/a/544958">Cross Validated</a>.</p>
</div>
</div>
</div>
</section>
<section id="sec-causal-graphical-sem" class="level3" data-number="12.6.2">
<h3 data-number="12.6.2" class="anchored" data-anchor-id="sec-causal-graphical-sem"><span class="header-section-number">12.6.2</span> Graphical models &amp; structural equation models</h3>
<div id="fig-causal-dag" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-causal-dag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/causal-dag.svg" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-causal-dag-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.4: A Causal DAG
</figcaption>
</figure>
</div>
<p><strong>Graphical and Structural Equation Models (SEM)</strong> are flexible approaches to regression and classification, and have one of the longest histories of formal statistical modeling, dating back over a century<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. As an example, <a href="#fig-causal-dag" class="quarto-xref">Figure&nbsp;<span>12.4</span></a> shows a <em>directed acyclic graph</em> (DAG) that represents a causal model. The arrows indicate the direction of the causal relationship, and each node is a feature or target, and some features are influenced by others.</p>
<p>In that graph, our focal treatment, or ‘exposure’, is physical activity, and we want to see its effect on a health outcome like cholesterol levels. However, dietary habits would also affect the outcome, and affect how much physical activity one does. Both dietary habits and physical activity may in part reflect access to healthy food. The target in question does not affect any other nodes, and in fact the causal flow is in one direction, so there is no cycle in the graph (i.e., it is ‘acyclic’).</p>
<p>One thing to note relative to the other graphical model depictions we’ve seen, is that the arrows directly flow to a target or set of targets, as opposed to just producing an ‘output’ that we then compare with the target. In graphical causal models, we’re making clear the direction and focus of the causal relationships, i.e., the causal structure, as opposed to the model structure. Also, in graphical causal models, the effects for any given feature are adjusted for the other features in the model in a particular way, so that we can think about them in isolation, rather than as a collective set of features that are all influencing the target<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>Structural equation models are widely employed in the social sciences and education, and are often used to model both observed and <em>latent</em> variables (<a href="data.html#sec-data-latent" class="quarto-xref"><span>Section 13.9</span></a>), with either serving as features or targets<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. They are also used to model causal relationships, to the point that historically they were even called ‘causal graphical models’ or ‘causal structural models’. SEMs are actually a special case of the graphical models just described, which are more common in non-social science disciplines. Compared to other graphical modeling techniques like DAGs, SEMs will typically have more assumptions, and these are often difficult to meet<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<p>The following shows a relatively simple SEM, a latent variable <strong>mediation model</strong> involving social support and self esteem, and with depression as the outcome of interest (<a href="#fig-sem" class="quarto-xref">Figure&nbsp;<span>12.5</span></a>). Each latent variable has three observed measures, e.g., item scores collected from a psychological inventory or personal survey. The observed variables are <em>caused</em> by the latent, i.e., <em>unseen</em> or <em>hidden</em>, variables. In other words, the observed item score is a less than perfect reflection of the true underlying latent variable, which is what we’re really interested in. The effects of the latent constructs of social support and self esteem on depression may be of equal interest in this setting. For social support, we’d be interested in the direct effect on depression, as well as the indirect effect through self esteem.</p>
<div id="fig-sem" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/sem.svg" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.5: SEM with latent and observed variables
</figcaption>
</figure>
</div>
<p>Formal graphical models provide a much richer set of tools for controlling various confounding, interaction, and indirect effects than simpler linear models. For this reason, they can be very useful for causal inference. It may be cautionary to note that models like linear regression can be seen as a special case, and we know that linear regression by itself is not a causal model. So in order for these tools to provide valid causal estimates, they need to be used in a way that is consistent with the assumptions of both the underlying causal model as well as the model estimation approach.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Causal Language">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Causal Language
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It’s often been suggested that we keep certain phrasing (e.g.&nbsp;feature X has an <em>effect</em> on target Y) only for the causal model setting. But the model we use can only tell us that the data is consistent with the effect we’re trying to understand, not that it actually exists. In everyday language, we often use causal language whenever we think the relationship is or should be causal, and that’s fine, and we think that’s okay in a modeling context too, as long as you are clear about the limits of your generalizability.</p>
</div>
</div>
</div>
</section>
<section id="sec-causal-counterfactual" class="level3" data-number="12.6.3">
<h3 data-number="12.6.3" class="anchored" data-anchor-id="sec-causal-counterfactual"><span class="header-section-number">12.6.3</span> Counterfactual thinking</h3>
<!-- if need a viz here; see dalle gen image at img/what_if_counterfactual.jpeg otherwise drop-->
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/causal-what_if_counterfactual.jpeg" class="img-fluid figure-img" style="width:25.0%"></p>
<figcaption>What if I had done something different…?</figcaption>
</figure>
</div>
<p>When we think about causality, we really ought to think about <strong>counterfactuals</strong>. What would have happened if I had done something different? What would have happened if I had done something sooner rather than later? What would have happened if I had done nothing at all? It’s natural to question our own actions in this way, but we can think like this in a modeling context too. In terms of our treatment effect example, we can summarize counterfactual thinking as:</p>
<blockquote class="blockquote">
<p>The question is not whether there is a difference between A and B but whether there would still be a difference if A <em>was</em> B and B <em>was</em> A.</p>
</blockquote>
<p>This is the essence of counterfactual thinking. It’s not about whether there is a difference between two groups, but whether there would still be a difference if those in one group had actually been treated differently. In this sense, we are concerned with the <strong>potential outcomes</strong> of the treatment, however defined.</p>
<p>Here is a more concrete example:</p>
<ul>
<li>Roy is shown ad A, and buys the product.</li>
<li>Pris is shown ad B, and does not buy the product.</li>
</ul>
<p>What are we to make of this? Which ad is better? <strong>A</strong> seems to be, but maybe Pris wouldn’t have bought the product if shown that ad either, and maybe Roy would have bought the product if shown ad <strong>B</strong> too! With counterfactual thinking, we are concerned with the potential outcomes of the treatment, which in this case is whether or not to show the ad.</p>
<p>Let’s say ad A is the new one, i.e., our treatment group, and B is the status quo ad, our control group. Without randomization, our real question can’t be answered by a simple test of whether means or predictions are different among the two groups, as this estimate would be biased if the groups are already different in some way to start with. The real effect is whether, for those who saw ad A, what the difference in the outcome would be if they hadn’t seen it.</p>
<p>From a prediction stand point, we can get an initial estimate straightforwardly. We demonstrated counterfactual predictions before in <a href="understanding_features.html#sec-knowing-counterfactual-predictions" class="quarto-xref"><span>Section 5.6</span></a>, but we can revisit it briefly here. For those in the treatment, we can just plug in their feature values with treatment set to ad A. Then we just make a prediction with treatment set to ad B. This approach is basically the <strong>S-Learner</strong> approach to meta-learning, which we’ll discuss in a bit, as well as a simple form of <strong>G-computation</strong>, widely used in causal inference.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">R</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model.predict(X.assign(treatment <span class="op">=</span> <span class="st">'A'</span>)) <span class="op">-</span> </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    model.predict(X.assign(treatment <span class="op">=</span> <span class="st">'B'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(model, X <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">treatment =</span> <span class="st">'A'</span>)) <span class="sc">-</span> </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(model, X <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">treatment =</span> <span class="st">'B'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>With counterfactual thinking explicitly in mind, we can see that the difference in predictions is the difference in the potential outcomes of the treatment. This is a very simple demo to illustrate how easy it is to start getting some counterfactual results from our models. But it’s typically not quite that simple in practice, and there are many ways to get this estimate wrong as well. As in other circumstances, the data and our assumptions about the problem can potentially lead us astray. But, assuming those aspects of our modeling endeavor are in order, this is one way to get an estimate of a causal effect.</p>
</section>
<section id="sec-causal-uplift" class="level3" data-number="12.6.4">
<h3 data-number="12.6.4" class="anchored" data-anchor-id="sec-causal-uplift"><span class="header-section-number">12.6.4</span> Uplift modeling</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/causal-sleeping_dog.jpeg" class="img-fluid figure-img" style="width:25.0%"></p>
<figcaption>A sleeping dog</figcaption>
</figure>
</div>
<p>The counterfactual prediction we just did provides a result that can be called the <strong>uplift</strong> or <strong>gain</strong> from the treatment, particularly when compared to a baseline metric. <strong>Uplift modeling</strong> is a general term applied to models where counterfactual thinking is at the forefront, especially in a marketing context. Uplift modeling is not a specific model per se, but any model that is used to answer a question about the potential outcomes of a treatment. The key question is what is the gain, or uplift, in applying a treatment vs.&nbsp;the baseline? Typically any statistical model can be used to answer this question, and often the model is a classification model, for example, whether Roy from the previous section bought the product or not.</p>
<p>It is common in uplift modeling to distinguish certain types of individuals or instances, and we think it’s useful to extend this to other modeling contexts as well. In the context of our previous example they are:</p>
<ul>
<li><strong>Sure things</strong>: those who would buy the product whether or not shown the ad.</li>
<li><strong>Lost causes</strong>: those who would not buy the product whether or not shown the ad.</li>
<li><strong>Sleeping dogs</strong>: those who would buy the product if not shown the ad, but not if they are shown the ad. Also referred to as the ‘Do not disturb’ group!</li>
<li><strong>Persuadables</strong>: those who would buy the product if shown the ad, but not if not shown the ad.</li>
</ul>
<p>We can generalize these conceptual groups beyond the marketing context to any treatment effect we might be interested in. So it’s worthwhile to think about which aspects of your data could correspond to these groups. One of the additional goals in uplift modeling is to identify persuadables for additional treatment efforts, and to avoid wasting money on the lost causes. But to reach such goals, we have to think causally first!</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Uplift Modeling in R and Python">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Uplift Modeling in R and Python
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>There are more widely used tools for uplift modeling and meta-learners in Python than in R, but there are some options in R as well. In Python you can check out <a href="https://causalml.readthedocs.io/en/latest/index.html">causalml</a> and <a href="https://www.uplift-modeling.com/en/v0.5.1/index.html">sci-kit uplift</a> for some nice tutorials and documentation.</p>
</div>
</div>
</div>
</section>
<section id="sec-causal-meta" class="level3" data-number="12.6.5">
<h3 data-number="12.6.5" class="anchored" data-anchor-id="sec-causal-meta"><span class="header-section-number">12.6.5</span> Meta-Learning</h3>
<p><a href="https://arxiv.org/pdf/1706.03461.pdf">Meta-learners</a> are used in machine learning contexts to assess potentially causal relationships between some treatment and outcome. The core model can actually be any kind you might want to use, but in which extra steps are taken to assess the causal relationship. The most common types of meta-learners are:</p>
<ul>
<li><strong>S-learner</strong> - <strong>s</strong>ingle model for both groups; predict the (counterfactual) difference as when all observations are treated vs when all are not, similar to our previous demonstrations of counterfactual predictions.</li>
<li><strong>T-learner</strong> - <strong>t</strong>wo models, one for each of the control and treatment groups respectively; get predictions as if all observations are ‘treated’ (i.e., using the treatment model) versus when all are ‘control’ (using the control model), and take the difference.</li>
<li><strong>X-learner</strong> - a more complicated modification to the T-learner using a multi-step approach.</li>
<li><strong>R-learner</strong> - also called (Double) Debiased ML. An approach that uses a <strong>r</strong>esidual-based model to adjust for the treatment effect<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</li>
</ul>
<p>Some variants of these models exist also. As elsewhere, the key idea is to use the model to predict the potential outcomes of the treatment levels to estimate the causal effect. Most models traditionally used in a machine learning context, e.g., random forests, boosted trees, or neural networks, are not designed to accurately estimate causal effects, nor correctly estimate the uncertainty in those effects. Meta-learners attempt to address the issue with regard to the effect, but you’ll typically still have your work cut out for you to understand the uncertainty in that effect.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Meta-Learners vs. Meta-Analysis">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Meta-Learners vs.&nbsp;Meta-Analysis
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Meta-learners are not to be confused with <strong>meta-analysis</strong>, which is also related to understanding causal effects. Meta-analysis attempts to combine the results of multiple <em>studies</em> to get a better estimate of the true effect. The studies are typically conducted by different researchers and in different settings. The term <strong>meta-learning</strong> has also been used to refer to what is more commonly called <strong>ensemble learning</strong>, the approach used in random forests and boosting. It is also probably used by other people that don’t bother to look things up before naming their technical terms.</p>
</div>
</div>
</div>
</section>
<section id="sec-causal-others" class="level3" data-number="12.6.6">
<h3 data-number="12.6.6" class="anchored" data-anchor-id="sec-causal-others"><span class="header-section-number">12.6.6</span> Others models used for causal inference</h3>
<p>Note that there are many models that would fall under the umbrella of causal inference. But typically these models are only a special application of some of the ones we’ve already become well acquainted with, so you should feel good about trying them out. Here are a few you might come across specific to the causal modeling domain:</p>
<ul>
<li>G-computation, doubly robust estimation, targeted maximum likelihood estimation<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></li>
<li>Marginal structural models<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></li>
<li>Instrumental variables and two-stage least squares<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></li>
<li>Propensity score matching/weighting</li>
<li>Regression discontinuity design<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a></li>
<li>Difference-in-differences<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></li>
<li>Mediation/moderation analysis<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></li>
<li>Meta-analysis</li>
<li>Bayesian networks</li>
</ul>
<p>In general, any modeling technique can be employed as part of a causal modeling endeavor. To actually make causal statements, you’ll generally need to ensure that the assumptions for those claims are tenable.</p>
</section>
</section>
<section id="causal-wrap" class="level2" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="causal-wrap"><span class="header-section-number">12.7</span> Wrapping Up</h2>
<p>We’ve been pretty loose in our presentation here, and glossed over many details with causal modeling. Our main goal is to give you some idea of the domain, but more so the models used and things to think about when you want to answer a causal question with your data.</p>
<p>Models used in statistical analysis and machine learning are not causal models, but when we take a causal model from the realm of ideas and apply it to the real world, a causal model becomes a statistical/ML model with more assumptions, and with additional steps taken to address those assumptions<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>. These assumptions are required in order to make stronger causal statements, but neither the assumptions, data, nor model can prove that the underlying theory is causally correct. Things like random assignment, sampling, a complex model and good data can possibly help the situation, but they can’t save you from a fundamental misunderstanding of the problem, or data that may still be consistent with that misunderstanding. Nothing about employing a causal model inherently makes better predictions either.</p>
<p>Causal modeling is hard, and most of the difficulty lies outside of the realm of models and data. The model implemented reflects the causal theory, which can be a correct or incorrect idea about how the world works. In the end, the main thing is that when we want to make causal statements, we’ll make do with what data we have, and be careful that we rule out some of the other obvious explanations and issues. The better we can control the setting, or the better we can do things from a modeling standpoint, the more confident we can be in making causal claims. Causal modeling is really an exercise in <em>reasoning</em>, which makes it such an interesting endeavor!</p>
<section id="causal-common" class="level3" data-number="12.7.1">
<h3 data-number="12.7.1" class="anchored" data-anchor-id="causal-common"><span class="header-section-number">12.7.1</span> The common thread</h3>
<p>Engaging in causal modeling may not even require you to learn any new models, but you will typically have to do more to be able to make causal statements. The key is to think about the problem in a different way, and to be more clear and careful about the assumptions you are making. You may need to do more work to ensure that your data and chosen model are consistent with the assumptions you are making.</p>
</section>
<section id="causal-adventure" class="level3" data-number="12.7.2">
<h3 data-number="12.7.2" class="anchored" data-anchor-id="causal-adventure"><span class="header-section-number">12.7.2</span> Choose your own adventure</h3>
<p>From here you might revisit some of the previous models and think about how you might use them to answer a causal question. You might also look into some of the other models we’ve mentioned here, and see how they are used in practice via the additional resources.</p>
</section>
<section id="causal-resources" class="level3" data-number="12.7.3">
<h3 data-number="12.7.3" class="anchored" data-anchor-id="causal-resources"><span class="header-section-number">12.7.3</span> Additional resources</h3>
<p>We have only scratched the surface here, and there is a lot more to learn. Here are some resources to get you started:</p>
<ul>
<li><a href="https://www.r-causal.org/">Causal Inference in R</a> <span class="citation" data-cites="barrett_causal_2024">Barrett, McGowan, and Gerke (<a href="references.html#ref-barrett_causal_2024" role="doc-biblioref">2024</a>)</span><a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></li>
<li><a href="https://mixtape.scunning.com/">Causal Inference The Mixtape</a> <span class="citation" data-cites="cunningham_causal_2023">Cunningham (<a href="references.html#ref-cunningham_causal_2023" role="doc-biblioref">2023</a>)</span></li>
<li><a href="https://matheusfacure.github.io/python-causality-handbook/">Causal Inference for the Brave and True</a> <span class="citation" data-cites="facure_alves_causal_2022">Facure Alves (<a href="references.html#ref-facure_alves_causal_2022" role="doc-biblioref">2022</a>)</span></li>
<li><a href="https://arxiv.org/abs/2403.02467">Applied Causal Inference Powered by ML and AI</a> <span class="citation" data-cites="chernozhukov_applied_2024">Chernozhukov et al. (<a href="references.html#ref-chernozhukov_applied_2024" role="doc-biblioref">2024</a>)</span></li>
<li><a href="https://www.pnas.org/doi/abs/10.1073/pnas.1804597116">Metalearners for estimating heterogeneous treatment effects using machine learning</a> <span class="citation" data-cites="kunzel_metalearners_2019">Künzel et al. (<a href="references.html#ref-kunzel_metalearners_2019" role="doc-biblioref">2019</a>)</span></li>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5888052/">The C-Word</a> <span class="citation" data-cites="hernan_c-word_2018">Hernán (<a href="references.html#ref-hernan_c-word_2018" role="doc-biblioref">2018</a>)</span></li>
</ul>
</section>
</section>
<section id="causal-exercise" class="level2" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="causal-exercise"><span class="header-section-number">12.8</span> Guided Exploration</h2>
<p>If you look into causal modeling, you’ll find mention of problematic covariates such as <a href="https://en.wikipedia.org/wiki/Collider_(statistics)">colliders</a> or <a href="https://en.wikipedia.org/wiki/Confounding">confounders</a>. We’ve talked about confounders already. A <strong>collider</strong> is a variable that is caused by two other variables, and when you condition on it, it can induce a spurious relationship between those two variables.</p>
<p>In this exercise, we’ll look at a simple example of a collider in the manner we did the confounder. First, run the available code to see what you get. Then, attempt to incorporate the simulation approach we used for the confounder example (<a href="#sec-causal-assumptions" class="quarto-xref"><span>Section 12.5.1</span></a>), and change some of the relevant coefficients around.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">R</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">2500</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.normal(size<span class="op">=</span>n)          <span class="co"># the feature</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.random.normal(size<span class="op">=</span>n)          <span class="co"># the target (no relation to x)</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x <span class="op">+</span> y <span class="op">+</span> np.random.normal(size<span class="op">=</span>n)  <span class="co"># the collider</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: x, <span class="st">'y'</span>: y, <span class="st">'z'</span>: z})</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear models</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>model_without_z <span class="op">=</span> LinearRegression().fit(data[[<span class="st">'x'</span>]], data[<span class="st">'y'</span>])</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>model_with_z <span class="op">=</span> LinearRegression().fit(data[[<span class="st">'x'</span>, <span class="st">'z'</span>]], data[<span class="st">'y'</span>])</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare x coefficients</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">'estimate_1'</span>: model_without_z.coef_[<span class="dv">0</span>],</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'estimate_2'</span>: model_with_z.coef_[<span class="dv">0</span>]</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>}, index<span class="op">=</span>[<span class="st">'x'</span>]).<span class="bu">round</span>(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate synthetic data</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">2500</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnorm</span>(n)          <span class="co"># the feature</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">rnorm</span>(n)          <span class="co"># the target (no relation to x)</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>z <span class="ot">=</span> x <span class="sc">+</span> y <span class="sc">+</span> <span class="fu">rnorm</span>(n)  <span class="co"># the collider</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">tibble</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">z =</span> z)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear models</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>model_without_z <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>model_with_z <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> x <span class="sc">+</span> z, <span class="at">data =</span> data)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare x coefficients</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">estimate_1 =</span> <span class="fu">coef</span>(model_without_z)[<span class="st">'x'</span>],</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">estimate_2 =</span> <span class="fu">coef</span>(model_with_z)[<span class="st">'x'</span>]</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-barrett_causal_2024" class="csl-entry" role="listitem">
Barrett, Malcolm, Lucy D’Agostino McGowan, and Travis Gerke. 2024. <em>Causal <span>Inference</span> in <span>R</span></em>. <a href="https://www.r-causal.org/">https://www.r-causal.org/</a>.
</div>
<div id="ref-chernozhukov_applied_2024" class="csl-entry" role="listitem">
Chernozhukov, Victor, Christian Hansen, Nathan Kallus, Martin Spindler, and Vasilis Syrgkanis. 2024. <span>“Applied <span>Causal</span> <span>Inference</span> <span>Powered</span> by <span>ML</span> and <span>AI</span>.”</span> arXiv. <a href="http://arxiv.org/abs/2403.02467">http://arxiv.org/abs/2403.02467</a>.
</div>
<div id="ref-cunningham_causal_2023" class="csl-entry" role="listitem">
Cunningham, Scott. 2023. <em>Causal <span>Inference</span> <span>The</span> <span>Mixtape</span></em>. <a href="https://mixtape.scunning.com/">https://mixtape.scunning.com/</a>.
</div>
<div id="ref-facure_alves_causal_2022" class="csl-entry" role="listitem">
Facure Alves, Matheus. 2022. <span>“Causal <span>Inference</span> for <span>The</span> <span>Brave</span> and <span>True</span> — <span>Causal</span> <span>Inference</span> for the <span>Brave</span> and <span>True</span>.”</span> <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html">https://matheusfacure.github.io/python-causality-handbook/landing-page.html</a>.
</div>
<div id="ref-hernan_c-word_2018" class="csl-entry" role="listitem">
Hernán, Miguel A. 2018. <span>“The <span>C</span>-<span>Word</span>: <span>Scientific</span> <span>Euphemisms</span> <span>Do</span> <span>Not</span> <span>Improve</span> <span>Causal</span> <span>Inference</span> <span>From</span> <span>Observational</span> <span>Data</span>.”</span> <em>American Journal of Public Health</em> 108 (5): 616–19. <a href="https://doi.org/10.2105/AJPH.2018.304337">https://doi.org/10.2105/AJPH.2018.304337</a>.
</div>
<div id="ref-kunzel_metalearners_2019" class="csl-entry" role="listitem">
Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. 2019. <span>“Metalearners for Estimating Heterogeneous Treatment Effects Using Machine Learning.”</span> <em>Proceedings of the National Academy of Sciences</em> 116 (10): 4156–65. <a href="https://doi.org/10.1073/pnas.1804597116">https://doi.org/10.1073/pnas.1804597116</a>.
</div>
<div id="ref-robins_marginal_2000" class="csl-entry" role="listitem">
Robins, J. M., M. A. Hernán, and B. Brumback. 2000. <span>“Marginal Structural Models and Causal Inference in Epidemiology.”</span> <em>Epidemiology (Cambridge, Mass.)</em> 11 (5): 550–60. <a href="https://doi.org/10.1097/00001648-200009000-00011">https://doi.org/10.1097/00001648-200009000-00011</a>.
</div>
<div id="ref-vanderweele_invited_2012" class="csl-entry" role="listitem">
VanderWeele, Tyler J. 2012. <span>“Invited <span>Commentary</span>: <span>Structural</span> <span>Equation</span> <span>Models</span> and <span>Epidemiologic</span> <span>Analysis</span>.”</span> <em>American Journal of Epidemiology</em> 176 (7): 608. <a href="https://doi.org/10.1093/aje/kws213">https://doi.org/10.1093/aje/kws213</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>This is a contrived example, but it is definitely something that you might see in the wild. The relationship is weak, and though statistically significant, the model can’t predict the target well at all. The <strong>statistical power</strong> is actually decent in this case, roughly 70%, but this is mainly because the sample size is so large and it is a very simple model setting. The same coefficient with a base rate of around 5% would have a power of around 20%. <br> This is a common issue, and it’s why we always need to be careful about how we interpret our models. In practice, we would generally need to consider other factors, such as the cost of a false positive or false negative, or the cost of the data and running the model itself, to determine if the model is worth using.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In causal modeling, there is the notion of <strong>transportability</strong>, which is the idea that a model can be used in, or generalize to, a different setting than it was trained on. For example, you may see an effect for one demographic group and want to know whether it holds for another. It is closely related to the notion of external validity, and is also related to the concepts we’ve hit on in our discussion of interactions(<a href="linear_model_extensions.html#sec-lm-extend-interactions" class="quarto-xref"><span>Section 8.2</span></a>).<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Note that experimental design is not just any setting that uses random assignment, but more generally how we introduce <em>control</em> in the sample settings.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Many experimental design settings involve sometimes very small samples due to the cost of the treatment implementation and other reasons. This often limits exploration of more complex relationships (e.g.&nbsp;interactions), and it is relatively rare to see any assessment of performance generalization. It would probably worry many to know how many important experimental results are based on p-values with small data, and this is the part of the problem seen with the <a href="https://en.wikipedia.org/wiki/Replication_crisis">replication crisis</a> in science.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>A reminder that a conclusion of ‘no effect’ is also a causal statement, and can also be a biased one. Also, you can come to the same <em>practical</em> conclusion with a biased estimate as with an unbiased one.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://en.wikipedia.org/wiki/Sewall_Wright">Wright</a> is credited with coming up with what would be called <strong>path analysis</strong> in the 1920s, which is a precursor to and part of SEM and form of graphical model.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>If we were to model this in an overly simple fashion with linear regressions for any variable with an arrow to it, you could say physical activity and dietary habits would basically be the output of their respective models. It isn’t that simple in practice though, such that we can just run separate regressions and feed in the results to the next one, thought that’s how they used to do it back in the day. We have to take more care in how we adjust for all features in the model, as well as correctly account for the uncertainty if we do take a multi-stage approach.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Your authors have to admit some bias here, but we hope the presentation for SEM is balanced. We’ve spent a lot of our past dealing with SEMs, and almost every application we saw had too little data and were grossly overfit. Many SEM programming approaches even added multiple ways to overfit the data even further, and it is difficult to trust the results reported in many papers that used them. But that’s not the fault of SEM in general- it can be a useful tool when used correctly, and it can help answer causal questions. But it can easily be misused by those not familiar with its assumptions and limitations.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><span class="citation" data-cites="vanderweele_invited_2012">VanderWeele (<a href="references.html#ref-vanderweele_invited_2012" role="doc-biblioref">2012</a>)</span> provides a nice overview of the increased assumptions of SEM relative to other methods.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>As a simple overview, think of it this way with Y outcome, T treatment and X confounders/other features. Y and T are each regressed on X via some ML model, and the residuals from both are used in a subsequent model, <span class="math inline">\(Y_{res} \sim T_{res}\)</span>, to estimate the treatment effect. Or, if you know how path analysis works, or even standard linear regression, it’s pretty much just that with ML. As an exercise, start with a linear regression for the target on all features, then just do a linear regression for a chosen focal feature predicted by the non-focal features. Next, regress the target on the non-focal features. Finally, just do a linear regression with the residuals from both models. The resulting coefficient will be what you started with for the focal feature in the first regression.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>The G-computation approach and S-learners are essentially the same approach, but came about from different domain contexts.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>Very common in epidemiology, and a nice introduction can be found in <span class="citation" data-cites="robins_marginal_2000">Robins, Hernán, and Brumback (<a href="references.html#ref-robins_marginal_2000" role="doc-biblioref">2000</a>)</span>.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Instrumental variables are used in econometrics, and are a way to get around the problem of unmeasured confounding.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Regression discontinuity design is a quasi-experimental design that is used when comparing an outcome on either side of a threshold, such as a cutoff for a program or policy. The idea is that those just above the threshold are similar to those just below, and the difference in the outcome can be attributed to the program or policy. This is at its core just a pre-post type of analysis.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Difference-in-differences just involves an interaction of a treatment with something else, typically time.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Mediation/moderation are special applications of structural equation modeling.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>Gentle reminder that making an assumption does not mean the assumption is correct, or even provable.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>Malcolm Barrett was kind enough to give us a review of the content in this chapter, and their text was a great resource for much of it. As a result, it’s much better than it would have been, and we definitely recommend it for a more in-depth look at causal inference.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ml_more.html" class="pagination-link" aria-label="More Machine Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">More Machine Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./data.html" class="pagination-link" aria-label="Dealing with Data">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Dealing with Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024 CC-BY-NC-SA</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/m-clark/book-of-models/edit/dev/causal.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/m-clark/book-of-models">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/statsdatasci">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/michael-clark-b475b5170/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>