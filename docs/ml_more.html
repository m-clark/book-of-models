<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.47">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; More ML – Models Demystified</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./data.html" rel="next">
<link href="./ml_common_models.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="8&nbsp; More ML – Models Demystified">
<meta property="og:description" content="">
<meta property="og:site_name" content="Models Demystified">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-ml-more" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">More ML</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Models Demystified</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/m-clark/book-of-models" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Linear Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">The Foundation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./knowing_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Knowing Your Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">How Did We Get Here?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generalized_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_model_extensions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Extending the Linear Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Core Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_common_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Common Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_more.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">More ML</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Other Considerations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Dealing with Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Causal Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./danger_zone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Danger Zone</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Until Next Time…</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataset_descriptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Dataset Descriptions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_operations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Matrix Operations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Using R and Python in ML</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix_placeholder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Other to come</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#key-ideas" id="toc-key-ideas" class="nav-link active" data-scroll-target="#key-ideas"><span class="header-section-number">8.1</span> Key Ideas</a>
  <ul class="collapse">
  <li><a href="#why-this-matters" id="toc-why-this-matters" class="nav-link" data-scroll-target="#why-this-matters"><span class="header-section-number">8.1.1</span> Why this matters</a></li>
  <li><a href="#good-to-know" id="toc-good-to-know" class="nav-link" data-scroll-target="#good-to-know"><span class="header-section-number">8.1.2</span> Good to know</a></li>
  </ul></li>
  <li><a href="#sec-ml-more-unsuper" id="toc-sec-ml-more-unsuper" class="nav-link" data-scroll-target="#sec-ml-more-unsuper"><span class="header-section-number">8.2</span> Unsupervised Learning</a>
  <ul class="collapse">
  <li><a href="#sec-ml-more-connections" id="toc-sec-ml-more-connections" class="nav-link" data-scroll-target="#sec-ml-more-connections"><span class="header-section-number">8.2.1</span> Connections</a></li>
  <li><a href="#sec-ml-more-other-unsupervised" id="toc-sec-ml-more-other-unsupervised" class="nav-link" data-scroll-target="#sec-ml-more-other-unsupervised"><span class="header-section-number">8.2.2</span> Other unsupervised learning techniques</a></li>
  </ul></li>
  <li><a href="#sec-ml-more-reinforcement" id="toc-sec-ml-more-reinforcement" class="nav-link" data-scroll-target="#sec-ml-more-reinforcement"><span class="header-section-number">8.3</span> Reinforcement Learning</a></li>
  <li><a href="#sec-ml-more-non-tabular" id="toc-sec-ml-more-non-tabular" class="nav-link" data-scroll-target="#sec-ml-more-non-tabular"><span class="header-section-number">8.4</span> Working with Specialized Data Types</a>
  <ul class="collapse">
  <li><a href="#sec-ml-more-spatial" id="toc-sec-ml-more-spatial" class="nav-link" data-scroll-target="#sec-ml-more-spatial"><span class="header-section-number">8.4.1</span> Spatial</a></li>
  <li><a href="#sec-ml-more-audio" id="toc-sec-ml-more-audio" class="nav-link" data-scroll-target="#sec-ml-more-audio"><span class="header-section-number">8.4.2</span> Audio</a></li>
  <li><a href="#sec-ml-more-cv" id="toc-sec-ml-more-cv" class="nav-link" data-scroll-target="#sec-ml-more-cv"><span class="header-section-number">8.4.3</span> Computer Vision</a></li>
  <li><a href="#sec-ml-more-nlp" id="toc-sec-ml-more-nlp" class="nav-link" data-scroll-target="#sec-ml-more-nlp"><span class="header-section-number">8.4.4</span> Natural Language Processing</a></li>
  </ul></li>
  <li><a href="#sec-ml-more-pretrained" id="toc-sec-ml-more-pretrained" class="nav-link" data-scroll-target="#sec-ml-more-pretrained"><span class="header-section-number">8.5</span> Pretrained Models &amp; Transfer Learning</a>
  <ul class="collapse">
  <li><a href="#sec-ml-more-self-supervised" id="toc-sec-ml-more-self-supervised" class="nav-link" data-scroll-target="#sec-ml-more-self-supervised"><span class="header-section-number">8.5.1</span> Self-Supervised Learning</a></li>
  </ul></li>
  <li><a href="#combining-models" id="toc-combining-models" class="nav-link" data-scroll-target="#combining-models"><span class="header-section-number">8.6</span> Combining Models</a></li>
  <li><a href="#sec-ml-more-ai" id="toc-sec-ml-more-ai" class="nav-link" data-scroll-target="#sec-ml-more-ai"><span class="header-section-number">8.7</span> Artificial Intelligence</a></li>
  <li><a href="#sec-ml-more-wrap" id="toc-sec-ml-more-wrap" class="nav-link" data-scroll-target="#sec-ml-more-wrap"><span class="header-section-number">8.8</span> Wrapping Up</a>
  <ul class="collapse">
  <li><a href="#the-thread" id="toc-the-thread" class="nav-link" data-scroll-target="#the-thread"><span class="header-section-number">8.8.1</span> The Thread</a></li>
  <li><a href="#choose-your-own-adventure" id="toc-choose-your-own-adventure" class="nav-link" data-scroll-target="#choose-your-own-adventure"><span class="header-section-number">8.8.2</span> Choose Your Own Adventure</a></li>
  <li><a href="#additional-resources" id="toc-additional-resources" class="nav-link" data-scroll-target="#additional-resources"><span class="header-section-number">8.8.3</span> Additional Resources</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/m-clark/book-of-models/edit/dev/ml_more.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-ml-more" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">More ML</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><img src="img/chapter_gp_plots/gp_plot_8.svg" class="img-fluid" style="width:75.0%"></p>
<p>We’ve explored some fundamental aspects of machine learning (ML) for typical data settings and modeling objectives, but there are many other areas of machine learning that we haven’t covered, and honestly, you just can’t cover everything. The field is always evolving, progressing, and branching out, and covers every data domain, which is what makes it so fun! Here we’ll briefly discuss some of the other aspects of ML that you’ll want to be aware of as you continue your journey.</p>
<section id="key-ideas" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="key-ideas"><span class="header-section-number">8.1</span> Key Ideas</h2>
<p>As we wrap up our discussion on machine learning, here are some things to keep in mind:</p>
<ul>
<li>ML can be applied to virtually any modeling or data domain</li>
<li>Other widely used areas and applications of ML include unsupervised learning, reinforcement learning, computer vision, natural language processing, and more generally, artificial intelligence.</li>
<li>While tabular data has traditionally been the primary format for modeling, the landscape has changed dramatically, and you may need to incorporate other data to reach your modeling goals.</li>
</ul>
<section id="why-this-matters" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="why-this-matters"><span class="header-section-number">8.1.1</span> Why this matters</h3>
<p>It’s very important to know just how unlimited the modeling universe is, but also to recognize the common thread that connects all models. Even when we get into other data situations and complex models, we can always fall back on the core approaches we’ve already seen and know well at this point, and know that those ideas can potentially be applied in any modeling situation.</p>
</section>
<section id="good-to-know" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="good-to-know"><span class="header-section-number">8.1.2</span> Good to know</h3>
<p>For the content in this chapter, a basic idea of modeling and machine learning would probably be enough. We’re not going to get too technical in this section.</p>
</section>
</section>
<section id="sec-ml-more-unsuper" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="sec-ml-more-unsuper"><span class="header-section-number">8.2</span> Unsupervised Learning</h2>
<p>All the models considered thus far would fall under the name of <strong>supervised learning</strong>. That is, we have a target variable that we are trying to predict with various features, and we use the data to train a model to predict the target. However, there are settings in which we do not have a target variable, or we do not have a target variable for all of the data. In these cases, we can still use what’s often referred to as <strong>unsupervised learning</strong> to learn about the data. Unsupervised learning is a type of machine learning that involves training a model without an explicit target variable in the sense that we’ve seen. But to be clear, a model and target is still definitely there! Unsupervised learning attempts learn patterns in the data in a general sense, and can be used in a wide range of applications, including clustering, anomaly detection, and dimensionality reduction. Although much of data science instruction seems to treat these as fundamentally different modeling approaches, just like much of what we’ve seen, it’s probably best to think of these as different flavors of a more general approach.</p>
<p>Traditionally, one of the more common applications of unsupervised learning falls under the heading of <strong>dimension reduction</strong>, or <strong>data compression</strong>, such that we reduce features to a smaller <strong>latent</strong>, or hidden, or unobserved, subset that accounts for most of the (co-)variance of the larger set. Alternatively, we reduce the rows to a small number of hidden, or unobserved, clusters. For example, we start with 100 features and reduce them to 10 features that still account for most of what’s important in the original set, or we classify each observation as belonging to 2-3 clusters. Either way, the primary goal is to reduce the dimensionality of the data, not predict an explicit target.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-cluster-scatter" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cluster-scatter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="ml_more_files/figure-html/fig-cluster-scatter-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cluster-scatter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1: Two Variables with Three Overlapping Clusters
</figcaption>
</figure>
</div>
</div>
</div>
<p>Classical methods in this domain include <strong>principal components analysis</strong> (PCA), <strong>singular value decomposition</strong> (SVD), and <strong>factor analysis</strong>, which are geared toward reducing column dimensions, as well as cluster methods such as <strong>k-means</strong> and <strong>hierarchical clustering</strong> for reducing observations into clusters. Sometimes these methods are often used as preprocessing steps for supervised learning problems, or as a part of exploratory data analysis, but often they are an end in themselves. Most of us are familiar with <strong>recommender systems</strong>, whether via Netflix or Amazon, which suggest products or movies, and we’re all now becoming extremely familiar with text analysis methods via chatbots and similar. While the underlying models are notably more complex these days, they actually just started off as SVD (recommender systems) or a form of factor analysis (text analysis via latent semantic analysis/latent dirichlet allocation). Having a conceptual understanding of the simpler methods can aid in understanding the more complex ones.</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled" type="tip" title="Dimension Reduction in Preprocessing">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Dimension Reduction in Preprocessing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><br> In general, you probably should not use a dimension reduction technique as a preprocessing step for a supervised learning problem. Instead, use a modeling approach that can handle high-dimensional data, has a built-in way to reduce features (e.g., lasso, boosting, dropout), or use a dimension reduction technique that is specifically designed for supervised learning (e.g., partial least squares). Creating a reduced set of features without any connection to the target target will generally be suboptimal for the supervised learning problem.</p>
</div>
</div>
</div>
<section id="sec-ml-more-connections" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="sec-ml-more-connections"><span class="header-section-number">8.2.1</span> Connections</h3>
<section id="sec-ml-more-clusters-latent" class="level4" data-number="8.2.1.1">
<h4 data-number="8.2.1.1" class="anchored" data-anchor-id="sec-ml-more-clusters-latent"><span class="header-section-number">8.2.1.1</span> Clusters are categorical latent features</h4>
<p>In both clustering rows and reducing columns, we’re essentially reducing the dimension of the features. For methods like PCA and factor analysis, we’re explicitly reducing the number of data columns to a smaller set of numeric features. For example, we might take answers to responses to dozens of questions from a personality inventory, and reduce them to five key features that represent general aspects of personality. These new features are on their own scale, often standardized, but they still reflect at least some of the original items’ variability <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>Now, imagine if we reduced the features to a single categorical variable. Now you have cluster analysis! You can discretize any continuous feature to a coarse couple of categories, and this goes for latent variables as well as those we actually observe in our data. For example, if we do a factor analysis with one latent feature, we could either convert it to a probability of some class with an appropriate transformation, or just say that scores higher than some cutoff are in cluster A and the others are in cluster B. Indeed, there is a whole class of clustering models called <strong>mixture models</strong> that do just that- they estimate the latent probability of class membership. Many of these approaches are conceptually similar or even identical, and the primary difference is how we think about and interpret the results.</p>
</section>
<section id="sec-ml-more-pca-as-net" class="level4" data-number="8.2.1.2">
<h4 data-number="8.2.1.2" class="anchored" data-anchor-id="sec-ml-more-pca-as-net"><span class="header-section-number">8.2.1.2</span> PCA as a neural network</h4>
<p>Consider the following neural network, called an <strong>autoencoder</strong>. Its job is to shrink the features down to a smaller, simpler representation, and then rebuild it from the compressed state to an output that matches the original as closely as possible. It’s trained by minimizing the error between the original data and the reconstructed data. The autoencoder is a special case of a neural network used as a component of many larger architectures such as those seen with large language models, but can be used for dimension reduction in and of itself if we are specifically interested in the compression layer, sometimes called a <strong>bottleneck</strong>.</p>
<div id="fig-pca-auto" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pca-auto-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/pca_as_net.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pca-auto-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.2: PCA or Autoencoder
</figcaption>
</figure>
</div>
<p>Consider the following setup for such a situation:</p>
<ul>
<li>Single hidden layer</li>
<li>Number of hidden nodes = number of inputs</li>
<li>Linear activation function</li>
</ul>
<p>An autoencoder in this case would be equivalent to principal components analysis. In the approach described, PCA perfectly reconstructs the original data when considering all components, and so the error would be zero. But that doesn’t give us any dimension reduction, we still have as many nodes in the compression layer as we did inputs. So with PCA we often only retain a small number of components that capture the data variance by some arbitrary amount. The discarded nodes are actually still estimated though.</p>
<p>Neural networks however are not bound to linear activation functions, the size of the inputs or even a single layer, and so they provide a much more flexible approach that can compress the data at a certain layer, but still have very good reconstruction error. Typical autoencoders would have multiple layers with notably more nodes than inputs. It’s not as easily interpretable as typical factor analytic techniques, and we still have to sort out the architecture. However, it’s a good example of how the same underlying approach can be used for different purposes.</p>
<!-- due to digrammer issues in preview vs rendered, we just created a png also, note which one is ultimately used -->
<div id="fig-autoencoder" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-autoencoder-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/autoencoder.png" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-autoencoder-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.3: Conceptual Diagram of an Autoencoder
</figcaption>
</figure>
</div>
<!-- TODO: find a way to make graphviz allow for labels/backgrounds on subgraphs with same rank -->
<!-- The only real difference between the two approaches is the objective (function), and for any k latent features I come up with I can create (at least) k + 1 clusters before taking into account interactions of the latent variables. 

https://stats.stackexchange.com/questions/122213/latent-class-analysis-vs-cluster-analysis-differences-in-inferences -->
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Autoencoders and LLMs">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Autoencoders and LLMs
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Autoencoders are special cases of encoder-decoder models, which are used in many applications, including machine translation, image captioning, and more. Autoencoders have the same inputs and outputs, but in other scenarios, a similar type of architecture might be used to classify or generate text, as with large language models.</p>
</div>
</div>
</div>
</section>
<section id="sec-ml-more-latent-linear" class="level4" data-number="8.2.1.3">
<h4 data-number="8.2.1.3" class="anchored" data-anchor-id="sec-ml-more-latent-linear"><span class="header-section-number">8.2.1.3</span> Latent Linear Models</h4>
<p>Another thing to be aware of is that some dimension reduction techniques can be thought of as <em>latent linear models</em>. The following depicts factor analysis as a latent linear model. The ‘targets’ are the observed features, and we predict each one by some linear combination of latent variables.</p>
<p><span class="math display">\[
\begin{aligned}
x_1 &amp;= \beta_{11} h_1 + \beta_{12} h_2 + \beta_{13} h_3 + \beta_{14} h_4 + \epsilon_1 \\
x_2 &amp;= \beta_{21} h_1 + \beta_{22} h_2 + \beta_{23} h_3 + \beta_{24} h_4 + \epsilon_2 \\
x_3 &amp;= \beta_{31} h_1 + \beta_{32} h_2 + \beta_{33} h_3 + \beta_{34} h_4 + \epsilon_3 \\
\end{aligned}
\]</span></p>
<p>In this scenario, the <span class="math inline">\(h\)</span> are estimated latent variables, and <span class="math inline">\(\beta\)</span> are the coefficients, which in some contexts are called <strong>loadings</strong>. The <span class="math inline">\(\epsilon\)</span> are the residuals, which are assumed to be independent and normally distributed as with a standard linear model. The <span class="math inline">\(\beta\)</span> are usually estimated by maximum likelihood. The latent variables are not observed, but are to be estimated as part of the modeling process<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, and typically standardized with mean 0 and standard deviation of 1. The number of latent variables we use is a hyperparameter in the ML sense, and so can be determined by the usual means<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. To tie some more common models together:</p>
<ul>
<li>PCA is a factor analysis with no (residual) variance, and the latent variables are orthogonal (independent).</li>
<li>Probabilistic PCA is a factor analysis with constant residual variance.</li>
<li>Factor analysis is a factor analysis with varying residual variance.</li>
<li>Independent component analysis is a factor analysis that does not assume an underlying gaussian data generating process.</li>
<li>Non-negative matrix factorization and latent dirichlet allocation are factor analyses applied to counts (think poisson and multinomial regression).</li>
</ul>
</section>
</section>
<section id="sec-ml-more-other-unsupervised" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="sec-ml-more-other-unsupervised"><span class="header-section-number">8.2.2</span> Other unsupervised learning techniques</h3>
<p>There are several techniques that are used to visualize high-dimensional data in simpler ways, such as multidimensional scaling, t-SNE, and (H)DBSCAN. These are often used as a part of exploratory data analysis to identify groups.</p>
<p><strong>Cluster analysis</strong> is a method with a long history and many different approaches, including hierarchical clustering algorithms (agglomerative, divisive), k-means, and more. Distance matrices are often the first step for these clustering approaches, and there are many ways to calculate distances between observations. Conversely, some methods use adjacency matrices, which focus on similarity of observations rather than differences (like correlations), are can be used for graph-based approaches to find hidden clusters.</p>
<p><strong>Anomaly/outlier detection</strong> is an approach for finding ‘unusual’ data points, or otherwise small, atypical clusters. This is often done by looking for data points that are far from the rest of the data, or that are not well explained by the model. This approach is often used for situations like fraud detection or network intrusion detection. Standard clustering or modeling techniques might be used to identify outliers, or specialized techniques might be used.</p>
<div id="fig-network-graph" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-network-graph-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/network_us.png" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-network-graph-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.4: Network Graph
</figcaption>
</figure>
</div>
<p><strong>Network analysis</strong> is a type of unsupervised learning that involves analyzing the relationships between entities. It is a graph-based approach that involves identifying nodes (e.g., people) and edges (e.g., do they know each other?) in a network. It is used in a wide range of applications, like identifying communities within a network, or to see how they evolve over time. It is also used to identify relationships between entities, such as people, products, or documents. One might be interested in such things as which nodes that have the most connections, or the general ‘connectedness’ of a network. Network analysis or similar graphical models typically have their own clustering techniques that are based on the edge (connection) weights between individuals, such as modularity, or the number of edges between individuals, such as k-clique.</p>
<p>In summary, there are many methods that fall under the umbrella of unsupervised learning, but even when you don’t think you have an explicit target variable, you can still understand or frame these as models in a similar way to help you understand the data. It’s important to not get hung up on trying to distinguish modeling approaches with somewhat arbitrary labels, and focus more on what their modeling goal is and how best to achieve it!</p>
<div class="callout callout-style-simple callout-none no-icon callout-titled" type="info" title="Generative vs. Discriminative Models">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Generative vs.&nbsp;Discriminative Models
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In general, many unsupervised learning and many deep learning techniques involved in computer vision and natural language processing are often thought of as <strong>generative</strong> models. These attempt to model the underlying data generating process, i.e.&nbsp;the features, but possibly a target variable also. In contrast, most supervised learning models are often thought of as <strong>discriminative</strong> models, that try to model the conditional distribution of the target given the features only.</p>
<p>These labels are a bit problematic though. Any probabilistic model can be used to generate data, even if it is only for the target, so calling a model generative isn’t all that clarifying. And models that might be thought of as discriminative in a machine learning context might not be in others (e.g.&nbsp;<a href="https://stats.stackexchange.com/questions/7455/the-connection-between-bayesian-statistics-and-generative-modeling">Bayesian</a>).</p>
</div>
</div>
</div>
</section>
</section>
<section id="sec-ml-more-reinforcement" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="sec-ml-more-reinforcement"><span class="header-section-number">8.3</span> Reinforcement Learning</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/ml-rl_basic.svg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Reinforcement Learning</figcaption>
</figure>
</div>
<p><strong>Reinforcement learning</strong> (RL) is a type of modeling approach that involves training an <strong>agent</strong> to make decisions in an <strong>environment</strong>. The agent receives feedback in the form of rewards or punishments for its actions, and the goal is to maximize its rewards over time by learning which actions lead to positive or negative outcomes. Typical data involves a sequence of states, actions, and rewards, and the agent learns a policy that maps states to actions. The agent learns by interacting with the environment, and the environment changes based on the agent’s actions.</p>
<p>The agent’s goal is to learn a <strong>policy</strong>, which is a set of rules that dictate which actions to take in different situations. The agent learns by trial and error, adjusting its policy based on the feedback it receives from the environment. The classic example is a game like chess or a simple video game. In these scenarios, The agent learns which moves (actions) lead to winning the game (positive reward) and which moves lead to losing the game (negative reward). Over time, the agent improves its policy to make better moves that increase its chances of winning.</p>
<p>One of the key challenges in reinforcement learning is balancing <strong>exploration and exploitation</strong>. Exploration is about trying new actions that could lead to higher rewards, while exploitation is about sticking to the actions that have already been found to give good rewards.</p>
<p>Reinforcement learning has many applications, including robotics, games, and autonomous driving, but there is little restriction on where it might be applied. It is often a key part of some deep learning models, where reinforcement is supplied via human feedback or other means to an otherwise automatic modeling process. In general, RL is a powerful tool that might be useful where traditional programming approaches may not be as feasible.</p>
</section>
<section id="sec-ml-more-non-tabular" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="sec-ml-more-non-tabular"><span class="header-section-number">8.4</span> Working with Specialized Data Types</h2>
<!-- TODO: Does this section belong in this chapter? Initially the focus was on CV/NLP -->
<p>While our focus in this book is on tabular data due to its ubiquity, there are many other types of data that can be used for machine learning and modeling in general, some of which can still potentially be used in that manner, but which often start as a different format or must be considered in a special way. You’ll often hear this labeled as ‘unstructured’, but that’s probably not the best conceptual way to think about it, as the data is still structured in some way, sometimes in a strict format (e.g.&nbsp;images). Here we’ll briefly discuss some of the other types of data you’ll potentially come across.</p>
<section id="sec-ml-more-spatial" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="sec-ml-more-spatial"><span class="header-section-number">8.4.1</span> Spatial</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/ml-spatial-tippecanoe-example.gif" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Spatial Data (code available from <a href="https://walker-data.com/mapboxapi/articles/creating-tiles.html">Kyle Walker</a>)</figcaption>
</figure>
</div>
<p>Spatial data, which includes geographic and similar information, can be quite complex. It often comes in specific formats (e.g.&nbsp;shapefiles), and may require specialized tools to work with it. Spatial specific features may include continuous variables like latitude and longitude, or tracking data from a device like a smartwatch. Other spatial features are more discrete, such as states or political regions within a country.</p>
<p>In general, we could use these features as we would others in the tabular setting, but we often want to take into account the uniqueness of a particular region, or the correlation of spatial regions. Historically, most spatial data can be incorporated into approaches like mixed models or generalized additive models, but in certain applications, such as satellite imagery, deep learning models are more the norm, and the models often transition into image processing techniques.</p>
</section>
<section id="sec-ml-more-audio" class="level3" data-number="8.4.2">
<h3 data-number="8.4.2" class="anchored" data-anchor-id="sec-ml-more-audio"><span class="header-section-number">8.4.2</span> Audio</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/wiki-colour_soundwave.svg" class="img-fluid figure-img"></p>
<figcaption>Sound wave</figcaption>
</figure>
</div>
<p>Audio data is a type of time series data that is also the focus for many modeling applications. Think of the sound of someone speaking or music playing, as it changes over time. Such data is often represented as a waveform, which is a plot of the amplitude of the sound wave over time.</p>
<p>The goal of modeling audio data may include speech recognition, language translation, music generation, and more. Like spatial data, audio data is typically stored in specific formats and can be quite large. Also like spatial data, the specific type of data and research question may allow for a tabular format. In that case the modeling approaches used are similar to those for other time series data.</p>
<p>Deep learning methods have proven very effective for analyzing audio data, and can even create songs people actually like, <a href="https://en.wikipedia.org/wiki/Now_and_Then_(Beatles_song)">even recently helping the Beatles to release one more song</a>. Nowadays, you can generate an entire song in any genre you want, just by typing a text prompt!</p>
</section>
<section id="sec-ml-more-cv" class="level3" data-number="8.4.3">
<h3 data-number="8.4.3" class="anchored" data-anchor-id="sec-ml-more-cv"><span class="header-section-number">8.4.3</span> Computer Vision</h3>
<!-- TODO: better image -->
<!-- https://alexlenail.me/NN-SVG/LeNet.html -->
<!-- ![Convolutional Neural Network](img/ml-resnet_architecture.png){#fig-cnn width=66%} -->
<div id="fig-cnn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/cnn.png" class="img-fluid figure-img" style="width:66.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cnn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.5: Convolutional Neural Network
</figcaption>
</figure>
</div>
<p>Computer vision involves a range of models and techniques for analyzing and interpreting image-based data. It includes tasks like image classification (labeling an image), object detection (finding the location of objects are in an image), image segmentation (identifying the boundaries of objects in an image), and object tracking (following objects as they move over time).</p>
<p>In general, your raw data is an image, which is represented as a matrix of pixel values. For example, each row of the matrix could be a grayscale value for a pixel, or it could be an array of Red, Green, and Blue (RGB) values for each pixel. The modeling goal is to extract features from the image that can be used for the task at hand. For example, you might extract features such as color, texture, and shape. You can then use these features to train a model to classify images or whatever your task may be.</p>
<p>Image processing is a broad field with many applications. It is used in medical imaging, satellite imagery, self-driving cars, and more. And while it can be really fun to classify objects such as cats and dogs, or generate images from text and vice versa, it can be quite challenging due to the size of the data, issues specific to video/image quality, and the model complexity. Even if your base data is often the same or very similar, the model architecture and training process can vary widely depending on the task at hand.</p>
<p>These days we generally don’t have to start from scratch though, there are pretrained models that can be used for image processing tasks, which you can then fine-tune for your specific task. These models are often based on convolutional neural networks (CNNs), which are a type of deep learning model. CNNs are designed to take advantage of the spatial structure of images, and they use a series of convolutional layers to extract features from the image. These features are then passed through a series of fully connected layers to make a prediction. CNNs have been used to achieve state-of-the-art results on a wide range of image processing tasks, and are the standard for many image processing applications. More recently, diffusion models, which seek to reconstruct images after successively adding noise to the initial input, have been shown to be quite effective for a wide range of tasks involving image generation.</p>
</section>
<section id="sec-ml-more-nlp" class="level3" data-number="8.4.4">
<h3 data-number="8.4.4" class="anchored" data-anchor-id="sec-ml-more-nlp"><span class="header-section-number">8.4.4</span> Natural Language Processing</h3>
<!-- TODO: SOME SORT OF CHAT RELATED IMAGE -->
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/gpt4_barth_data.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Partial GPT4 output from a prompt: Write a very brief short story about using models in data science. It should reflect the style of Donald Barthelme.</figcaption>
</figure>
</div>
<p>One of the hottest areas of modeling development in recent times regards <strong>natural language processing</strong>, as evidenced by the runaway success of models like <a href="https://chat.openai.com/">ChatGPT</a>. Natural language processing (NLP) is a field of study that focuses on understanding human language, and along with computer vision, is a very visible subfield of artificial intelligence. NLP is used in a wide range of applications, including machine translation, speech recognition, text classification, and more. NLP is behind some of the most exciting modeling applications today, with tools that continue to amaze with their capabilities to generate summaries of articles, answering questions, write code, and even <a href="https://www.abajournal.com/web/article/latest-version-of-chatgpt-aces-the-bar-exam-with-score-in-90th-percentile">pass the bar exam with flying colors</a>!</p>
<p>Early efforts in this field were based on statistical models, and then variations on things like PCA, but it took a lot of <a href="https://m-clark.github.io/text-analysis-with-R/intro.html">data pre-processing work</a> to get much from those approaches, and results could still be unsatisfactory. More recently, deep learning models became the standard application, and there is no looking back in that regard. Current state of the art models have been trained on massive amounts of data, <a href="https://commoncrawl.org/">even much of the internet</a>, and can be used for a wide range of tasks. But you don’t have to train such a model yourself- now you can simply use a pretrained model like GPT-4 for your own tasks. In some cases much of the trouble comes with generating the best prompt to produce the desired results. However, the field and the models are evolving extremely rapidly, and things are getting easier all the time. In the meantime, feel free to just <a href="https://chat.openai.com/">play around with ChatGPT yourself</a>.</p>
</section>
</section>
<section id="sec-ml-more-pretrained" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="sec-ml-more-pretrained"><span class="header-section-number">8.5</span> Pretrained Models &amp; Transfer Learning</h2>
<p>Pretrained models are those that have been trained on a large amount of data, and can be used for a wide range of tasks, even on data they were not trained on. They are widely employed in image and natural language processing. The basic idea is that if you can use a model that was trained on the entire internet of text, why start from scratch? Image processing models already understand things like edges and colors, so there is little need to reinvent the wheel when you know those features would be useful for your own task. These are viable in tasks where the inputs are similar to the data the model was trained on, as is the case with images and text.</p>
<p>You can use a pretrained model as a starting point for your own model, and then <strong>fine-tune</strong> it for your specific task, and this is more generally called <strong>transfer learning</strong>. The gist is that you only need to train part of the model on your specific data, or possibly even not at all. You can just feed your data in and get predictions from the ready-to-go model! This obviously can save a lot of time and resources, assuming you don’t have to pay much to use the model in the first place, and can be especially useful when you don’t have a lot of data to train your model on.</p>
<section id="sec-ml-more-self-supervised" class="level3" data-number="8.5.1">
<h3 data-number="8.5.1" class="anchored" data-anchor-id="sec-ml-more-self-supervised"><span class="header-section-number">8.5.1</span> Self-Supervised Learning</h3>
<p>Self-supervised learning is a type of machine learning technique that involves training a model on a task that can be generated from the data itself. In this case there is no labeled data unlike the standard pre-trained setting. For example, you might train a model to predict the next word in a sentence. The idea is that the model learns to extract (represent) useful features from the data by trying to predict the missing information, which is imposed via a <strong>mask</strong> and may change from sample to sample. We also may use a different type of objective function, such as minimizing the distance between the embeddings for similar inputs and maximizing the distance between embeddings for dissimilar inputs.</p>
<p>This can be a useful approach when you don’t have labeled data, or just when you don’t have a lot of labeled data. Once trained, it can be used as other pre-trained models to predict other unlabeled data. Self-supervised learning is often used in natural language processing, but can be applied to other types of data as well.</p>
</section>
</section>
<section id="combining-models" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="combining-models"><span class="header-section-number">8.6</span> Combining Models</h2>
<p>It’s also important to note that these types of data and their associated models are not mutually exclusive. For example, you might have a video that contains both audio and visual information pertinent to the task. Or you might want to produce images from text inputs. In these cases, you can use a combination of models to extract features from the data, which may just be more features in a tabular format, or be as complex as a <strong>multimodal</strong> deep learning architecture.</p>
<p>Many computer vision, audio, natural language and other modeling approaches incorporate <strong>transformers</strong>. They are based on the idea of <strong>attention</strong>, which is a mechanism that allows the model to focus on certain parts of the input sequence and less on others. Transformers are used in many state-of-the-art models with different data types, such as those that combine text and images. The transformer architecture, <a href="(https://bbycroft.net/llm)">although complex</a>, underpins many of today’s most sophisticated models, so is worth being aware of even if it isn’t your data domain.</p>
<p>As an example, we added a transformer-based approach to process the reviews in the movie review data set used in other chapters. We kept to the same basic data setup, and we ended up with notably better performance than the other models demonstrated, pushing toward 90% accuracy on test, even without fiddling too much with many hyper parameters. It’s a good example of a case where we have standard tabular data, but need to deal with additional data structure in a different way. By combining the approaches to obtain a final output for prediction, we obtained better results than we would with a single model. This won’t always be the case, but keep it in mind when you are dealing with different data sources or types.</p>
</section>
<section id="sec-ml-more-ai" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="sec-ml-more-ai"><span class="header-section-number">8.7</span> Artificial Intelligence</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/ai_workshop_brain_3.jpeg" class="img-fluid figure-img" style="width:66.0%"></p>
<figcaption>AI</figcaption>
</figure>
</div>
<p>The prospect of combining models for computer vision, natural language processing, audio processing, and other domains can produce tools that mimic many aspects of what we call intelligence<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Current efforts in <strong>artificial intelligence</strong> produce models that can pass law and medical exams, create better explanations of images and text than average human effort, and produce conversation on par with humans. AI even helped to create this book!</p>
<p>In many discussions of ML and AI, <a href="https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/artificial-intelligence-vs-machine-learning">many put ML as a subset of AI</a>, but this is a bit off the mark from a modeling perspective in our opinion<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. In terms of models, practically most of what we’d call modern AI almost exclusively employs deep learning models, while the ML approach to training and evaluating models can be used for any underlying model, from simple linear models to the most complex deep learning models, and whether the application falls under the domain of AI or not. Furthermore, statistical model applications have never seriously attempted what we might call AI.</p>
<p>If AI is some ‘autonomous and general set of tools that attempt to engage the world in a human-like way or better’, it’s not clear why it’d be compared to ML in the first place. That’s kind of like saying the brain is a subset of cognition. The brain does the work, much like ML does the modeling work with data, and gives rise to what we call cognition, but generally we would not compare the brain to cognition. We also wouldn’t call ML a subset of climate science or medicine for similar reasons - they are domains in which it is used, much like the domain of artificial intelligence.</p>
<p>The main point is to not get too hung up on the labels, and focus on the modeling goal and how best to achieve it. Deep learning models, and machine learning in general, can be used for AI or non-AI settings, as we have seen for ourselves. And models still employ the <em>perspective</em> of the ML approach when ultimately used for AI - the steps taken from data to model output are largely the same, as we are concerned with validation and generalization.</p>
<p>Many of the non-AI settings we use modeling for may well be things we can eventually rely on AI to do. At present though, the computational limits, and the amount of data that would be required for AI models to do well, or the ability of AI to be able to deal with situations in which there is <em>only</em> small bits of data to train on, are still hindrances in current applications of AI. However, we feel it’s likely these issues will eventually be overcome. Even then, a statistical approach may still have a place when the data is small.</p>
<p><strong>Artificial general intelligence (AGI)</strong> is the holy grail of AI, and like AI itself is not consistently defined. In general, the idea behind AGI is the creation of some autonomous agent that can perform any task that a human can perform, many that humans cannot, and generalize abilities to new problems that have not even been seen yet. It seems we are getting closer to AGI all the time, but it’s not yet clear when it will be achieved, or even what it will look like when it is, especially since no one has an agreed upon definition of what intelligence is in the first place.</p>
<p>All that being said, to be perfectly honest, you may well be reading a history book. Given recent advancements just in the last couple years, it almost seems unlikely that the data science being performed five years from now will resemble much of how things are done today<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. We are already capable of making faster and further advancements in many domains due to AI, and it’s likely that the next generation of data scientists will be able to do so even more easily. The future is here, and it is amazing. Buckle up!</p>
</section>
<section id="sec-ml-more-wrap" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="sec-ml-more-wrap"><span class="header-section-number">8.8</span> Wrapping Up</h2>
<p>We hope you’ve enjoyed the journey and have a better understanding of the core concepts. By now you also have a couple modeling tools in hand, and also have a good idea of where things can go. We encourage you to continue learning and experimenting with what you’ve seen, and to apply what you’ve learned to your own problems. The best way to learn is by doing, so don’t be afraid to get your hands dirty and start building models!</p>
<section id="the-thread" class="level3" data-number="8.8.1">
<h3 data-number="8.8.1" class="anchored" data-anchor-id="the-thread"><span class="header-section-number">8.8.1</span> The Thread</h3>
<p>Even the most complex models can be thought of as a series of steps that go from input to output. In between can get very complicated, but often the underlying operations are the same ones you saw used with the simplest models. One of the key goals of any model is to generalize to new data, and this is the same no matter what type of data you’re working with or what type of model you’re using.</p>
</section>
<section id="choose-your-own-adventure" class="level3" data-number="8.8.2">
<h3 data-number="8.8.2" class="anchored" data-anchor-id="choose-your-own-adventure"><span class="header-section-number">8.8.2</span> Choose Your Own Adventure</h3>
<p>The sky’s the limit with machine learning and modeling, so go where your heart leads you, and have some fun! If you started here, feel free to go back to Part I for a more traditional and statistical modeling overview. Otherwise, head to Part III for an overview of a few more modeling topics such as causal modeling (<a href="causal.html" class="quarto-xref"><span>Chapter 10</span></a>), data issues (<a href="data.html" class="quarto-xref"><span>Chapter 9</span></a>), and things to avoid (<a href="danger_zone.html" class="quarto-xref"><span>Chapter 11</span></a>).</p>
</section>
<section id="additional-resources" class="level3" data-number="8.8.3">
<h3 data-number="8.8.3" class="anchored" data-anchor-id="additional-resources"><span class="header-section-number">8.8.3</span> Additional Resources</h3>
<ul>
<li>Courses on ML and DL: FastAI (<span class="citation" data-cites="howard_practical_2024">Howard (<a href="references.html#ref-howard_practical_2024" role="doc-biblioref">2024</a>)</span>), <a href="https://www.coursera.org/collections/machine-learning">Coursera</a>, <a href="https://www.edx.org/">edX</a>, (DeepLearning.AI)[https://www.deeplearning.ai/], and many others are great places to get more formal training.</li>
<li><a href="https://www.kaggle.com/">Kaggle</a>: Even if you don’t compete, you can learn a lot from what others are doing.</li>
<li><a href="https://cloud.google.com/discover/what-is-unsupervised-learning">Unsupervised learning overview at Google</a></li>
<li>Machine Learning and AI: Beyond the Basics (<span class="citation" data-cites="raschka_machine_2023">Raschka (<a href="references.html#ref-raschka_machine_2023" role="doc-biblioref">2023</a>)</span>)</li>
<li><a href="https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1">Visualizing Transformer Models</a> (<span class="citation" data-cites="vig_deconstructing_2019">Vig (<a href="references.html#ref-vig_deconstructing_2019" role="doc-biblioref">2019</a>)</span>)</li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-howard_practical_2024" class="csl-entry" role="listitem">
Howard, Jeremy. 2024. <span>“Practical <span>Deep</span> <span>Learning</span> for <span>Coders</span> - <span>Practical</span> <span>Deep</span> <span>Learning</span>.”</span> <em>Practical Deep Learning for Coders</em>. <a href="https://course.fast.ai/">https://course.fast.ai/</a>.
</div>
<div id="ref-raschka_machine_2023" class="csl-entry" role="listitem">
Raschka, Sebastian. 2023. <em>Machine <span>Learning</span> <span>Q</span> and <span>AI</span></em>. <a href="https://nostarch.com/machine-learning-q-and-ai">https://nostarch.com/machine-learning-q-and-ai</a>.
</div>
<div id="ref-vig_deconstructing_2019" class="csl-entry" role="listitem">
Vig, Jesse. 2019. <span>“Deconstructing <span>BERT</span>, <span>Part</span> 2: <span>Visualizing</span> the <span>Inner</span> <span>Workings</span> of <span>Attention</span>.”</span> <em>Medium</em>. <a href="https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1">https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1</a>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Ideally we’d capture all the variability, but that’s not going to happen, and some techniques or results may only capture a relatively small percentage. In our personality example, this could be because the questions don’t adequately capture the underlying personality constructs (i.e.&nbsp;an issue of the reliability of instrument), or because personality is just not that simple and we’d need more dimensions.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>They can also be derived in post-processing depending on the estimation approach.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Actually, in application as typically seen in social sciences, cross-validation is very rarely employed, and the number of latent variables is determined by some combination of theory, model comparison for training data only, or trial and error. Not that we’re advocating for that, but it’s a common practice.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>It seems most discussions of AI in the public sphere haven’t really defined intelligence very clearly in the first place, and the academic realm has struggled with the concept for centuries.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>In almost every instance of this we’ve seen printed, there isn’t any actual detail or specific enough definitions to make the comparison meaningful to begin with, so don’t take it too seriously.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>A good reference for this sentiment is a scene from Star Trek in which <a href="https://www.youtube.com/watch?v=hShY6xZWVGE">Scotty has to use a contemporary computer</a>.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ml_common_models.html" class="pagination-link" aria-label="Common Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Common Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./data.html" class="pagination-link" aria-label="Dealing with Data">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Dealing with Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024 CC-BY-NC-SA</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/m-clark/book-of-models/edit/dev/ml_more.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link active" href="https://github.com/m-clark/book-of-models" aria-current="page">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/statsdatasci">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>