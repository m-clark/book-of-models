<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>11&nbsp; Common Models in Machine Learning – Models Demystified</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ml_more.html" rel="next">
<link href="./machine_learning.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-eec513e658ff5c45193b855ab1b1d361.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="11&nbsp; Common Models in Machine Learning – Models Demystified">
<meta property="og:description" content="">
<meta property="og:image" content="img/ml-beat_the_baseline.svg">
<meta property="og:site_name" content="Models Demystified">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-ml-common-models" class="quarto-section-identifier"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Common Models in Machine Learning</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Models Demystified</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/m-clark/book-of-models" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Thinking About Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Foundation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Understanding the Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding_features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Understanding the Features</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model Estimation and Optimization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./uncertainty.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Estimating Uncertainty</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generalized_linear_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Generalized Linear Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_model_extensions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Extending the Linear Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Core Concepts in Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_common_models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Common Models in Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_more.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Extending Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Causal Modeling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dealing with Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./danger_zone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Danger Zone</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Parting Thoughts</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Acknowledgments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_operations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Matrix Operations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./more_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">More Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataset_descriptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Dataset Descriptions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-ml-common-key-ideas" id="toc-sec-ml-common-key-ideas" class="nav-link active" data-scroll-target="#sec-ml-common-key-ideas"><span class="header-section-number">11.1</span> Key Ideas</a>
  <ul class="collapse">
  <li><a href="#sec-ml-common-why-matters" id="toc-sec-ml-common-why-matters" class="nav-link" data-scroll-target="#sec-ml-common-why-matters"><span class="header-section-number">11.1.1</span> Why this matters</a></li>
  <li><a href="#sec-ml-common-good-to-know" id="toc-sec-ml-common-good-to-know" class="nav-link" data-scroll-target="#sec-ml-common-good-to-know"><span class="header-section-number">11.1.2</span> Helpful context</a></li>
  </ul></li>
  <li><a href="#sec-ml-common-general-approach" id="toc-sec-ml-common-general-approach" class="nav-link" data-scroll-target="#sec-ml-common-general-approach"><span class="header-section-number">11.2</span> General Approach</a></li>
  <li><a href="#sec-ml-common-data-setup" id="toc-sec-ml-common-data-setup" class="nav-link" data-scroll-target="#sec-ml-common-data-setup"><span class="header-section-number">11.3</span> Data Setup</a></li>
  <li><a href="#sec-ml-common-baseline" id="toc-sec-ml-common-baseline" class="nav-link" data-scroll-target="#sec-ml-common-baseline"><span class="header-section-number">11.4</span> Beat the Baseline</a>
  <ul class="collapse">
  <li><a href="#sec-ml-common-baseline-why" id="toc-sec-ml-common-baseline-why" class="nav-link" data-scroll-target="#sec-ml-common-baseline-why"><span class="header-section-number">11.4.1</span> Why do we do this?</a></li>
  <li><a href="#sec-ml-common-baseline-how-much" id="toc-sec-ml-common-baseline-how-much" class="nav-link" data-scroll-target="#sec-ml-common-baseline-how-much"><span class="header-section-number">11.4.2</span> How much better?</a></li>
  </ul></li>
  <li><a href="#sec-ml-common-penalized" id="toc-sec-ml-common-penalized" class="nav-link" data-scroll-target="#sec-ml-common-penalized"><span class="header-section-number">11.5</span> Penalized Linear Models</a>
  <ul class="collapse">
  <li><a href="#sec-ml-common-elasticnet" id="toc-sec-ml-common-elasticnet" class="nav-link" data-scroll-target="#sec-ml-common-elasticnet"><span class="header-section-number">11.5.1</span> Elastic net</a></li>
  <li><a href="#sec-ml-common-penalized-strengths-weaknesses" id="toc-sec-ml-common-penalized-strengths-weaknesses" class="nav-link" data-scroll-target="#sec-ml-common-penalized-strengths-weaknesses"><span class="header-section-number">11.5.2</span> Strengths and weaknesses</a></li>
  <li><a href="#sec-ml-common-penalized-additional" id="toc-sec-ml-common-penalized-additional" class="nav-link" data-scroll-target="#sec-ml-common-penalized-additional"><span class="header-section-number">11.5.3</span> Additional thoughts</a></li>
  </ul></li>
  <li><a href="#sec-ml-common-trees" id="toc-sec-ml-common-trees" class="nav-link" data-scroll-target="#sec-ml-common-trees"><span class="header-section-number">11.6</span> Tree-based Models</a>
  <ul class="collapse">
  <li><a href="#sec-ml-common-trees-lightgbm" id="toc-sec-ml-common-trees-lightgbm" class="nav-link" data-scroll-target="#sec-ml-common-trees-lightgbm"><span class="header-section-number">11.6.1</span> Example with LightGBM</a></li>
  <li><a href="#sec-ml-common-trees-strengths-weaknesses" id="toc-sec-ml-common-trees-strengths-weaknesses" class="nav-link" data-scroll-target="#sec-ml-common-trees-strengths-weaknesses"><span class="header-section-number">11.6.2</span> Strengths and weaknesses</a></li>
  </ul></li>
  <li><a href="#sec-ml-common-dl-nn" id="toc-sec-ml-common-dl-nn" class="nav-link" data-scroll-target="#sec-ml-common-dl-nn"><span class="header-section-number">11.7</span> Deep Learning and Neural Networks</a>
  <ul class="collapse">
  <li><a href="#sec-ml-common-nnet" id="toc-sec-ml-common-nnet" class="nav-link" data-scroll-target="#sec-ml-common-nnet"><span class="header-section-number">11.7.1</span> What is a neural network?</a></li>
  <li><a href="#sec-ml-common-nnet-how" id="toc-sec-ml-common-nnet-how" class="nav-link" data-scroll-target="#sec-ml-common-nnet-how"><span class="header-section-number">11.7.2</span> How do they work?</a></li>
  <li><a href="#sec-ml-common-dl-nn-try" id="toc-sec-ml-common-dl-nn-try" class="nav-link" data-scroll-target="#sec-ml-common-dl-nn-try"><span class="header-section-number">11.7.3</span> Trying it out</a></li>
  <li><a href="#sec-ml-common-dl-nn-strengths-weaknesses" id="toc-sec-ml-common-dl-nn-strengths-weaknesses" class="nav-link" data-scroll-target="#sec-ml-common-dl-nn-strengths-weaknesses"><span class="header-section-number">11.7.4</span> Strengths and weaknesses</a></li>
  </ul></li>
  <li><a href="#sec-ml-common-tuned-ex" id="toc-sec-ml-common-tuned-ex" class="nav-link" data-scroll-target="#sec-ml-common-tuned-ex"><span class="header-section-number">11.8</span> Tuned Example</a></li>
  <li><a href="#sec-ml-common-compare" id="toc-sec-ml-common-compare" class="nav-link" data-scroll-target="#sec-ml-common-compare"><span class="header-section-number">11.9</span> Comparing Models</a></li>
  <li><a href="#sec-ml-common-interpret" id="toc-sec-ml-common-interpret" class="nav-link" data-scroll-target="#sec-ml-common-interpret"><span class="header-section-number">11.10</span> Interpretation</a>
  <ul class="collapse">
  <li><a href="#sec-ml-common-feat-imp" id="toc-sec-ml-common-feat-imp" class="nav-link" data-scroll-target="#sec-ml-common-feat-imp"><span class="header-section-number">11.10.1</span> Feature importance</a></li>
  </ul></li>
  <li><a href="#sec-ml-common-other-models" id="toc-sec-ml-common-other-models" class="nav-link" data-scroll-target="#sec-ml-common-other-models"><span class="header-section-number">11.11</span> Other ML Models for Tabular Data</a></li>
  <li><a href="#sec-ml-common-wrap" id="toc-sec-ml-common-wrap" class="nav-link" data-scroll-target="#sec-ml-common-wrap"><span class="header-section-number">11.12</span> Wrapping Up</a>
  <ul class="collapse">
  <li><a href="#sec-ml-common-thread" id="toc-sec-ml-common-thread" class="nav-link" data-scroll-target="#sec-ml-common-thread"><span class="header-section-number">11.12.1</span> The common thread</a></li>
  <li><a href="#sec-ml-common-choose" id="toc-sec-ml-common-choose" class="nav-link" data-scroll-target="#sec-ml-common-choose"><span class="header-section-number">11.12.2</span> Choose your own adventure</a></li>
  <li><a href="#sec-ml-common-resources" id="toc-sec-ml-common-resources" class="nav-link" data-scroll-target="#sec-ml-common-resources"><span class="header-section-number">11.12.3</span> Additional resources</a></li>
  </ul></li>
  <li><a href="#sec-ml-common-exercise" id="toc-sec-ml-common-exercise" class="nav-link" data-scroll-target="#sec-ml-common-exercise"><span class="header-section-number">11.13</span> Guided Exploration</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/m-clark/book-of-models/edit/dev/ml_common_models.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-ml-common-models" class="quarto-section-identifier"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Common Models in Machine Learning</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="gp-visualization">

</div>
<script src="https://d3js.org/d3.v7.min.js"></script>
<script src="js/gp_visualization.js"></script>
<p></p>
<p>Before really getting into some machine learning models, let’s get one thing straight from the outset: <strong>any model may be used in machine learning</strong>, from a standard linear model to a deep neural network. The key focus in ML is on performance, and generally we’ll go with what works for the situation. This means that the modeler is often less concerned with the interpretation of the model, and more with the ability of the model to predict well on new data. But, as we’ll see, we can do both if desired. In this chapter, we will explore some of the more common machine learning models and techniques.</p>
<section id="sec-ml-common-key-ideas" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="sec-ml-common-key-ideas"><span class="header-section-number">11.1</span> Key Ideas</h2>
<p>The take-home messages from this section include the following:</p>
<ul>
<li>Any model can be used with machine learning.</li>
<li>A good and simple baseline is essential for interpreting your performance results.</li>
<li>You only need a small set of tools (models) to go very far with machine learning.</li>
</ul>
<section id="sec-ml-common-why-matters" class="level3" data-number="11.1.1">
<h3 data-number="11.1.1" class="anchored" data-anchor-id="sec-ml-common-why-matters"><span class="header-section-number">11.1.1</span> Why this matters</h3>
<p>Having the right tools in data science saves time and improves results, and using well-known tools means you’ll have plenty of resources for help. It also allows you to focus more on the data and the problem, rather than the details of the model. A simple model might be all you need, but if you need something more complex, these models can still provide a performance benchmark.</p>
</section>
<section id="sec-ml-common-good-to-know" class="level3" data-number="11.1.2">
<h3 data-number="11.1.2" class="anchored" data-anchor-id="sec-ml-common-good-to-know"><span class="header-section-number">11.1.2</span> Helpful context</h3>
<p>Before diving in, it’d be helpful to be familiar with the following:</p>
<ul>
<li>Linear models, especially linear and logistic regression (<a href="linear_models.html" class="quarto-xref"><span>Chapter 3</span></a> and <a href="generalized_linear_models.html" class="quarto-xref"><span>Chapter 8</span></a>)</li>
<li>Basic machine learning concepts as outlined in <a href="machine_learning.html" class="quarto-xref"><span>Chapter 10</span></a></li>
<li>Model estimation as outlined in <a href="estimation.html" class="quarto-xref"><span>Chapter 6</span></a></li>
</ul>
</section>
</section>
<section id="sec-ml-common-general-approach" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="sec-ml-common-general-approach"><span class="header-section-number">11.2</span> General Approach</h2>
<p> Let’s start with a general approach to machine learning to help us get some bearings. Here is an example outline of the process we could typically take. It incorporates some of the ideas we also cover in other chapters, and we’ll demonstrate most of this in the following sections.</p>
<ul>
<li>Define the problem, including the target variable(s)</li>
<li>Select the model(s) to be explored, including one baseline model</li>
<li>Define the performance objective and metric(s) used for model assessment</li>
<li>Define the search space (parameters, hyperparameters) for those models</li>
<li>Define the search method (optimization)</li>
<li>Implement a validation technique and collect the corresponding performance metrics</li>
<li>Evaluate the chosen model on unseen data</li>
<li>Interpret the results</li>
</ul>
<p>Here is a more concrete example:</p>
<ul>
<li>Define the problem: predict the probability of heart disease given a set of features</li>
<li>Select the model(s) to be used: ridge regression (main model), standard regression with no penalty (baseline)</li>
<li>Define the objective and performance metric(s): RMSE, R-squared</li>
<li>Define the search space (parameters, hyperparameters) for those models: ridge penalty parameter</li>
<li>Define the search method (optimization): grid search</li>
<li>Implement some sort of cross-validation technique: 5-fold cross-validation</li>
<li>Evaluate the results on unseen data: RMSE on test data</li>
<li>Interpret the results: the ridge regression model performed better than the baseline model, and the coefficients tell us something about the nature of the relationship between the features and the target</li>
</ul>
<p>As we go along in this chapter, we’ll see most of this in action. So let’s get to it!</p>
</section>
<section id="sec-ml-common-data-setup" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="sec-ml-common-data-setup"><span class="header-section-number">11.3</span> Data Setup</h2>
<p>For our demonstration here, we’ll use the heart disease dataset. This is a popular ML binary classification problem, where we want to predict whether a patient has heart disease, given information such as age, sex, resting heart rate, etc. (<a href="dataset_descriptions.html#sec-dd-heart-disease-uci" class="quarto-xref"><span>Section D.3</span></a>).</p>
<p><em>There are two forms of the data that we’ll use</em>: one which is mostly in raw form, and one that is purely numeric, where the categorical features are dummy coded and where numeric variables have been standardized (<a href="data.html#sec-data-transformations" class="quarto-xref"><span>Section 14.2</span></a>). The purely numeric version will allow us to forgo any additional data processing for some model/package implementations (like penalized regression). We have also dropped the handful of rows with missing values, even though some techniques, like tree-based models, naturally handle missing values. This form of the data will allow us to use any model and make direct comparisons among them later.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>For Python we’ll go ahead and do all the imports needed for this chapter.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Basic data packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Models</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightgbm <span class="im">import</span> LGBMClassifier</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Metrics and more</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> (</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    cross_validate, RandomizedSearchCV, train_test_split</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> PartialDependenceDisplay</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df_heart <span class="op">=</span> pd.read_csv(<span class="st">'https://tinyurl.com/heartdiseaseprocessed'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df_heart_num <span class="op">=</span> pd.read_csv(<span class="st">'https://tinyurl.com/heartdiseaseprocessednumeric'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># convert appropriate features to categorical</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>non_num_cols <span class="op">=</span> df_heart.select_dtypes(exclude<span class="op">=</span><span class="st">'number'</span>).columns</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>df_heart[non_num_cols] <span class="op">=</span> df_heart[non_num_cols].astype(<span class="st">'category'</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_heart_num.drop(columns<span class="op">=</span>[<span class="st">'heart_disease'</span>]).to_numpy()</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_heart_num[<span class="st">'heart_disease'</span>].to_numpy()</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>prevalence <span class="op">=</span> np.mean(y)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>majority <span class="op">=</span> np.<span class="bu">max</span>([prevalence, <span class="dv">1</span> <span class="op">-</span> prevalence])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df_heart <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="st">'https://tinyurl.com/heartdiseaseprocessed'</span>) <span class="sc">|&gt;</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.character), as.factor))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>df_heart_num <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="st">'https://tinyurl.com/heartdiseaseprocessednumeric'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># for use with for mlr3</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> df_heart_num <span class="sc">|&gt;</span> </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span> </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">heart_disease =</span> <span class="fu">factor</span>(heart_disease)) <span class="sc">|&gt;</span> </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    janitor<span class="sc">::</span><span class="fu">clean_names</span>() <span class="co"># remove some symbols</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>prevalence <span class="ot">=</span> <span class="fu">mean</span>(df_heart_num<span class="sc">$</span>heart_disease)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>majority <span class="ot">=</span> <span class="fu">pmax</span>(prevalence, <span class="dv">1</span> <span class="sc">-</span> prevalence)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p>In this data, roughly 46% suffered from heart disease, so if we’re interested in accuracy, we could get 54% correct by just guessing the majority class of no disease. Hopefully we can do better than that!</p>
<p>One last thing, as we go along, performance metrics will vary depending on your setup (e.g., Python vs.&nbsp;R), package versions used, and other things. As such, your results may not look exactly like these, and that’s okay! Your results should still be similar, and the important thing is to understand the concepts and how to apply them to your own data.</p>
</section>
<section id="sec-ml-common-baseline" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="sec-ml-common-baseline"><span class="header-section-number">11.4</span> Beat the Baseline</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/ml-beat_the_baseline.svg" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Hypothetical model comparison.</figcaption>
</figure>
</div>
<p> Before getting carried away with models, we should have a good reference point for performance – a <strong>baseline model</strong>. The baseline model should serve as a way to gauge how much better your model performs over one that is simpler, probably more computationally efficient, more interpretable, and is still <em>viable</em>. It could also be a model that is sufficiently complex to capture something about the data you are exploring, but not as complex as the models you’re also interested in.</p>
<p>Take a classification model, for example. In this case we might use a logistic regression as a baseline. It is a viable model to begin answering some questions, and get a sense of performance possibilities, but it is often too simple to be adequately performant for many situations. We should be able to do better with more complex models, or if we can’t, there is little justification for using them.</p>
<section id="sec-ml-common-baseline-why" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1" class="anchored" data-anchor-id="sec-ml-common-baseline-why"><span class="header-section-number">11.4.1</span> Why do we do this?</h3>
<p>Having a baseline model can help you avoid wasting time and resources implementing more complex models, and to avoid mistakenly thinking performance is better than expected. It is probably rare, but sometimes relationships for the selected features and target are mostly or nearly linear and have little interaction. In this case, no amount of fancy modeling will make complex feature targets exist if they don’t already. Also, if our baseline is a more complex model that actually incorporates nonlinear relationships and interactions (e.g., a GAMM), you’ll often find that the more complex models often don’t significantly improve on it. As a last example, in time series settings, a <em>moving average</em> can often be a difficult baseline to beat, so it can be a good starting point.</p>
<p>So you may find that the initial baseline model is good enough for your purposes, and you can then move on to other problems to solve, like acquiring data that is more predictive. This is especially true if you are working in a situation with limited time and resources.</p>
</section>
<section id="sec-ml-common-baseline-how-much" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2" class="anchored" data-anchor-id="sec-ml-common-baseline-how-much"><span class="header-section-number">11.4.2</span> How much better?</h3>
<p>In many settings, it often isn’t enough to merely beat the baseline model. Your model should perform <em>statistically</em> better. For instance, if your advanced model accuracy is 75% and your baseline model’s accuracy is 73%, that’s great. But, it’s good to check if this 2% difference is statistically significant. Remember, accuracy and other metrics are <em>estimates</em> and come with uncertainty<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. This means you can get a ranged estimate for them, as well as test whether they are different from one another. <a href="#tbl-prop-test-r" class="quarto-xref">Table&nbsp;<span>11.1</span></a> shows an example comparison of 75% vs.&nbsp;73% accuracy at different sample sizes. If the difference is not statistically significant, then it’s possible you should stick with the baseline model, or maybe try a different approach to compete with it. This is because such a result means that the next time you run the model on new data, the baseline may actually perform better, or at least you can’t be sure that it won’t.</p>
<div class="cell">
<div id="tbl-prop-test-r" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-prop-test-r-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;11.1: Interval Estimates for Accuracy Differences
</figcaption>
<div aria-describedby="tbl-prop-test-r-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="halbzmbunb" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
#halbzmbunb table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#halbzmbunb thead, #halbzmbunb tbody, #halbzmbunb tfoot, #halbzmbunb tr, #halbzmbunb td, #halbzmbunb th {
  border-style: none;
}

#halbzmbunb p {
  margin: 0;
  padding: 0;
}

#halbzmbunb .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#halbzmbunb .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#halbzmbunb .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#halbzmbunb .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#halbzmbunb .gt_heading {
  background-color: #FFFFFF;
  text-align: left;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#halbzmbunb .gt_bottom_border {
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#halbzmbunb .gt_col_headings {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#halbzmbunb .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#halbzmbunb .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#halbzmbunb .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#halbzmbunb .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#halbzmbunb .gt_column_spanner {
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#halbzmbunb .gt_spanner_row {
  border-bottom-style: hidden;
}

#halbzmbunb .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#halbzmbunb .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#halbzmbunb .gt_from_md > :first-child {
  margin-top: 0;
}

#halbzmbunb .gt_from_md > :last-child {
  margin-bottom: 0;
}

#halbzmbunb .gt_row {
  padding-top: 7px;
  padding-bottom: 7px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#halbzmbunb .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#halbzmbunb .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#halbzmbunb .gt_row_group_first td {
  border-top-width: 2px;
}

#halbzmbunb .gt_row_group_first th {
  border-top-width: 2px;
}

#halbzmbunb .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#halbzmbunb .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#halbzmbunb .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#halbzmbunb .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#halbzmbunb .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#halbzmbunb .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#halbzmbunb .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#halbzmbunb .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#halbzmbunb .gt_table_body {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #FFFFFF;
}

#halbzmbunb .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#halbzmbunb .gt_footnote {
  margin: 0px;
  font-size: 9px;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#halbzmbunb .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#halbzmbunb .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#halbzmbunb .gt_left {
  text-align: left;
}

#halbzmbunb .gt_center {
  text-align: center;
}

#halbzmbunb .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#halbzmbunb .gt_font_normal {
  font-weight: normal;
}

#halbzmbunb .gt_font_bold {
  font-weight: bold;
}

#halbzmbunb .gt_font_italic {
  font-style: italic;
}

#halbzmbunb .gt_super {
  font-size: 65%;
}

#halbzmbunb .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#halbzmbunb .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#halbzmbunb .gt_indent_1 {
  text-indent: 5px;
}

#halbzmbunb .gt_indent_2 {
  text-indent: 10px;
}

#halbzmbunb .gt_indent_3 {
  text-indent: 15px;
}

#halbzmbunb .gt_indent_4 {
  text-indent: 20px;
}

#halbzmbunb .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="true" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="Sample Size">Sample Size</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="Lower Bound">Lower Bound</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="Upper Bound">Upper Bound</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="p-value">p-value</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="Sample_Size" class="gt_row gt_right" style="font-family: 'Source Sans Pro'; font-weight: 400;">1000</td>
<td headers="Lower" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">−0.02</td>
<td headers="Upper" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.06</td>
<td headers="p_value" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.31</td></tr>
    <tr><td headers="Sample_Size" class="gt_row gt_right" style="font-family: 'Source Sans Pro'; font-weight: 400;">10000</td>
<td headers="Lower" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.01</td>
<td headers="Upper" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.03</td>
<td headers="p_value" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.00</td></tr>
  </tbody>
  
  <tfoot class="gt_footnotes">
    <tr>
      <td class="gt_footnote" colspan="4"> Statistics regard the difference in proportions of .75 and .73.</td>
    </tr>
  </tfoot>
</table>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>That said, in some situations <em>any</em> performance increase is worth it, and even if we can’t be certain a result is statistically better, any sign of improvement is worth pursuing. For example, if you are trying to predict the next word in a sentence, and your baseline is 70% accurate, and your new model is 72% accurate, that may be significant in terms of user experience. You should still try and show that this is a consistent increase and not a fluke if possible. In other settings, you’ll need to make sure the cost is worth it. Is 2% worth millions of dollars? Six months of research? These are among many of the practical considerations you may have to make as well. </p>
</section>
</section>
<section id="sec-ml-common-penalized" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="sec-ml-common-penalized"><span class="header-section-number">11.5</span> Penalized Linear Models</h2>
<p> So let’s get on with some models already! Let’s use the classic linear model as our starting point for ML. We show explicitly how to estimate models like lasso and ridge regression in <a href="estimation.html#sec-estim-penalty" class="quarto-xref"><span>Section 6.8</span></a>. Those work well as a baseline, and so should be in your ML modeling toolbox.</p>
<section id="sec-ml-common-elasticnet" class="level3" data-number="11.5.1">
<h3 data-number="11.5.1" class="anchored" data-anchor-id="sec-ml-common-elasticnet"><span class="header-section-number">11.5.1</span> Elastic net</h3>
<p>Another common linear model approach is <strong>elastic net</strong>, which we also saw in <a href="machine_learning.html" class="quarto-xref"><span>Chapter 10</span></a>. It combines two techniques: lasso and ridge regression. We demonstrate the lasso and ridge penalties in <a href="estimation.html#sec-estim-penalty" class="quarto-xref"><span>Section 6.8</span></a>, but all you have to know is that elastic net combines the two penalties: one for lasso and one for ridge, along with a standard objective function for a numeric or categorical target. The relative proportion of the two penalties is controlled by a mixing parameter, and the optimal value for it is determined by cross-validation. So for example, you might end up with a 75% lasso penalty and 25% ridge penalty. In the end though, it’s just a slightly fancier logistic regression!</p>
<p>Let’s apply this to the heart disease data. We are only doing simple cross-validation here to get a better performance assessment, but you are more than welcome to tune both the penalty parameter and the mixing ratio as we have demonstrated before (<a href="machine_learning.html#sec-ml-tuning" class="quarto-xref"><span>Section 10.7</span></a>). We’ll revisit hyperparameter tuning toward the end of this chapter.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>model_elastic <span class="op">=</span> LogisticRegression(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    penalty <span class="op">=</span> <span class="st">'elasticnet'</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    solver <span class="op">=</span> <span class="st">'saga'</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    l1_ratio <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    random_state <span class="op">=</span> <span class="dv">42</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    max_iter <span class="op">=</span> <span class="dv">10000</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>model_elastic_cv <span class="op">=</span> cross_validate(</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    model_elastic,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    X,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    scoring <span class="op">=</span> <span class="st">'accuracy'</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(model_elastic_cv) # default output</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training accuracy:  0.828 
Guessing:  0.539</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>tsk_elastic <span class="ot">=</span> <span class="fu">as_task_classif</span>(</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    X,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">target =</span> <span class="st">"heart_disease"</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>model_elastic <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classif.cv_glmnet"</span>, </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">nfolds =</span> <span class="dv">5</span>, </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">type.measure =</span> <span class="st">"class"</span>, </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>model_elastic_cv <span class="ot">=</span> <span class="fu">resample</span>(</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">task =</span> tsk_elastic,</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">learner =</span> model_elastic,</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co"># model_elastic_cv$aggregate(msr('classif.acc')) # default output</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training Accuracy: 0.825
Guessing: 0.539</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>So we’re starting off with what seems to be a good model. Our average accuracy across the validation sets is definitely doing better than guessing, with a performance increase of more than 50%!</p>
</section>
<section id="sec-ml-common-penalized-strengths-weaknesses" class="level3" data-number="11.5.2">
<h3 data-number="11.5.2" class="anchored" data-anchor-id="sec-ml-common-penalized-strengths-weaknesses"><span class="header-section-number">11.5.2</span> Strengths and weaknesses</h3>
<p>Let’s take a moment to consider the strengths and weaknesses of penalized regression models.</p>
<p><strong>Strengths</strong></p>
<ul>
<li>Intuitive approach. In the end, it’s still just a standard regression model you’re already familiar with.</li>
<li>Widely used for many problems. Lasso/Ridge/ElasticNet would be fine to use in any setting you would use linear or logistic regression.</li>
<li>A good baseline for tabular data problems.</li>
</ul>
<p><strong>Weaknesses</strong></p>
<ul>
<li>Does not automatically seek out interactions and nonlinearity, and as such will generally not be as predictive as other techniques.</li>
<li>Variables have to be scaled or results will largely reflect data types.</li>
<li>May have interpretability issues with correlated features.</li>
<li>Relatively weaker performance compared to other models, especially in high-dimensional settings.</li>
</ul>
</section>
<section id="sec-ml-common-penalized-additional" class="level3" data-number="11.5.3">
<h3 data-number="11.5.3" class="anchored" data-anchor-id="sec-ml-common-penalized-additional"><span class="header-section-number">11.5.3</span> Additional thoughts</h3>
<p>Using penalized regression is a very good default method in the tabular data setting, and it is something to strongly consider for more interpretation-focused model settings. These approaches predict better on new data than their standard, non-regularized complements, so they provide a nice balance between interpretability and predictive power. However, in general they are not going to be as strong of a method as others typically used in the machine learning world, and they may not even be competitive without a lot of feature engineering. If prediction is all you care about, you’ll likely need something else. Now let’s see if we can do better with other models!</p>
<p></p>
</section>
</section>
<section id="sec-ml-common-trees" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="sec-ml-common-trees"><span class="header-section-number">11.6</span> Tree-based Models</h2>
<p> </p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/tree_complex.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>Let’s move beyond standard linear models and get into a notably different type of approach. Tree-based methods are a class of models that are very popular in machine learning contexts, and for good reason, they work <em>very</em> well. To get a sense of how they work, consider the following classification example where we want to predict a binary target as ‘Yes’ or ‘No’.</p>
<div id="fig-tree" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/tree.svg" class="img-fluid figure-img" style="width:30.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.1: Simple classification tree.
</figcaption>
</figure>
</div>
<p>We have two numeric features, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. At the start, we take <span class="math inline">\(X_1\)</span> and make a split at the value of 5. Any observation less than 5 on <span class="math inline">\(X_1\)</span> goes to the right with a prediction of <em>No</em>. Any observation greater than or equal to 5 goes to the left, where we then split based on values of <span class="math inline">\(X_2\)</span>. Any observation less than 3 goes to the right with a prediction of <em>Yes</em>. Any observation greater than or equal to 3 goes to the left with a prediction of <em>No</em>. So in the end, we see that an observation that is relatively lower on <span class="math inline">\(X_1\)</span>, or relatively higher on both, results in a prediction of <em>No</em>. On the other hand, an observation that is high on <span class="math inline">\(X_1\)</span> and low on <span class="math inline">\(X_2\)</span> results in a prediction of <em>Yes</em>.</p>
<p>This is a simple example, but it illustrates the core idea of a tree-based model, where the <strong>tree</strong> reflects the total process, and <strong>branches</strong> are represented by the splits going down, ultimately ending at <strong>leaves</strong> where predictions are made. We can also think of the tree as a series of <code>if-then</code> statements, where we start at the top and work our way down until we reach a leaf node, which is a prediction for all observations that qualify for that leaf.</p>
<p>A single tree would likely be the most interpretable model we could probably come up with. Furthermore, it incorporates nonlinearities through multiple branches on a single feature, interactions by branching across different features, and feature selection by excluding features that do not result in useful splits for the objective, all in one.</p>
<p>However, a single tree is not a very stable model unfortunately, and so it does not generalize well. For example, just a slight change in data, or even just starting with a different feature, might produce a very different tree<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Even though predictions could be similar, model interpretation would be very different.</p>
<p> The solution to that problem is straightforward though. By using the power of a bunch of trees, we can get predictions for each observation from each tree, and then average the predictions, resulting in a much more stable estimate. This is the concept behind both <strong>random forests</strong> (RF) and <strong>gradient boosting</strong> (GB), which can be seen as different algorithms to produce a bunch of trees. They are also considered types of <strong>ensemble models</strong>, which are models that combine the predictions of multiple models, to ultimately produce a single prediction for each observation. In this case each tree serves as a model.</p>
<p>Random forests and boosting methods are very easy to implement, to a point. However, there are typically several hyperparameters to consider for tuning. Here are just a few to think about:</p>
<ul>
<li>Number of trees</li>
<li>Learning rate (GB)</li>
<li>Maximum depth of each tree</li>
<li>Minimum number of observations in each leaf</li>
<li>Number of features to consider at each tree/split</li>
<li>Regularization parameters (GB)</li>
<li>Out-of-bag sample size (RF)</li>
</ul>
<p>The number of trees is simply how many trees you want to build, and it is a key parameter setting for both RF and GB. For boosting models, the number of trees and learning rate play off of each other. Having more trees allows for a smaller rate<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, which might improve the model but will take longer to train. However, it can lead to overfitting if other steps are not taken.</p>
<p>The depth of each tree refers to how many levels we allow the model to branch out and is a crucial parameter. It controls the complexity of each tree, and thus the complexity of the overall model – less depth helps to avoid overfitting, but if the depth is too shallow, you won’t be able to capture the nuances of the data. The minimum number of observations required for each leaf is also important for similar reasons. A lower number will allow for more complex trees, while a higher number will result in simpler trees.</p>
<p>It’s also generally a good idea to take a random sample of features for each tree (or possibly even each branch), to also help reduce overfitting, but it’s not obvious what proportion to take. The regularization parameters<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> are typically less important in practice, but can help reduce overfitting as in other modeling circumstances we’ve talked about. As with hyperparameters in other model settings, you’ll use something like cross-validation to settle on final values.</p>
<p></p>
<section id="sec-ml-common-trees-lightgbm" class="level3" data-number="11.6.1">
<h3 data-number="11.6.1" class="anchored" data-anchor-id="sec-ml-common-trees-lightgbm"><span class="header-section-number">11.6.1</span> Example with LightGBM</h3>
<p>Here is an example of gradient boosting with the heart disease data. We’ll explicitly set some of the parameters, and use 5-fold cross-validation to estimate performance.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>Although boosting methods are available in <span class="pack">scikit-learn</span> for Python, in general we recommend using the <span class="pack">lightgbm</span> or <span class="pack">xgboost</span> packages directly for boosting, as both have a sklearn API (as demonstrated). Also, they both provide R and Python implementations of the package, making it easy to not lose your place when switching between languages. We’ll use <span class="pack">lightgbm</span> here<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model_boost <span class="op">=</span> LGBMClassifier(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    n_estimators <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> <span class="fl">1e-3</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    max_depth <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>model_boost_cv <span class="op">=</span> cross_validate(</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    model_boost,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    df_heart.drop(columns<span class="op">=</span><span class="st">'heart_disease'</span>),</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    df_heart[<span class="st">'heart_disease'</span>],</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(model_boost_cv)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training accuracy:  0.835 
Guessing:  0.539</code></pre>
</div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>Note that as of writing, the <span class="pack">mlr3</span> requires one of the extended packages for its implementation of lightgbm, and so we’ll use the <span class="pack">mlr3extralearners</span> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># for lightgbm, you need mlr3extralearners and lightgbm package installed</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># it is available from github via:</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># remotes::install_github("mlr-org/mlr3extralearners@*release")</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3extralearners) </span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define task</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># For consistency we use X, but lgbm can handle factors and missing data </span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># and so we can use the original df_heart if desired</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>tsk_boost <span class="ot">=</span> <span class="fu">as_task_classif</span>(</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    df_heart,                   <span class="co"># can use the 'raw' data</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">target =</span> <span class="st">"heart_disease"</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>model_boost <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classif.lightgbm"</span>,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">num_iterations =</span> <span class="dv">1000</span>,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">learning_rate =</span> <span class="fl">1e-3</span>,</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="dv">5</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>model_boost_cv <span class="ot">=</span> <span class="fu">resample</span>(</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">task =</span> tsk_boost,</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">learner =</span> model_boost,</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training Accuracy: 0.828
Guessing: 0.539</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>So here we have a model that is also performing well, though not significantly better or worse than our elastic net model. For most tabular data situations, we’d expect boosting to do better, but this shows why we want a good baseline or simpler model for comparison. We’ll revisit hyperparameter tuning using this model later.</p>
<!-- If you'd like to see an example of how we could implement a form  boosting by hand, see @app-boosting. -->
<!-- TODO: ADD GBLINEAR BY HAND TO APPENDIX for web version in future -->
<p></p>
</section>
<section id="sec-ml-common-trees-strengths-weaknesses" class="level3" data-number="11.6.2">
<h3 data-number="11.6.2" class="anchored" data-anchor-id="sec-ml-common-trees-strengths-weaknesses"><span class="header-section-number">11.6.2</span> Strengths and weaknesses</h3>
<p>Random forests and boosting methods, though not new, are still ‘state of the art’ in terms of performance on tabular data like the type we’ve been using for our demos here. You’ll often find that it will usually take considerable effort to beat them.</p>
<p><strong>Strengths</strong></p>
<ul>
<li>A single tree is highly interpretable.</li>
<li>Relatively good prediction out of the box.</li>
<li>Easily incorporates features of different types, regardless of scale or whether it’s categorical.</li>
<li>Tolerance to irrelevant features.</li>
<li>Some tolerance to correlated inputs.</li>
<li>Handling of missing values. Missing values are just another value to potentially split on<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</li>
</ul>
<p><strong>Weaknesses</strong></p>
<ul>
<li>Honestly few, but like all techniques, it might be relatively less predictive in certain situations. There is <a href="https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/">no free lunch</a>.</li>
<li>It does take more effort to tune relative to linear model methods, so this wouldn’t be the best choice for a baseline model.</li>
<li>Predictions, though relatively accurate, will be less smooth relative to some models like GAMs, and a smooth result may be more desirable in some settings.</li>
</ul>
<p></p>
</section>
</section>
<section id="sec-ml-common-dl-nn" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="sec-ml-common-dl-nn"><span class="header-section-number">11.7</span> Deep Learning and Neural Networks</h2>
<p> </p>
<div id="fig-basic-nn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-basic-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/nn_basic.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-basic-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.2: Neural network.
</figcaption>
</figure>
</div>
<p><strong>Deep learning has fundamentally transformed the world of data science, and, in many ways, the world itself</strong>. It has been used to solve problems in image detection, speech recognition, natural language processing, and more, from assisting with cancer diagnosis, to writing entire novels, providing self-driving cars, and even helping the formerly blind see. It is an extremely powerful tool.</p>
<p> For tabular data, however, the story is a bit different. Here, deep learning has consistently struggled to outperform models like boosting and even penalized regression in many cases. But while it is not always the best option, it should be in your modeling toolbox, if only because it potentially can be the most performant model and may well become the dominant model for tabular data in the future. Here we’ll provide a brief overview of the key concepts behind neural networks, the underlying approach to deep learning, and then demonstrate how to implement a simple neural network to get things started.</p>
<section id="sec-ml-common-nnet" class="level3" data-number="11.7.1">
<h3 data-number="11.7.1" class="anchored" data-anchor-id="sec-ml-common-nnet"><span class="header-section-number">11.7.1</span> What is a neural network?</h3>
<p><strong>Neural networks</strong> form the basis of deep learning models. They have actually been around a while – both <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html">computationally and conceptually going back decades</a><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a><sup>,</sup> <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Like other models, they are computational tools that help us understand how to get outputs from inputs. However, they weren’t quickly adopted due to computing limitations, similar to the slow adoption of Bayesian methods. But now, neural networks, or deep learning more generally, have recently become the go-to method for many problems.</p>
</section>
<section id="sec-ml-common-nnet-how" class="level3" data-number="11.7.2">
<h3 data-number="11.7.2" class="anchored" data-anchor-id="sec-ml-common-nnet-how"><span class="header-section-number">11.7.2</span> How do they work?</h3>
<p>At its core, a neural network can be seen as a series of matrix multiplications and other operations to produce combinations of features, and ultimately a desired output. We’ve been talking about inputs and outputs since the beginning (<a href="models.html#sec-lm-relationships" class="quarto-xref"><span>Section 2.3</span></a>), but neural networks like to put a lot more in between the inputs and outputs than we’ve seen with other models. However, many of the key operations are often no different than what we’ve done with a basic linear model, and they sometimes even simpler! But the combinations of features they produce can represent many aspects of the data that are not easily captured by simpler models.</p>
<p>One notable difference from models we’ve been seeing is that neural networks implement <em>multiple combinations of features</em>, where each combination is referred to as a hidden <strong>node</strong> or unit<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. In a neural network, each feature has a weight (or coefficient), just like in a linear model of the type we’ve used before. These features are multiplied by their weights and then added together. But we actually create multiple such combinations, as depicted in the ‘H’ or ‘hidden’ nodes in the following visualization.</p>
<div id="fig-first-layer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-first-layer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/nn_first_hidden_layer.svg" class="img-fluid figure-img" style="width:33.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-first-layer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.3: The first hidden layer.
</figcaption>
</figure>
</div>
<p> The next phase is where things can get more interesting. We take those hidden units and add in nonlinear transformations before moving deeper into the network. The transformations applied are typically referred to as <strong>activation functions</strong><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. So, the output of the current (typically linear) part is transformed in a way that allows the model to incorporate nonlinearities. While this might sound new, this is just like how we use link functions in generalized linear models (<a href="generalized_linear_models.html#sec-glm-distributions" class="quarto-xref"><span>Section 8.2</span></a>). Furthermore, these multiple combinations also allow us to incorporate interactions between features.</p>
<p> </p>
<div id="fig-activate" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-activate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/nn_activation2.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-activate-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.4: Activation function transforms node output before the next layer.
</figcaption>
</figure>
</div>
<p>But we can go even further! We can add more layers, and more nodes in each layer, even different types of layers, to create a <strong>deep neural network</strong>. We can also add components specific to certain types of processing, have some parts of the network only connected to certain other parts, apply specific computations to specific components, and more. The complexity really is only limited by our imagination, <em>and computational capacity</em>! This is what helps make neural networks so powerful. Given enough nodes, layers, and components, they can approximate <strong><em>any</em></strong> function, which could include the true function that connects our features to the target. Practically though, the feature inputs become an output or multiple outputs that can then be assessed in the same ways as other models.</p>
<div id="fig-complex-nn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-complex-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/nn_deep.svg" class="img-fluid figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-complex-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.5: Complex neural network.
</figcaption>
</figure>
</div>
<p></p>
<p> Before getting too carried away, let’s simplify things a bit by returning to some familiar ground. Consider a logistic regression model. There we take the linear combination of features and weights, and then apply the sigmoid function (inverse logit) to it, and that is the output of the model that we compare to our observed target and calculate an objective function.</p>
<p>We can revisit a plot we saw earlier (<a href="linear_models.html#fig-graph-logistic" class="quarto-xref">Figure&nbsp;<span>3.7</span></a>) to make things more concrete. The input features are <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, and <span class="math inline">\(X_3\)</span>, and the output is the probability of a positive outcome of a binary target. The weights are <span class="math inline">\(w_1\)</span>, <span class="math inline">\(w_2\)</span>, and <span class="math inline">\(w_3\)</span>, and the bias<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> is <span class="math inline">\(w_0\)</span>. The hidden node is just our linear predictor which we can create via matrix multiplication of the feature matrix and weights. The sigmoid function is the activation function, and the output is the probability of the chosen label.</p>
<div id="fig-logreg-nn" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-logreg-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/nn_logreg.svg" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-logreg-nn-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.6: Logistic regression as a neural network with a single hidden layer with one node, and sigmoid activation
</figcaption>
</figure>
</div>
<p>This shows that we can actually think of logistic regression as a very simple neural network, with a linear combination of the inputs as a single hidden node and a sigmoid activation function adding the nonlinear transformation. Indeed, the earliest <strong>multilayer perceptron</strong> models were just composed of multiple layers of logistic regressions!</p>
<p></p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="GAMs and Neural Networks">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
GAMs and Neural Networks
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>You can think of neural networks as nonlinear extensions of linear models. Regression approaches like GAMs and Gaussian process regression can be seen as <a href="https://arxiv.org/abs/1711.00165">approximations to neural networks</a> (see also <span class="citation" data-cites="rasmussen_gaussian_2005">Rasmussen and Williams (<a href="references.html#ref-rasmussen_gaussian_2005" role="doc-biblioref">2005</a>)</span>), bridging the gap between the simpler, and more interpretable linear model, and black box of a deep neural network. This brings us back to having a good baseline. If you know some simpler tools that can approximate more complex ones, you can often get ‘good enough’ results with the simpler models.</p>
</div>
</div>
</div>
</section>
<section id="sec-ml-common-dl-nn-try" class="level3" data-number="11.7.3">
<h3 data-number="11.7.3" class="anchored" data-anchor-id="sec-ml-common-dl-nn-try"><span class="header-section-number">11.7.3</span> Trying it out</h3>
<p> The neural network model we’ll use is a <strong>multilayer perceptron</strong> (MLP), which is a model like the one we’ve been showing. It consists of multiple hidden layers of potentially varying sizes, and we can incorporate activation functions as we see fit.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="More on Neural Networks for Tabular Data">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
More on Neural Networks for Tabular Data
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Be aware that this would be considered a bare minimum approach for a neural network, and generally you’d need to do more, even for standard tabular data. To begin with, you’d want to tune the <strong>architecture</strong>, or structure of hidden layers. For example, you might want to try more layers, as well as ‘wider’ layers, or more nodes per layer. Also, we’d usually want to use <strong>embeddings</strong> for categorical features as opposed to the one-hot approach used here (<a href="data.html#sec-data-cat" class="quarto-xref"><span>Section 14.2.2</span></a>)<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>.</p>
</div>
</div>
</div>
<p>For our demo, we’ll use the numeric heart disease data with one-hot encoded categorical features. For our architecture, we’ll use three hidden layers with 200 nodes each. As noted, these and other settings are hyperparameters that you’d normally prefer to tune, but we’ll just set them as fixed parameters.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<p>For our demonstration we’ll use <span class="pack">sklearn</span>’s built-in <code>MLPClassifier</code>. We set the learning rate to 0.001. We set an <strong>adaptive learning rate</strong>, which is a way to automatically adjust the learning rate as the model trains. The ReLU activation function is default. We’ll also use the <strong>nesterov momentum</strong> approach, which is a modification to an SGD variant (Adam). We use a <strong>warm start</strong>, which allows us to train the model in stages, and is useful for allowing the algorithm to stop before the maximum number of iterations. We’ll also set the <strong>validation fraction</strong>, which is the proportion of data to use for the validation set. And finally, we’ll use <strong>shuffle</strong> to shuffle each batch used during the SGD approach (<a href="estimation.html#sec-estim-opt-algos-sgd" class="quarto-xref"><span>Section 6.10.3</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model_mlp <span class="op">=</span> MLPClassifier(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    hidden_layer_sizes <span class="op">=</span> (<span class="dv">200</span>, <span class="dv">200</span>, <span class="dv">200</span>),  </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    learning_rate <span class="op">=</span> <span class="st">'adaptive'</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    learning_rate_init <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    shuffle <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    random_state <span class="op">=</span> <span class="dv">123</span>,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    warm_start <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    nesterovs_momentum <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    validation_fraction <span class="op">=</span>  <span class="fl">.2</span>,</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># with the above settings, this will take a few seconds</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>model_mlp_cv <span class="op">=</span> cross_validate(</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    model_mlp, </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    X, </span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    y, </span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.DataFrame(model_mlp_cv) # default output</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training accuracy:  0.818 
Guessing:  0.539</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>For R, we’ll use <span class="pack">mlr3torch</span>, which calls <span class="pack">pytorch</span> directly under the hood. We’ll use the same architecture as was done with the Python example. It uses the <strong>ReLU</strong> activation function as a default. We’ll also use the <strong>Adam</strong> SGD variant as the optimizer, which is a popular choice in deep learning models, and the default for the <span class="pack">sklearn</span> approach. We’ll use <strong>cross-entropy</strong> as the loss function, which is the same as the log loss objective function used in logistic regression and other ML classification models. We use a <strong>batch size</strong> of 16. Batch size is the number of observations to use for each <a href="https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network">batch of training</a>. We’ll also use <strong>epochs</strong> of 50, which is the number of times to train on the entire dataset (probably way more than necessary). We’ll also use <strong>predict type</strong> of <strong>prob</strong>, which is the type of prediction to make. Finally, we’ll use both <strong>logloss</strong> and <strong>accuracy</strong> as the metrics to track. As specified, this took over a minute.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3torch)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>learner_mlp <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classif.mlp"</span>,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># defining network parameters</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">neurons =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">200</span>, <span class="dv">200</span>),</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># training parameters</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">16</span>,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">50</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Defining the optimizer, loss, and callbacks</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="fu">t_opt</span>(<span class="st">"adam"</span>, <span class="at">lr =</span> <span class="fl">1e-3</span>),</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="fu">t_loss</span>(<span class="st">"cross_entropy"</span>),</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Measures to track</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">measures_train =</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.logloss"</span>)),</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">validate =</span> .<span class="dv">1</span>,</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">measures_valid =</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"classif.logloss"</span>, <span class="st">"classif.ce"</span>)),</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict type (required by logloss)</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">predict_type =</span> <span class="st">"prob"</span>,</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">123</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>tsk_mlp <span class="ot">=</span> <span class="fu">as_task_classif</span>(</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> X,</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">target =</span> <span class="st">'heart_disease'</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="co"># this will take a few seconds depending on your chosen settings and hardware</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>model_mlp_cv <span class="ot">=</span> <span class="fu">resample</span>(</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">task =</span> tsk_mlp,</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">learner =</span> learner_mlp,</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>),</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>model_mlp_cv<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>)) <span class="co"># default output</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training Accuracy: 0.842
Guessing: 0.539</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>This model actually did pretty well, and we’re on par with our accuracy as we were with the other two models. This is somewhat surprising given the nature of the data, small number of observations with different data types, a type of situation in which neural networks don’t usually do as well as others. Just goes to show, you never know until you try!</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Deep and Wide">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Deep and Wide
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A now relatively old question in deep learning is what is the better approach: deep networks, with more layers, or extremely wide (lots of neurons) and fewer layers? The answer is that it can depend on the problem, but in general, deep networks are more efficient and easier to train, and <a href="https://stats.stackexchange.com/questions/222883/why-are-neural-networks-becoming-deeper-but-not-wider">will generalize better</a>. Deeper networks have the ability to build upon what the previous layers have learned, basically compartmentalizing different parts of the task to learn. More important to the task is creating an architecture that is able to learn the appropriate aspects of the data, and generalize well.</p>
</div>
</div>
</div>
<p></p>
</section>
<section id="sec-ml-common-dl-nn-strengths-weaknesses" class="level3" data-number="11.7.4">
<h3 data-number="11.7.4" class="anchored" data-anchor-id="sec-ml-common-dl-nn-strengths-weaknesses"><span class="header-section-number">11.7.4</span> Strengths and weaknesses</h3>
<p>So why might we want to use neural networks for tabular data? The main reason is that they can be the most performant model and can potentially capture the most complex relationships in the data. They can also be used for a wide variety of data types and tasks. However, they are also the most complex model and can be the most difficult to tune and interpret.</p>
<p><strong>Strengths</strong></p>
<ul>
<li>Good prediction generally.</li>
<li>Incorporates the predictive power of different combinations of inputs.</li>
<li>Some tolerance to correlated inputs.</li>
<li>Batch processing and parallelization of many operations makes it very efficient for large datasets.</li>
<li>Can be used for even standard GLM approaches.</li>
<li>Can be added as a component to other deep learning models (e.g., LLMs that are handling text input).</li>
</ul>
<p><strong>Weaknesses</strong></p>
<ul>
<li>Susceptible to irrelevant features.</li>
<li>Doesn’t consistently outperform other methods that are easier to implement on tabular data.</li>
</ul>
<p></p>
</section>
</section>
<section id="sec-ml-common-tuned-ex" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="sec-ml-common-tuned-ex"><span class="header-section-number">11.8</span> Tuned Example</h2>
<p> We noted in the chapter on machine learning concepts that there are often multiple hyperparameters we are concerned with for a given model (<a href="machine_learning.html#sec-ml-tuning" class="quarto-xref"><span>Section 10.7</span></a>). We had hyperparameters for each of the models in this chapter also. For the elastic net model, we might want to tune the penalty parameters and the mixing ratio. For the boosting method, we might want to tune the number of trees, the learning rate, the maximum depth of each tree, the minimum number of observations in each leaf, and the number of features to consider at each tree/split. And for the neural network, we might want to tune the number of hidden layers, the number of nodes in each layer, the learning rate, the batch size, the number of epochs, and the activation function. There is plenty to explore!</p>
<p>Here is an example of a hyperparameter search using the boosting model. We’ll tune the number of trees, the learning rate, the minimum number of observations in each leaf, and the maximum depth of each tree. We’ll use a <strong>randomized search</strong> across the parameter space to sample from the set of hyperparameters, rather than searching every possible combination as in a <strong>grid search</strong>. This is a good approach when you have a lot of hyperparameters to tune, and/or when you have a lot of data.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train-test split</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    df_heart.drop(columns<span class="op">=</span><span class="st">'heart_disease'</span>), </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    df_heart[<span class="st">'heart_disease'</span>],</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    test_size <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    random_state <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>model_boost <span class="op">=</span> LGBMClassifier(verbose <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">500</span>, <span class="dv">1000</span>],</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>],</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>],</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_child_samples'</span>: [<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># this will take a few seconds</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    model_boost, </span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    param_grid, </span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    n_iter <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> <span class="dv">5</span>, </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    scoring <span class="op">=</span> <span class="st">'accuracy'</span>, </span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    random_state <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune.fit(X_train, y_train)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>test_predictions <span class="op">=</span> model_boost_cv_tune.predict(X_test)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_test, test_predictions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Test Accuracy 0.8 
Guessing:  0.539</code></pre>
</div>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>tsk_model_boost_cv_tune <span class="ot">=</span> <span class="fu">as_task_classif</span>(</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    df_heart,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">target =</span> <span class="st">"heart_disease"</span>,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">positive =</span> <span class="st">"yes"</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">partition</span>(tsk_model_boost_cv_tune, <span class="at">ratio =</span> .<span class="dv">8</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>lrn_lgbm <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classif.lightgbm"</span>,</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">num_iterations =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(<span class="dv">500</span>, <span class="dv">1000</span>)),</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">learning_rate =</span> <span class="fu">to_tune</span>(<span class="fl">1e-3</span>, <span class="fl">1e-1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>)),</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">min_data_in_leaf =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>))</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune <span class="ot">=</span> <span class="fu">auto_tuner</span>(</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuner =</span> <span class="fu">tnr</span>(<span class="st">"random_search"</span>),</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">learner =</span> lrn_lgbm,</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">5</span>),</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">measure =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>),</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> <span class="dv">10</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune<span class="sc">$</span><span class="fu">train</span>(tsk_model_boost_cv_tune, <span class="at">row_ids =</span> split<span class="sc">$</span>train)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>test_preds <span class="ot">=</span> model_boost_cv_tune<span class="sc">$</span><span class="fu">predict</span>(</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>    tsk_model_boost_cv_tune,</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">row_ids =</span> split<span class="sc">$</span>test</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>test_preds<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Test Accuracy: 0.831
Guessing: 0.539</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>It looks like we’ve done a lot better than guessing. Even if we don’t do better than our previously untuned model, we should feel better that we’ve done our due diligence in trying to find the best set of underlying parameters, rather than just going with defaults or what <em>seems</em> to work best.</p>
</section>
<section id="sec-ml-common-compare" class="level2" data-number="11.9">
<h2 data-number="11.9" class="anchored" data-anchor-id="sec-ml-common-compare"><span class="header-section-number">11.9</span> Comparing Models</h2>
<p></p>
<p>We can tune all the models and compare them head to head. For this demo, we’ll just describe what we did, as you’ve seen the code for how to do so throughout this chapter already. We first split the same data into training and test sets (20% test). Then with training data, we tuned each model over different settings:</p>
<ul>
<li>Elastic net: penalty and mixing ratio</li>
<li>Boosting: number of trees, learning rate, and maximum depth, etc.</li>
<li>Neural network: number of hidden layers, number of nodes in each layer, etc.</li>
</ul>
<p>After this, we used the tuned values to retrain the model on the complete training dataset. At this stage it’s not necessary to investigate in most settings, but we show the results of the 10-fold cross-validation for the already-tuned models, to give a sense of the uncertainty in error estimation with a small sample like this. Even with the ‘best’ settings, we can see that there is definitely some variability across data splits.</p>
<!-- :::{.content-visible when-format='pdf'} 
TODO: had to use png for pdf b/c it otherwise wouldn't center a a smaller image or use the caption
-->
<div id="fig-benchmark" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-benchmark-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/ml-benchmark-comparison.png" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-benchmark-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.7: Cross-validation results for tuned models.
</figcaption>
</figure>
</div>
<!-- ::: -->
<p>We now look at the performance on the holdout set with our tuned models in the following table<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>. In this case, we see something that might surprise you – the simplest model does really well! In this case, we’d probably declare it the winner given the combination of ease of use and interpretability. Again, your results may vary depending on whether you used a seed, R vs.&nbsp;Python, and possibly other aspects of your modeling environment.</p>
<div class="cell">
<div id="tbl-benchmark-py" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-benchmark-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;11.2: Metrics for Tuned Models on Holdout Data
</figcaption>
<div aria-describedby="tbl-benchmark-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="wdpvjxarvj" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
#wdpvjxarvj table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#wdpvjxarvj thead, #wdpvjxarvj tbody, #wdpvjxarvj tfoot, #wdpvjxarvj tr, #wdpvjxarvj td, #wdpvjxarvj th {
  border-style: none;
}

#wdpvjxarvj p {
  margin: 0;
  padding: 0;
}

#wdpvjxarvj .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#wdpvjxarvj .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#wdpvjxarvj .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#wdpvjxarvj .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#wdpvjxarvj .gt_heading {
  background-color: #FFFFFF;
  text-align: left;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#wdpvjxarvj .gt_bottom_border {
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wdpvjxarvj .gt_col_headings {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#wdpvjxarvj .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#wdpvjxarvj .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#wdpvjxarvj .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#wdpvjxarvj .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#wdpvjxarvj .gt_column_spanner {
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#wdpvjxarvj .gt_spanner_row {
  border-bottom-style: hidden;
}

#wdpvjxarvj .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#wdpvjxarvj .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#wdpvjxarvj .gt_from_md > :first-child {
  margin-top: 0;
}

#wdpvjxarvj .gt_from_md > :last-child {
  margin-bottom: 0;
}

#wdpvjxarvj .gt_row {
  padding-top: 7px;
  padding-bottom: 7px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#wdpvjxarvj .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#wdpvjxarvj .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#wdpvjxarvj .gt_row_group_first td {
  border-top-width: 2px;
}

#wdpvjxarvj .gt_row_group_first th {
  border-top-width: 2px;
}

#wdpvjxarvj .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdpvjxarvj .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#wdpvjxarvj .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#wdpvjxarvj .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wdpvjxarvj .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdpvjxarvj .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#wdpvjxarvj .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#wdpvjxarvj .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#wdpvjxarvj .gt_table_body {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #FFFFFF;
}

#wdpvjxarvj .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#wdpvjxarvj .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdpvjxarvj .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#wdpvjxarvj .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#wdpvjxarvj .gt_left {
  text-align: left;
}

#wdpvjxarvj .gt_center {
  text-align: center;
}

#wdpvjxarvj .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#wdpvjxarvj .gt_font_normal {
  font-weight: normal;
}

#wdpvjxarvj .gt_font_bold {
  font-weight: bold;
}

#wdpvjxarvj .gt_font_italic {
  font-style: italic;
}

#wdpvjxarvj .gt_super {
  font-size: 65%;
}

#wdpvjxarvj .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#wdpvjxarvj .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#wdpvjxarvj .gt_indent_1 {
  text-indent: 5px;
}

#wdpvjxarvj .gt_indent_2 {
  text-indent: 10px;
}

#wdpvjxarvj .gt_indent_3 {
  text-indent: 15px;
}

#wdpvjxarvj .gt_indent_4 {
  text-indent: 20px;
}

#wdpvjxarvj .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="true" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="model">model</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="acc">acc</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="tpr">tpr</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="tnr">tnr</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="f1">f1</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="ppv">ppv</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="npv">npv</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="model" class="gt_row gt_left" style="font-family: 'Source Sans Pro'; font-weight: 400;">Elastic Net</td>
<td headers="acc" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: bold;">0.88</td>
<td headers="tpr" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.83</td>
<td headers="tnr" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: bold;">0.92</td>
<td headers="f1" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: bold;">0.85</td>
<td headers="ppv" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: bold;">0.87</td>
<td headers="npv" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.89</td></tr>
    <tr><td headers="model" class="gt_row gt_left" style="font-family: 'Source Sans Pro'; font-weight: 400;">Boost</td>
<td headers="acc" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.85</td>
<td headers="tpr" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: bold;">0.92</td>
<td headers="tnr" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.81</td>
<td headers="f1" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.83</td>
<td headers="ppv" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.76</td>
<td headers="npv" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: bold;">0.94</td></tr>
    <tr><td headers="model" class="gt_row gt_left" style="font-family: 'Source Sans Pro'; font-weight: 400;">MLP</td>
<td headers="acc" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.80</td>
<td headers="tpr" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.83</td>
<td headers="tnr" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.78</td>
<td headers="f1" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.77</td>
<td headers="ppv" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.71</td>
<td headers="npv" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.88</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>It’s important to note that, for each metric, none of the model results are <em>statistically different</em> from each other. As an example, the elastic net model had an accuracy of 0.88, but the interval estimate for such a small holdout sample is very wide – from 0.77 to 0.95. The interval estimate for the <em>difference</em> in accuracy between the elastic net and boosting models is from -0.1 to 0.17<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. Again, we shouldn’t take this result too far, as we’re dealing with a small dataset and it is difficult to detect potentially complex relationships in such a setting. In addition, we could have done more to explore the parameter space of the models, but we’ll leave that for another time. But this was a good example of the importance of having an adequate baseline, and where complexity didn’t really help much, though all our approaches did reasonably well.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="Test Metrics Better than Training?">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Test Metrics Better than Training?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Some may wonder how the holdout results can be better than training, which you might have seen in playing around with the models for this data. This can definitely happen and, at least in this case, would probably just reflect the small sample size. The holdout set is a random sample of 20% of the complete data, which is 59 examples. Just slightly different predictions could result in a several percentage point difference in accuracy. In general though, you’d expect the holdout results to be a bit, or even significantly, worse than the training results.</p>
</div>
</div>
</div>
<p> </p>
</section>
<section id="sec-ml-common-interpret" class="level2" data-number="11.10">
<h2 data-number="11.10" class="anchored" data-anchor-id="sec-ml-common-interpret"><span class="header-section-number">11.10</span> Interpretation</h2>
<p>When it comes to machine learning, many models we use don’t have an easy interpretation, like with coefficients in a linear regression model. However, that doesn’t mean we can’t still figure out what’s going on. Let’s use the boosting model as an example.</p>
<section id="sec-ml-common-feat-imp" class="level3" data-number="11.10.1">
<h3 data-number="11.10.1" class="anchored" data-anchor-id="sec-ml-common-feat-imp"><span class="header-section-number">11.10.1</span> Feature importance</h3>
<p> The default importance metric for a lightgbm model is the number of splits in which a feature is used across trees, and this will depend a lot on the chosen parameters of the best model. For the table below, we show the top 4 features from the tuned model and values rescaled to be between 0 and 1 for easier comparison. But there are other ways to think about what importance means that will be specific to a model, data setting, and the ultimate goal of the modeling process.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get feature importances</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> model_boost_cv_tune.best_estimator_</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>best_model.feature_importances_ <span class="co"># seriously, no feature names?</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># if it's not obvious which of these values belongs to which feature, do this:</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: best_model.feature_name_,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: best_model.feature_importances_</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<p>R shows the proportion of splits in which a feature is used across trees rather than the raw number.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get feature importances</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune<span class="sc">$</span>learner<span class="sc">$</span><span class="fu">importance</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<div class="cell">
<div id="tbl-imp-r-show" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-imp-r-show-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;11.3: Top 4 Features from a Tuned LGBM model
</figcaption>
<div aria-describedby="tbl-imp-r-show-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="txmdojiwnh" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Libre+Franklin:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
#txmdojiwnh table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#txmdojiwnh thead, #txmdojiwnh tbody, #txmdojiwnh tfoot, #txmdojiwnh tr, #txmdojiwnh td, #txmdojiwnh th {
  border-style: none;
}

#txmdojiwnh p {
  margin: 0;
  padding: 0;
}

#txmdojiwnh .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#txmdojiwnh .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#txmdojiwnh .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#txmdojiwnh .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#txmdojiwnh .gt_heading {
  background-color: #FFFFFF;
  text-align: left;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#txmdojiwnh .gt_bottom_border {
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#txmdojiwnh .gt_col_headings {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#txmdojiwnh .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#txmdojiwnh .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 12px;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#txmdojiwnh .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#txmdojiwnh .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#txmdojiwnh .gt_column_spanner {
  border-bottom-style: none;
  border-bottom-width: 1px;
  border-bottom-color: #334422;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#txmdojiwnh .gt_spanner_row {
  border-bottom-style: hidden;
}

#txmdojiwnh .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#txmdojiwnh .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#txmdojiwnh .gt_from_md > :first-child {
  margin-top: 0;
}

#txmdojiwnh .gt_from_md > :last-child {
  margin-bottom: 0;
}

#txmdojiwnh .gt_row {
  padding-top: 7px;
  padding-bottom: 7px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#txmdojiwnh .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#txmdojiwnh .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#txmdojiwnh .gt_row_group_first td {
  border-top-width: 2px;
}

#txmdojiwnh .gt_row_group_first th {
  border-top-width: 2px;
}

#txmdojiwnh .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#txmdojiwnh .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#txmdojiwnh .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#txmdojiwnh .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#txmdojiwnh .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#txmdojiwnh .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#txmdojiwnh .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#txmdojiwnh .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#txmdojiwnh .gt_table_body {
  border-top-style: none;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #FFFFFF;
}

#txmdojiwnh .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#txmdojiwnh .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#txmdojiwnh .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#txmdojiwnh .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#txmdojiwnh .gt_left {
  text-align: left;
}

#txmdojiwnh .gt_center {
  text-align: center;
}

#txmdojiwnh .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#txmdojiwnh .gt_font_normal {
  font-weight: normal;
}

#txmdojiwnh .gt_font_bold {
  font-weight: bold;
}

#txmdojiwnh .gt_font_italic {
  font-style: italic;
}

#txmdojiwnh .gt_super {
  font-size: 65%;
}

#txmdojiwnh .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#txmdojiwnh .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#txmdojiwnh .gt_indent_1 {
  text-indent: 5px;
}

#txmdojiwnh .gt_indent_2 {
  text-indent: 10px;
}

#txmdojiwnh .gt_indent_3 {
  text-indent: 15px;
}

#txmdojiwnh .gt_indent_4 {
  text-indent: 20px;
}

#txmdojiwnh .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="true" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="Feature">Feature</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="color: #A9A9A9; font-family: 'Source Sans Pro'; text-transform: uppercase;" scope="col" id="Importance">Importance</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="Feature" class="gt_row gt_left" style="font-family: 'Source Sans Pro'; font-weight: 400;">age</td>
<td headers="Importance" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">1.00</td></tr>
    <tr><td headers="Feature" class="gt_row gt_left" style="font-family: 'Source Sans Pro'; font-weight: 400;">cholesterol</td>
<td headers="Importance" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.97</td></tr>
    <tr><td headers="Feature" class="gt_row gt_left" style="font-family: 'Source Sans Pro'; font-weight: 400;">max_heart_rate</td>
<td headers="Importance" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.83</td></tr>
    <tr><td headers="Feature" class="gt_row gt_left" style="font-family: 'Source Sans Pro'; font-weight: 400;">resting_bp</td>
<td headers="Importance" class="gt_row gt_right" style="color: #404040; font-family: 'Source Sans Pro'; font-weight: 400;">0.68</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>Now let’s think about a visual display to aid our understanding. Here we show a partial dependence plot (<a href="understanding_features.html#sec-knowing-related-viz" class="quarto-xref"><span>Section 5.8</span></a>) to see the effects of cholesterol and being male. From this we can see that males are expected to have a higher probability of heart disease, and that cholesterol has a positive relationship with heart disease, though this occurs mostly after midpoint for cholesterol (shown by vertical line). The plot shown is a prettier version of what you’d get with the following code, but the model predictions are the same.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>PartialDependenceDisplay.from_estimator(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    model_boost_cv_tune, </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    df_heart.drop(columns<span class="op">=</span><span class="st">'heart_disease'</span>), </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    features<span class="op">=</span>[<span class="st">'cholesterol'</span>, <span class="st">'male'</span>], </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    categorical_features<span class="op">=</span>[<span class="st">'male'</span>], </span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    percentiles<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">.9</span>),</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    grid_resolution<span class="op">=</span><span class="dv">75</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<p>For R we’ll use the <span class="pack">iml</span> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(iml)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> Predictor<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    model_boost_cv_tune<span class="sc">$</span>model<span class="sc">$</span>learner,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> df_heart,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">'prob'</span>, </span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">class =</span> <span class="st">'yes'</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction plot, select a single feature for a single feature plot</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>effect_dat <span class="ot">=</span> FeatureEffect<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    prediction, </span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">feature =</span> <span class="fu">c</span>(<span class="st">'cholesterol'</span>, <span class="st">'male'</span>),</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">"pdp"</span>, </span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>effect_dat<span class="sc">$</span><span class="fu">plot</span>(<span class="at">show.data =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<div id="fig-pdp-r-plot-show" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pdp-r-plot-show-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/ml-pdp-plot.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pdp-r-plot-show-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.8: Partial dependence plot for cholesterol.
</figcaption>
</figure>
</div>
<p></p>
</section>
</section>
<section id="sec-ml-common-other-models" class="level2" data-number="11.11">
<h2 data-number="11.11" class="anchored" data-anchor-id="sec-ml-common-other-models"><span class="header-section-number">11.11</span> Other ML Models for Tabular Data</h2>
<p> When you research classical machine learning models for the kind of data we’ve been exploring, you’ll find a variety of methods. Popular approaches from the past include <em>k</em>-nearest neighbors regression, principal components regression, support vector machines (SVM), and more. You don’t see these used in practice as much though for several reasons:</p>
<ul>
<li>Some, like k-nearest neighbors regression, generally don’t predict as well as other models.</li>
<li>Others, like linear discriminant analysis, make strong assumptions about how the data is distributed.</li>
<li>Some models, like SVM, tend to work well only with ‘clean’ and well-structured data of the same type.</li>
<li>Many of these models’ standard approach is computationally demanding, making them less practical for large datasets.</li>
<li>Lastly, some of these models are less interpretable, making it hard to understand their predictions without an obvious gain in performance.</li>
</ul>
<p>While some of these classical models might still work well in unique situations, when you have tools that can handle a lot of data complexity and predict very well (and usually better) like tree-based methods, there’s not much reason to use the historical alternatives. If you’re interested in learning more about them or think one of them is just ‘neat’, you could potentially use it as a baseline model. Alternatively, you could maybe employ them as part of an ensemble or <strong>stacked</strong> model, where you combine the predictions of multiple models to produce a single prediction. This is a common approach in machine learning and is often used in Kaggle competitions.</p>
<p>There are also other methods that are more specialized, such as those for text, image, and audio data. We will provide an overview of these elsewhere (<a href="ml_more.html" class="quarto-xref"><span>Chapter 12</span></a>). Currently, the main research effort for new models for tabular data regards deep learning methods like large language models (LLMs). While typically used for text data, they can be adapted for tabular data as well. They are very powerful but also computationally expensive. The issue is primarily whether a model can be devised that can consistently beat boosting and other approaches that already do very well. While it hasn’t happened yet, there is a good chance it will in the near future. For now, the best approach is to use the best model that works for your data and to be open to new methods as they come along.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled" title="SOTA Deep Learning for Tabular Data">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
SOTA Deep Learning for Tabular Data
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>As of this writing, the current state of the art (SOTA) for deep learning on tabular data appears to be techniques like TabR (<span class="citation" data-cites="gorishniy_tabr_2023">Gorishniy et al. (<a href="references.html#ref-gorishniy_tabr_2023" role="doc-biblioref">2023</a>)</span>) and Modern NCA (<span class="citation" data-cites="ye_modern_2024">Ye, Yin, and Zhan (<a href="references.html#ref-ye_modern_2024" role="doc-biblioref">2024</a>)</span>). These are very new and not yet widely used, but they are showing promise in some benchmarks.</p>
</div>
</div>
</div>
<p></p>
</section>
<section id="sec-ml-common-wrap" class="level2" data-number="11.12">
<h2 data-number="11.12" class="anchored" data-anchor-id="sec-ml-common-wrap"><span class="header-section-number">11.12</span> Wrapping Up</h2>
<p>In this chapter we’ve provided a few common and successful models you can implement with much success in machine learning. You don’t really need much beyond these for tabular data unless your unique data condition somehow requires it. But here are some things are worth mentioning before moving on from models in machine learning:</p>
<blockquote class="blockquote">
<p><strong>Thinking hard about the problem and the data is more important than the model choice.</strong></p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Feature engineering will typically pay off more in performance than the model choice.</strong></p>
</blockquote>
<blockquote class="blockquote">
<p><strong>The best model is simply the one that works best for your situation.</strong></p>
</blockquote>
<p>You’ll always get more payoff by coming up with better features to use in the model, as well as just using better data that’s been ‘fixed’ because you’ve done some good exploratory data analysis. Thinking harder about the problem means you will waste less time going down dead-ends. You also can find better data to use to solve the problem by thinking more clearly about the question at hand. And finally, it’s good to not be stuck on one model and be willing to use something new to get the job done.</p>
<section id="sec-ml-common-thread" class="level3" data-number="11.12.1">
<h3 data-number="11.12.1" class="anchored" data-anchor-id="sec-ml-common-thread"><span class="header-section-number">11.12.1</span> The common thread</h3>
<p>When it comes to machine learning, you can use any model you feel like, and this could be standard statistical models like we’ve covered elsewhere. Both boosting and neural networks, like GAMs and related techniques, can be put under a common heading of <em>basis function models</em>. GAMs with certain types of smooth functions are approximations of Gaussian processes, and Gaussian processes are equivalent to a neural network with an infinitely wide hidden layer (<span class="citation" data-cites="neal_priors_1996">Neal (<a href="references.html#ref-neal_priors_1996" role="doc-biblioref">1996</a>)</span>). Even the most complicated deep learning model typically has components that involve feature combinations and transformations that we use in far simpler models like linear regression.</p>
<p></p>
</section>
<section id="sec-ml-common-choose" class="level3" data-number="11.12.2">
<h3 data-number="11.12.2" class="anchored" data-anchor-id="sec-ml-common-choose"><span class="header-section-number">11.12.2</span> Choose your own adventure</h3>
<p>If you haven’t had much exposure to statistical approaches, we suggest heading to any chapter before Chapter <a href="machine_learning.html" class="quarto-xref"><span>10</span></a>. Otherwise, consider an overview of more machine learning techniques (<a href="ml_more.html" class="quarto-xref"><span>Chapter 12</span></a>), data-specific considerations (<a href="data.html" class="quarto-xref"><span>Chapter 14</span></a>), or causal modeling (<a href="causal.html" class="quarto-xref"><span>Chapter 13</span></a>).</p>
</section>
<section id="sec-ml-common-resources" class="level3" data-number="11.12.3">
<h3 data-number="11.12.3" class="anchored" data-anchor-id="sec-ml-common-resources"><span class="header-section-number">11.12.3</span> Additional resources</h3>
<p>Additional resources include those mentioned in <a href="machine_learning.html#sec-ml-resources" class="quarto-xref"><span>Section 10.9.3</span></a>, but here are some more to consider:</p>
<ul>
<li><a href="https://christophm.github.io/interpretable-ml-book/">Interpretable ML</a> (<span class="citation" data-cites="molnar_interpretable_2023">Molnar (<a href="references.html#ref-molnar_interpretable_2023" role="doc-biblioref">2023</a>)</span>)</li>
<li>Interpretable Machine Learning with Python (<span class="citation" data-cites="masis_interpretable_2023">Masis (<a href="references.html#ref-masis_interpretable_2023" role="doc-biblioref">2023</a>)</span>)</li>
<li><a href="https://substack.com/redirect/84b123ee-9f41-4b96-be90-5e38028c2424?j=eyJ1IjoiMXR6aHdpIn0.5Ipuq5Kqxxiat2G2fMY0hl7pUnbdbCGq1J3hhzg1FeU">Machine Learning Q &amp; AI</a> (<span class="citation" data-cites="raschka_machine_2023">Raschka (<a href="references.html#ref-raschka_machine_2023" role="doc-biblioref">2023</a>)</span>)</li>
<li><a href="https://developers.google.com/machine-learning/decision-forests">Google’s Course on Decision Forests</a></li>
</ul>
<p>For deep learning specifically:</p>
<ul>
<li><a href="https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html">Common activation functions</a></li>
<li>An overview of deep learning applications for tabular data by Michael <span class="citation" data-cites="clark_this_2021 clark_deep_2022">(see <a href="references.html#ref-clark_this_2021" role="doc-biblioref">Clark 2021</a>, <a href="references.html#ref-clark_deep_2022" role="doc-biblioref">2022</a>)</span></li>
<li><a href="https://d2l.ai/">Dive into Deep Learning</a> (<span class="citation" data-cites="zhang_dive_2023">Zhang et al. (<a href="references.html#ref-zhang_dive_2023" role="doc-biblioref">2023</a>)</span>)</li>
<li>Fast AI course (<span class="citation" data-cites="howard_practical_2024">Howard (<a href="references.html#ref-howard_practical_2024" role="doc-biblioref">2024</a>)</span>)</li>
</ul>
</section>
</section>
<section id="sec-ml-common-exercise" class="level2" data-number="11.13">
<h2 data-number="11.13" class="anchored" data-anchor-id="sec-ml-common-exercise"><span class="header-section-number">11.13</span> Guided Exploration</h2>
<p>Tune a model of your choice to predict whether a movie is good or bad with the <a href="https://tinyurl.com/moviereviewsdata">movie review data</a>. Use the categorical target, and use one-hot encoded features if needed. Make sure you use a good baseline model for comparison!</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="language">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">Python</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">R</a></li></ul>
<div class="tab-content" data-group="language">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>df_reviews <span class="op">=</span> pd.read_csv(<span class="st">'https://tinyurl.com/moviereviewsdata'</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>df_reviews_sub <span class="op">=</span> df_reviews[[</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'review_year'</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age'</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'children_in_home'</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'education'</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'work_status'</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'genre'</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'release_year'</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'word_count'</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'rating_good'</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>]]</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    df_reviews_sub.drop(columns<span class="op">=</span><span class="st">'rating_good'</span>), </span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    df_heart_num[<span class="st">'rating_good'</span>],</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    test_size <span class="op">=</span> ???,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    random_state <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>model_boost <span class="op">=</span> LGBMClassifier(</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    verbose <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: ???,</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: ???,</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: ???,</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_child_samples'</span>: ???,</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a><span class="co"># this will take a few seconds</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    model_boost, </span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    param_grid, </span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>    n_iter <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> ???, </span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    scoring <span class="op">=</span> ????, </span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>    n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    random_state <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune.fit(X_train, y_train)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>test_predictions <span class="op">=</span> model_boost_cv_tune.predict(X_test)</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>accuracy_score(y_test, test_predictions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>df_reviews <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="st">'https://tinyurl.com/moviereviewsdata'</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>df_reviews_sub <span class="ot">=</span> df_reviews <span class="sc">%&gt;%</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        review_year,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        age,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        children_in_home,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        education,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        work_status,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        genre,</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        release_year,</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>        word_count,</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        rating_good</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">|&gt;</span> </span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>        <span class="fu">across</span>(<span class="fu">where</span>(is.character), \(x) <span class="fu">as.factor</span>(x))</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>tsk_model_boost_cv_tune <span class="ot">=</span> <span class="fu">as_task_classif</span>(</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>    df_reviews_sub,</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">target =</span> <span class="st">"rating_good"</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">partition</span>(tsk_model_boost_cv_tune, <span class="at">ratio =</span> ??)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>lrn_lgbm <span class="ot">=</span> <span class="fu">lrn</span>(</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">"classif.lightgbm"</span>,</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">num_iterations =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(???, ???)),</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">learning_rate =</span> <span class="fu">to_tune</span>(<span class="fl">1e-3</span>, <span class="fl">1e-1</span>, <span class="at">logscale =</span> <span class="cn">TRUE</span>),</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_depth =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(???, ???)),</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">min_data_in_leaf =</span> <span class="fu">to_tune</span>(<span class="fu">c</span>(???, ???))</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune <span class="ot">=</span> <span class="fu">auto_tuner</span>(</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuner =</span> <span class="fu">tnr</span>(<span class="st">"random_search"</span>),</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">learner =</span> lrn_lgbm,</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">resampling =</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> ???),</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">measure =</span> <span class="fu">msr</span>(<span class="st">"classif.acc"</span>),</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">terminator =</span> <span class="fu">trm</span>(<span class="st">"evals"</span>, <span class="at">n_evals =</span> ???)</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune<span class="sc">$</span><span class="fu">train</span>(tsk_model_boost_cv_tune, <span class="at">row_ids =</span> split<span class="sc">$</span>train)</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>model_boost_cv_tune<span class="sc">$</span><span class="fu">predict</span>(</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>    tsk_model_boost_cv_tune,</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">row_ids =</span> split<span class="sc">$</span>test</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>)<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-clark_this_2021" class="csl-entry" role="listitem">
Clark, Michael. 2021. <span>“This Is Definitely Not All You Need,”</span> July. <a href="https://m-clark.github.io/posts/2021-07-15-dl-for-tabular/">https://m-clark.github.io/posts/2021-07-15-dl-for-tabular/</a>.
</div>
<div id="ref-clark_deep_2022" class="csl-entry" role="listitem">
Clark, Michael. 2022. <span>“Deep <span>Learning</span> for <span>Tabular</span> <span>Data</span>,”</span> May. <a href="https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/">https://m-clark.github.io/posts/2022-04-01-more-dl-for-tabular/</a>.
</div>
<div id="ref-gorishniy_tabr_2023" class="csl-entry" role="listitem">
Gorishniy, Yury, Ivan Rubachev, Nikolay Kartashev, Daniil Shlenskii, Akim Kotelnikov, and Artem Babenko. 2023. <span>“<span>TabR</span>: <span>Tabular</span> <span>Deep</span> <span>Learning</span> <span>Meets</span> <span>Nearest</span> <span>Neighbors</span> in 2023.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2307.14338">https://doi.org/10.48550/arXiv.2307.14338</a>.
</div>
<div id="ref-howard_practical_2024" class="csl-entry" role="listitem">
Howard, Jeremy. 2024. <span>“Practical <span>Deep</span> <span>Learning</span> for <span>Coders</span> - <span>Practical</span> <span>Deep</span> <span>Learning</span>.”</span> <em>Practical Deep Learning for Coders</em>. <a href="https://course.fast.ai/">https://course.fast.ai/</a>.
</div>
<div id="ref-masis_interpretable_2023" class="csl-entry" role="listitem">
Masis, Serg. 2023. <span>“Interpretable <span>Machine</span> <span>Learning</span> with <span>Python</span> - <span>Second</span> <span>Edition</span>.”</span> <em>Packt</em>. <a href="https://www.packtpub.com/product/interpretable-machine-learning-with-python-second-edition/9781803235424">https://www.packtpub.com/product/interpretable-machine-learning-with-python-second-edition/9781803235424</a>.
</div>
<div id="ref-mcculloch_logical_1943" class="csl-entry" role="listitem">
McCulloch, Warren S., and Walter Pitts. 1943. <span>“A Logical Calculus of the Ideas Immanent in Nervous Activity.”</span> <em>The Bulletin of Mathematical Biophysics</em> 5 (4): 115–33. <a href="https://doi.org/10.1007/BF02478259">https://doi.org/10.1007/BF02478259</a>.
</div>
<div id="ref-molnar_interpretable_2023" class="csl-entry" role="listitem">
Molnar, Christoph. 2023. <em>Interpretable <span>Machine</span> <span>Learning</span></em>. <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a>.
</div>
<div id="ref-neal_priors_1996" class="csl-entry" role="listitem">
Neal, Radford M. 1996. <span>“Priors for <span>Infinite</span> <span>Networks</span>.”</span> In <em>Bayesian <span>Learning</span> for <span>Neural</span> <span>Networks</span></em>, edited by Radford M. Neal, 29–53. New York, NY: Springer. <a href="https://doi.org/10.1007/978-1-4612-0745-0_2">https://doi.org/10.1007/978-1-4612-0745-0_2</a>.
</div>
<div id="ref-raschka_machine_2023" class="csl-entry" role="listitem">
Raschka, Sebastian. 2023. <em>Machine <span>Learning</span> <span>Q</span> and <span>AI</span></em>. <a href="https://nostarch.com/machine-learning-q-and-ai">https://nostarch.com/machine-learning-q-and-ai</a>.
</div>
<div id="ref-rasmussen_gaussian_2005" class="csl-entry" role="listitem">
Rasmussen, Carl Edward, and Christopher K. I. Williams. 2005. <em>Gaussian <span>Processes</span> for <span>Machine</span> <span>Learning</span></em>. The MIT Press. <a href="https://doi.org/10.7551/mitpress/3206.001.0001">https://doi.org/10.7551/mitpress/3206.001.0001</a>.
</div>
<div id="ref-ye_modern_2024" class="csl-entry" role="listitem">
Ye, Han-Jia, Huai-Hong Yin, and De-Chuan Zhan. 2024. <span>“Modern <span>Neighborhood</span> <span>Components</span> <span>Analysis</span>: <span>A</span> <span>Deep</span> <span>Tabular</span> <span>Baseline</span> <span>Two</span> <span>Decades</span> <span>Later</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2407.03257">https://doi.org/10.48550/arXiv.2407.03257</a>.
</div>
<div id="ref-zhang_dive_2023" class="csl-entry" role="listitem">
Zhang, Aston, Zack Lipton, Mu Li, and Alex Smola. 2023. <span>“Dive into <span>Deep</span> <span>Learning</span> — <span>Dive</span> into <span>Deep</span> <span>Learning</span> 1.0.3 Documentation.”</span> <a href="https://d2l.ai/index.html">https://d2l.ai/index.html</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>There would be far less hype and wasted time if those in ML and DL research simply did this rather than just reporting the chosen metric of their model ‘winning’ against other models. It’d also be nice if they used a more meaningful baseline than logistic regression, but that’s a different story. And one more thing, although many papers also rank the competing models, ranks and mean ranks also have uncertainty, and ranks are typically <em>very</em> noisy.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>A single regression/classification tree actually could serve as a decent baseline model, especially given the interpretability, and modern methods try to make them more stable.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>For boosting models, the learning rate is a scaling factor for the contribution of each tree to the overall model. A smaller learning rate means that each tree contributes less to the overall model, and so you’ll need more trees to get the same performance, all else being equal.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>For boosting models, the regularization parameters are basically penalties on the weights of the leaves. For example, a smaller value would reduce the contribution of that leaf to the overall model, and so would help to reduce overfitting.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Some also prefer <span class="pack">catboost</span>. Your humble authors have not actually been able to practically implement catboost in a setting where it was more predictive or as efficient/speedy as <span class="pack">xgboost</span> or <span class="pack">lightgbm</span> to get to the same performance level, but some have had notable success with it.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>It’s not clear why most model functions still have no default for this sort of thing in 2025. Is it that hard to drop or impute them with an informative message?<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Most consider the scientific origin with <span class="citation" data-cites="mcculloch_logical_1943">McCulloch and Pitts (<a href="references.html#ref-mcculloch_logical_1943" role="doc-biblioref">1943</a>)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>On the conceptual side, they served as a rudimentary model of neuronal functioning in the brain, and a way to understand how the brain processes information. The models sprung from the cognitive revolution, a backlash against the behaviorist approach to psychology, and used the computer as <a href="https://en.wikipedia.org/wiki/Connectionism">a metaphor for how the brain might operate</a>.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>The term ‘hidden’ is used because these nodes are between the input or output. It does not imply a latent/hidden variable in the sense used in many statistical models, but there is common ground. See the connection with principal components analysis, for example (<a href="ml_more.html#sec-ml-more-pca-as-net" class="quarto-xref"><span>Section 12.2.1.2</span></a>).<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>We have multiple options for our activation functions, and probably the most common one in deep learning is the <strong>rectified linear unit</strong> or <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a>, and its more recent variants. Others used include the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a>, which is the same as what we used in logistic regression, the hyperbolic tangent function, and the linear/identity function, which does not do any transformation at all.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>It’s not exactly clear <a href="https://stats.stackexchange.com/questions/511726/different-usage-of-the-term-bias-in-stats-machine-learning">why computer scientists chose to call this the bias</a>, but it’s the same as the intercept in a linear model, or conceptually as an offset or constant. It has nothing to do with the word bias as used in every other modeling context.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>A really good tool for a standard MLP type approach with automatic categorical embeddings is <span class="pack">fastai</span>’s tabular learner. For a more flexible, DIY type of approach, consider the recently developed <span class="pack">torch_frame</span> package.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>This table was based on Python with randomized CV search, but the R approach produced similar results. However, they can both vary quite a bit even with just a random seed change due to the small sample size.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>We just used the <code>prop.test</code> function in R for these values with the key question of whether these proportions are different. A lot of the metrics people look at from confusion matrices are proportions.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./machine_learning.html" class="pagination-link" aria-label="Core Concepts in Machine Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Core Concepts in Machine Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ml_more.html" class="pagination-link" aria-label="Extending Machine Learning">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Extending Machine Learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025 CC-BY-NC-SA</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/m-clark/book-of-models/edit/dev/ml_common_models.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/m-clark/book-of-models">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/statsdatasci">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/michael-clark-b475b5170/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>