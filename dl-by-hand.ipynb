{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: path = Path('../input/titanic')\n",
    "else:\n",
    "    path = Path('titanic')\n",
    "    if not path.exists():\n",
    "        import zipfile,kaggle\n",
    "        kaggle.api.competition_download_cli(str(path))\n",
    "        zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(modes, inplace=True)\n",
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Fare'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log1p(df['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LogFare'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclasses = sorted(df.Pclass.unique())\n",
    "pclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name   Age  SibSp  Parch            Ticket     Fare    Cabin  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris  22.0      1      0         A/5 21171   7.2500  B96 B98   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0          PC 17599  71.2833      C85   \n",
       "2            3         1                             Heikkinen, Miss. Laina  26.0      0      0  STON/O2. 3101282   7.9250  B96 B98   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0            113803  53.1000     C123   \n",
       "4            5         0                           Allen, Mr. William Henry  35.0      0      0            373450   8.0500  B96 B98   \n",
       "\n",
       "    LogFare  Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0  2.110213           0         1         0         0         1           0           0           1  \n",
       "1  4.280593           1         0         1         0         0           1           0           0  \n",
       "2  2.188856           1         0         0         0         1           0           0           1  \n",
       "3  3.990834           1         0         1         0         0           0           0           1  \n",
       "4  2.202765           0         1         0         0         1           0           0           1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "target = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "all_features = ['Age', 'SibSp', 'Parch', 'LogFare'] + dummies \n",
    "\n",
    "X = tensor(df[all_features].values, dtype=torch.float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(442)\n",
    "\n",
    "n_coeff = X.shape[1]\n",
    "coeffs = torch.rand(n_coeff)-0.5\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vals,indices = X.max(dim=0)\n",
    "# X = X / vals\n",
    "X_means = X.mean(dim = 0, keepdim=True)\n",
    "X_sds = X.std(dim = 0)\n",
    "\n",
    "\n",
    "X_sc = (X - X_means) / X_sds\n",
    "# X_sc.mean(dim=0)  # all means = 0 \n",
    "# X_sc.std(dim=0)   # all sd = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6000, -1.9341,  0.2080,  0.1723, -0.0032,  0.3088, -0.5066,  1.6219,  0.6990, -1.2584])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (X_sc*coeffs).sum(axis=1)\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3960)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.square(preds - target).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3960)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_preds(X, weights):\n",
    "    return((X*weights).sum(axis=1))\n",
    "\n",
    "def calc_loss(X, weights, target):\n",
    "    preds = calc_preds(X, weights)\n",
    "    # target = tensor(target, dtype = torch.float)\n",
    "    L = torch.nn.MSELoss()(preds, target.float())\n",
    "    return(L)\n",
    "\n",
    "calc_loss(X_sc, coeffs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3960)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss()(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3960, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(X_sc, coeffs, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9311,  0.6245,  0.4957, -0.7423,  0.6008, -0.6008, -0.9158,  0.0938,  0.7127, -1.7183,  0.1715,  1.3974])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8621,  1.2491,  0.9914, -1.4847,  1.2015, -1.2015, -1.8317,  0.1877,  1.4254, -3.4366,  0.3431,  2.7947])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(X_sc, coeffs, target)\n",
    "loss.backward()\n",
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(83.9144)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    coeffs.sub_(coeffs.grad*0.1)\n",
    "    coeffs.grad.zero_()\n",
    "    print(calc_loss(X, coeffs, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X_sc, target.float(), test_size=0.2) # in keeping with RandomSplitter default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, lr):\n",
    "    weights.sub_(weights.grad * lr)\n",
    "    weights.grad.zero_()\n",
    "\n",
    "def one_epoch(X, weights, target, lr, verbose = 1, i = 1):\n",
    "    loss = calc_loss(X, weights, target)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_weights(weights, lr)\n",
    "    if verbose != 0:\n",
    "        if i % verbose == 0:\n",
    "            print(f'{loss: 3f}', end = '\\n ')\n",
    "\n",
    "def init_weights(n_wts): \n",
    "    return (torch.rand(n_wts)-0.5).requires_grad_()\n",
    "\n",
    "def train_model(X, target, epochs=30, lr=1e-3):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_weights(X.shape[1])\n",
    "    for i in range(epochs): \n",
    "        one_epoch(X, coeffs, target, lr=lr, i = i)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_loss(X_sc, init_weights(X_sc.shape[1]), target).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.990650\n",
      " "
     ]
    }
   ],
   "source": [
    "one_epoch(train_x, init_weights(train_x.shape[1]), train_y, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.490951\n",
      "  1.480902\n",
      "  1.470947\n",
      "  1.461088\n",
      "  1.451321\n",
      "  1.441648\n",
      "  1.432065\n",
      "  1.422574\n",
      "  1.413173\n",
      "  1.403860\n",
      "  1.394636\n",
      "  1.385498\n",
      "  1.376447\n",
      "  1.367482\n",
      "  1.358600\n",
      "  1.349803\n",
      "  1.341088\n",
      "  1.332455\n",
      "  1.323903\n",
      "  1.315432\n",
      "  1.307041\n",
      "  1.298728\n",
      "  1.290493\n",
      "  1.282335\n",
      "  1.274253\n",
      "  1.266248\n",
      "  1.258317\n",
      "  1.250460\n",
      "  1.242676\n",
      "  1.234966\n",
      "  1.227327\n",
      "  1.219759\n",
      "  1.212262\n",
      "  1.204835\n",
      "  1.197476\n",
      "  1.190187\n",
      "  1.182964\n",
      "  1.175809\n",
      "  1.168721\n",
      "  1.161698\n",
      "  1.154739\n",
      "  1.147846\n",
      "  1.141016\n",
      "  1.134249\n",
      "  1.127545\n",
      "  1.120903\n",
      "  1.114322\n",
      "  1.107801\n",
      "  1.101341\n",
      "  1.094940\n",
      "  1.088598\n",
      "  1.082314\n",
      "  1.076088\n",
      "  1.069919\n",
      "  1.063807\n",
      "  1.057750\n",
      "  1.051749\n",
      "  1.045803\n",
      "  1.039912\n",
      "  1.034074\n",
      "  1.028289\n",
      "  1.022558\n",
      "  1.016878\n",
      "  1.011250\n",
      "  1.005673\n",
      "  1.000147\n",
      "  0.994672\n",
      "  0.989246\n",
      "  0.983869\n",
      "  0.978541\n",
      "  0.973261\n",
      "  0.968029\n",
      "  0.962845\n",
      "  0.957707\n",
      "  0.952615\n",
      "  0.947570\n",
      "  0.942570\n",
      "  0.937615\n",
      "  0.932705\n",
      "  0.927838\n",
      "  0.923016\n",
      "  0.918237\n",
      "  0.913500\n",
      "  0.908807\n",
      "  0.904155\n",
      "  0.899545\n",
      "  0.894976\n",
      "  0.890448\n",
      "  0.885960\n",
      "  0.881512\n",
      "  0.877104\n",
      "  0.872736\n",
      "  0.868406\n",
      "  0.864114\n",
      "  0.859861\n",
      "  0.855646\n",
      "  0.851467\n",
      "  0.847326\n",
      "  0.843222\n",
      "  0.839154\n",
      "  0.835121\n",
      "  0.831125\n",
      "  0.827163\n",
      "  0.823237\n",
      "  0.819345\n",
      "  0.815487\n",
      "  0.811664\n",
      "  0.807874\n",
      "  0.804117\n",
      "  0.800393\n",
      "  0.796702\n",
      "  0.793043\n",
      "  0.789416\n",
      "  0.785820\n",
      "  0.782257\n",
      "  0.778724\n",
      "  0.775222\n",
      "  0.771750\n",
      "  0.768309\n",
      "  0.764897\n",
      "  0.761515\n",
      "  0.758163\n",
      "  0.754839\n",
      "  0.751545\n",
      "  0.748278\n",
      "  0.745040\n",
      "  0.741830\n",
      "  0.738648\n",
      "  0.735493\n",
      "  0.732365\n",
      "  0.729265\n",
      "  0.726190\n",
      "  0.723142\n",
      "  0.720121\n",
      "  0.717125\n",
      "  0.714155\n",
      "  0.711210\n",
      "  0.708291\n",
      "  0.705396\n",
      "  0.702526\n",
      "  0.699680\n",
      "  0.696859\n",
      "  0.694062\n",
      "  0.691288\n",
      "  0.688538\n",
      "  0.685811\n",
      "  0.683107\n",
      "  0.680427\n",
      "  0.677768\n",
      "  0.675133\n",
      "  0.672519\n",
      "  0.669928\n",
      "  0.667358\n",
      "  0.664810\n",
      "  0.662283\n",
      "  0.659778\n",
      "  0.657293\n",
      "  0.654830\n",
      "  0.652387\n",
      "  0.649964\n",
      "  0.647562\n",
      "  0.645180\n",
      "  0.642817\n",
      "  0.640474\n",
      "  0.638151\n",
      "  0.635847\n",
      "  0.633562\n",
      "  0.631296\n",
      "  0.629048\n",
      "  0.626820\n",
      "  0.624609\n",
      "  0.622417\n",
      "  0.620243\n",
      "  0.618087\n",
      "  0.615949\n",
      "  0.613828\n",
      "  0.611725\n",
      "  0.609639\n",
      "  0.607570\n",
      "  0.605518\n",
      "  0.603482\n",
      "  0.601464\n",
      "  0.599461\n",
      "  0.597475\n",
      "  0.595505\n",
      "  0.593552\n",
      "  0.591614\n",
      "  0.589692\n",
      "  0.587785\n",
      "  0.585894\n",
      "  0.584018\n",
      "  0.582157\n",
      "  0.580311\n",
      "  0.578480\n",
      "  0.576664\n",
      "  0.574862\n",
      "  0.573075\n",
      "  0.571302\n",
      "  0.569544\n",
      "  0.567799\n",
      "  0.566068\n",
      "  0.564351\n",
      "  0.562648\n",
      "  0.560959\n",
      "  0.559283\n",
      "  0.557620\n",
      "  0.555970\n",
      "  0.554333\n",
      "  0.552710\n",
      "  0.551099\n",
      "  0.549501\n",
      "  0.547915\n",
      "  0.546342\n",
      "  0.544782\n",
      "  0.543233\n",
      "  0.541697\n",
      "  0.540173\n",
      "  0.538661\n",
      "  0.537160\n",
      "  0.535672\n",
      "  0.534195\n",
      "  0.532729\n",
      "  0.531275\n",
      "  0.529832\n",
      "  0.528400\n",
      "  0.526980\n",
      "  0.525570\n",
      "  0.524172\n",
      "  0.522784\n",
      "  0.521406\n",
      "  0.520040\n",
      "  0.518684\n",
      "  0.517338\n",
      "  0.516003\n",
      "  0.514678\n",
      "  0.513363\n",
      "  0.512058\n",
      "  0.510763\n",
      "  0.509478\n",
      "  0.508203\n",
      "  0.506937\n",
      "  0.505681\n",
      "  0.504435\n",
      "  0.503198\n",
      "  0.501970\n",
      "  0.500752\n",
      "  0.499543\n",
      "  0.498343\n",
      "  0.497152\n",
      "  0.495970\n",
      "  0.494797\n",
      "  0.493632\n",
      "  0.492477\n",
      "  0.491330\n",
      "  0.490191\n",
      "  0.489061\n",
      "  0.487940\n",
      "  0.486827\n",
      "  0.485722\n",
      "  0.484625\n",
      "  0.483536\n",
      "  0.482456\n",
      "  0.481383\n",
      "  0.480319\n",
      "  0.479262\n",
      "  0.478213\n",
      "  0.477172\n",
      "  0.476138\n",
      "  0.475112\n",
      "  0.474093\n",
      "  0.473082\n",
      "  0.472078\n",
      "  0.471082\n",
      "  0.470093\n",
      "  0.469111\n",
      "  0.468136\n",
      "  0.467168\n",
      "  0.466207\n",
      "  0.465254\n",
      "  0.464307\n",
      "  0.463366\n",
      "  0.462433\n",
      "  0.461506\n",
      "  0.460586\n",
      "  0.459673\n",
      "  0.458766\n",
      "  0.457866\n",
      "  0.456972\n",
      "  0.456084\n",
      "  0.455203\n",
      "  0.454328\n",
      "  0.453459\n",
      "  0.452596\n",
      "  0.451740\n",
      "  0.450889\n",
      "  0.450045\n",
      "  0.449206\n",
      "  0.448373\n",
      "  0.447547\n",
      "  0.446725\n",
      " "
     ]
    }
   ],
   "source": [
    "coeffs_est = train_model(train_x, train_y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.2773),\n",
       " 'SibSp': tensor(0.0217),\n",
       " 'Parch': tensor(0.1309),\n",
       " 'LogFare': tensor(-0.1302),\n",
       " 'Sex_male': tensor(-0.3591),\n",
       " 'Sex_female': tensor(-0.2189),\n",
       " 'Pclass_1': tensor(0.5893),\n",
       " 'Pclass_2': tensor(0.3047),\n",
       " 'Pclass_3': tensor(0.1995),\n",
       " 'Embarked_C': tensor(-0.1170),\n",
       " 'Embarked_Q': tensor(0.1557),\n",
       " 'Embarked_S': tensor(0.1146)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_coeffs(estimates): \n",
    "    return dict(zip(all_features, estimates.requires_grad_(False)))\n",
    "    \n",
    "show_coeffs(coeffs_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6615), tensor(0.6816))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(X, weights, target): \n",
    "    return (target.bool()==(calc_preds(X, weights)>0.5)).float().mean()\n",
    "\n",
    "acc(train_x, coeffs_est, train_y), acc(valid_x, coeffs_est, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(X, weights):\n",
    "    return torch.sigmoid((X*weights).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.318874\n",
      "  0.318817\n",
      "  0.318760\n",
      "  0.318702\n",
      "  0.318645\n",
      "  0.318588\n",
      "  0.318530\n",
      "  0.318473\n",
      "  0.318416\n",
      "  0.318359\n",
      "  0.318301\n",
      "  0.318244\n",
      "  0.318187\n",
      "  0.318130\n",
      "  0.318072\n",
      "  0.318015\n",
      "  0.317958\n",
      "  0.317901\n",
      "  0.317843\n",
      "  0.317786\n",
      "  0.317729\n",
      "  0.317672\n",
      "  0.317614\n",
      "  0.317557\n",
      "  0.317500\n",
      "  0.317443\n",
      "  0.317386\n",
      "  0.317328\n",
      "  0.317271\n",
      "  0.317214\n",
      " "
     ]
    }
   ],
   "source": [
    "coeffs_est = train_model(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3975), tensor(0.4693))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(train_x, coeffs_est, train_y), acc(valid_x, coeffs_est, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.4622),\n",
       " 'SibSp': tensor(0.1384),\n",
       " 'Parch': tensor(0.2411),\n",
       " 'LogFare': tensor(-0.2238),\n",
       " 'Sex_male': tensor(-0.2668),\n",
       " 'Sex_female': tensor(-0.3112),\n",
       " 'Pclass_1': tensor(0.4897),\n",
       " 'Pclass_2': tensor(0.3141),\n",
       " 'Pclass_3': tensor(0.2776),\n",
       " 'Embarked_C': tensor(-0.4366),\n",
       " 'Embarked_Q': tensor(0.2101),\n",
       " 'Embarked_S': tensor(0.3604)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs(coeffs_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(X, weights): \n",
    "    return torch.sigmoid(X@weights)\n",
    "\n",
    "def init_coeffs(n_wts): \n",
    "    return (torch.rand(n_wts, 1)*0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually not necessary or missed something somewhere\n",
    "# train_y = train_y[:,None]\n",
    "# valid_y = valid_y[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([712, 12]), torch.Size([712]), torch.Size([712]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, calc_preds(train_x, coeffs_est).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.318874\n",
      "  0.235403\n",
      "  0.221616\n",
      "  0.219067\n",
      "  0.218460\n",
      "  0.218004\n",
      "  0.217624\n",
      "  0.217337\n",
      "  0.217105\n",
      "  0.216918\n",
      "  0.216768\n",
      "  0.216647\n",
      "  0.216548\n",
      "  0.216465\n",
      "  0.216393\n",
      "  0.216330\n",
      "  0.216275\n",
      "  0.216225\n",
      "  0.216180\n",
      "  0.216139\n",
      "  0.216102\n",
      "  0.216068\n",
      "  0.216037\n",
      "  0.216008\n",
      "  0.215980\n",
      "  0.215954\n",
      "  0.215930\n",
      "  0.215906\n",
      "  0.215883\n",
      "  0.215861\n",
      "  0.215839\n",
      "  0.215816\n",
      "  0.215794\n",
      "  0.215771\n",
      "  0.215746\n",
      "  0.215721\n",
      "  0.215693\n",
      "  0.215663\n",
      "  0.215629\n",
      "  0.215591\n",
      "  0.215546\n",
      "  0.215493\n",
      "  0.215426\n",
      "  0.215340\n",
      "  0.215224\n",
      "  0.215057\n",
      "  0.214800\n",
      "  0.214372\n",
      "  0.213607\n",
      "  0.212264\n",
      "  0.210278\n",
      "  0.208379\n",
      "  0.207362\n",
      "  0.206743\n",
      "  0.206250\n",
      "  0.205803\n",
      "  0.205375\n",
      "  0.204952\n",
      "  0.204530\n",
      "  0.204110\n",
      "  0.203697\n",
      "  0.203301\n",
      "  0.202941\n",
      "  0.202633\n",
      "  0.202381\n",
      "  0.202172\n",
      "  0.201989\n",
      "  0.201817\n",
      "  0.201646\n",
      "  0.201473\n",
      "  0.201310\n",
      "  0.201176\n",
      "  0.201080\n",
      "  0.201014\n",
      "  0.200962\n",
      "  0.200917\n",
      "  0.200875\n",
      "  0.200840\n",
      "  0.200820\n",
      "  0.200848\n",
      "  0.201057\n",
      "  0.201594\n",
      "  0.203339\n",
      "  0.202828\n",
      "  0.205279\n",
      "  0.201076\n",
      "  0.202099\n",
      "  0.201973\n",
      "  0.203777\n",
      "  0.200332\n",
      "  0.200586\n",
      "  0.199042\n",
      "  0.198427\n",
      "  0.194869\n",
      "  0.195812\n",
      "  0.195484\n",
      "  0.196923\n",
      "  0.194680\n",
      "  0.195647\n",
      "  0.194486\n",
      "  0.195368\n",
      "  0.194073\n",
      "  0.194756\n",
      "  0.193594\n",
      "  0.194154\n",
      "  0.193071\n",
      "  0.193528\n",
      "  0.192509\n",
      "  0.192869\n",
      "  0.191874\n",
      "  0.192138\n",
      "  0.191189\n",
      "  0.191846\n",
      "  0.191036\n",
      "  0.192502\n",
      "  0.190414\n",
      "  0.191485\n",
      "  0.189173\n",
      "  0.190727\n",
      "  0.185638\n",
      "  0.182022\n",
      "  0.190488\n",
      "  0.195300\n",
      "  0.190698\n",
      "  0.213664\n",
      "  0.208850\n",
      "  0.202342\n",
      "  0.185683\n",
      "  0.197388\n",
      "  0.178106\n",
      "  0.181188\n",
      "  0.171510\n",
      "  0.170197\n",
      "  0.173971\n",
      "  0.180910\n",
      "  0.192079\n",
      "  0.185472\n",
      "  0.182367\n",
      "  0.196492\n",
      "  0.195879\n",
      "  0.198834\n",
      "  0.196956\n",
      "  0.173660\n",
      "  0.179146\n",
      "  0.187308\n",
      "  0.186352\n",
      "  0.183743\n",
      "  0.170578\n",
      "  0.169819\n",
      "  0.172775\n",
      "  0.181887\n",
      "  0.173301\n",
      "  0.170417\n",
      "  0.172143\n",
      "  0.176443\n",
      "  0.181231\n",
      "  0.178135\n",
      "  0.169577\n",
      "  0.170539\n",
      "  0.174104\n",
      "  0.180633\n",
      "  0.183207\n",
      "  0.178259\n",
      "  0.171483\n",
      "  0.170651\n",
      "  0.170281\n",
      "  0.171827\n",
      "  0.174012\n",
      "  0.176246\n",
      "  0.174374\n",
      "  0.171012\n",
      "  0.172803\n",
      "  0.175623\n",
      "  0.182272\n",
      "  0.187819\n",
      "  0.183425\n",
      "  0.176190\n",
      "  0.194420\n",
      "  0.193660\n",
      "  0.189266\n",
      "  0.180136\n",
      "  0.180886\n",
      "  0.180684\n",
      "  0.181437\n",
      "  0.174649\n",
      "  0.174703\n",
      "  0.174705\n",
      "  0.177645\n",
      "  0.175822\n",
      "  0.180520\n",
      "  0.179294\n",
      "  0.186510\n",
      "  0.186361\n",
      "  0.183592\n",
      "  0.187899\n",
      "  0.172571\n",
      "  0.171765\n",
      "  0.171720\n",
      "  0.170757\n",
      "  0.172543\n",
      "  0.172617\n",
      "  0.175044\n",
      "  0.174274\n",
      "  0.175960\n",
      "  0.174580\n",
      "  0.172233\n",
      "  0.171346\n",
      "  0.173466\n",
      "  0.174463\n",
      "  0.177823\n",
      "  0.175008\n",
      "  0.177164\n",
      "  0.181489\n",
      "  0.179506\n",
      "  0.177933\n",
      "  0.176064\n",
      "  0.178410\n",
      "  0.178758\n",
      "  0.173689\n",
      "  0.172026\n",
      "  0.177903\n",
      "  0.188136\n",
      "  0.192968\n",
      "  0.193417\n",
      "  0.186706\n",
      "  0.191854\n",
      "  0.185315\n",
      "  0.178470\n",
      "  0.169950\n",
      "  0.169216\n",
      "  0.169472\n",
      "  0.170546\n",
      "  0.170221\n",
      "  0.171015\n",
      "  0.171999\n",
      "  0.173307\n",
      "  0.176105\n",
      "  0.174087\n",
      "  0.172366\n",
      "  0.172516\n",
      "  0.176765\n",
      "  0.174911\n",
      "  0.171531\n",
      "  0.171256\n",
      "  0.174615\n",
      "  0.174807\n",
      "  0.177109\n",
      "  0.174452\n",
      "  0.176290\n",
      "  0.179941\n",
      "  0.177834\n",
      "  0.181375\n",
      "  0.177965\n",
      "  0.173703\n",
      "  0.171594\n",
      "  0.172798\n",
      "  0.175611\n",
      "  0.183209\n",
      "  0.184771\n",
      "  0.183885\n",
      "  0.180904\n",
      "  0.182357\n",
      "  0.170973\n",
      "  0.170454\n",
      "  0.171311\n",
      "  0.172485\n",
      "  0.176224\n",
      "  0.173712\n",
      "  0.172067\n",
      "  0.172689\n",
      "  0.175337\n",
      "  0.173157\n",
      "  0.170771\n",
      "  0.170879\n",
      "  0.172708\n",
      "  0.174991\n",
      "  0.176102\n",
      "  0.176619\n",
      "  0.173852\n",
      "  0.173611\n",
      "  0.176185\n",
      "  0.177329\n",
      "  0.175760\n",
      "  0.171913\n",
      "  0.169770\n",
      "  0.170618\n",
      "  0.172081\n",
      "  0.174484\n",
      "  0.175714\n",
      "  0.176090\n",
      "  0.173523\n",
      "  0.174010\n",
      "  0.176918\n",
      "  0.175369\n",
      "  0.171989\n",
      "  0.171587\n",
      "  0.172334\n",
      "  0.174365\n",
      "  0.175081\n",
      "  0.174291\n",
      " "
     ]
    }
   ],
   "source": [
    "coeffs_est = train_model(train_x, train_y, lr = 100, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-2.5086),\n",
       " 'SibSp': tensor(-1.1699),\n",
       " 'Parch': tensor(0.4923),\n",
       " 'LogFare': tensor(0.3870),\n",
       " 'Sex_male': tensor(-10.5254),\n",
       " 'Sex_female': tensor(9.9475),\n",
       " 'Pclass_1': tensor(7.6705),\n",
       " 'Pclass_2': tensor(6.9386),\n",
       " 'Pclass_3': tensor(-11.3008),\n",
       " 'Embarked_C': tensor(7.4288),\n",
       " 'Embarked_Q': tensor(5.0554),\n",
       " 'Embarked_S': tensor(-9.5792)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs(coeffs_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7486)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(valid_x, coeffs_est, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Linear/Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-6.000000e-02, -5.000000e-02, -2.000000e-02,  7.000000e-02,  6.370400e+02,  6.372800e+02,  1.616514e+04,  1.526930e+04,\n",
       "         1.876156e+04, -6.764580e+03, -4.859330e+03, -7.721810e+03], dtype=float32),\n",
       " tensor([ -2.5086,  -1.1699,   0.4923,   0.3870, -10.5254,   9.9475,   7.6705,   6.9386, -11.3008,   7.4288,   5.0554,  -9.5792])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "[np.round(reg.coef_, 2), coeffs_est]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7486), tensor(0.7542))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(valid_x, coeffs_est, valid_y), acc(valid_x, reg.coef_.T, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7821229050279329"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(train_x, train_y)\n",
    "\n",
    "accuracy_score(valid_y, reg.predict(valid_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(n_wts, n_hidden=20):\n",
    "    layer1 = (torch.rand(n_wts, n_hidden)-0.5)/n_hidden\n",
    "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(X, weights):\n",
    "    l1,l2,const = weights\n",
    "    res = F.mish(X@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, lr):\n",
    "    for layer in weights:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.325964\n",
      "  0.273374\n",
      "  0.235846\n",
      "  0.210313\n",
      "  0.192793\n",
      "  0.180467\n",
      "  0.171522\n",
      "  0.164820\n",
      "  0.159647\n",
      "  0.155552\n",
      "  0.152245\n",
      "  0.149536\n",
      "  0.147291\n",
      "  0.145414\n",
      "  0.143833\n",
      "  0.142492\n",
      "  0.141346\n",
      "  0.140361\n",
      "  0.139510\n",
      "  0.138770\n",
      "  0.138123\n",
      "  0.137554\n",
      "  0.137051\n",
      "  0.136605\n",
      "  0.136207\n",
      "  0.135851\n",
      "  0.135531\n",
      "  0.135242\n",
      "  0.134980\n",
      "  0.134742\n",
      "  0.134525\n",
      "  0.134327\n",
      "  0.134145\n",
      "  0.133977\n",
      "  0.133823\n",
      "  0.133679\n",
      "  0.133547\n",
      "  0.133423\n",
      "  0.133308\n",
      "  0.133201\n",
      "  0.133100\n",
      "  0.133005\n",
      "  0.132916\n",
      "  0.132832\n",
      "  0.132753\n",
      "  0.132678\n",
      "  0.132607\n",
      "  0.132539\n",
      "  0.132475\n",
      "  0.132413\n",
      "  0.132354\n",
      "  0.132298\n",
      "  0.132244\n",
      "  0.132192\n",
      "  0.132142\n",
      "  0.132094\n",
      "  0.132048\n",
      "  0.132003\n",
      "  0.131959\n",
      "  0.131917\n",
      "  0.131876\n",
      "  0.131836\n",
      "  0.131797\n",
      "  0.131759\n",
      "  0.131721\n",
      "  0.131685\n",
      "  0.131649\n",
      "  0.131614\n",
      "  0.131580\n",
      "  0.131546\n",
      "  0.131513\n",
      "  0.131480\n",
      "  0.131447\n",
      "  0.131415\n",
      "  0.131384\n",
      "  0.131352\n",
      "  0.131321\n",
      "  0.131290\n",
      "  0.131260\n",
      "  0.131229\n",
      "  0.131199\n",
      "  0.131169\n",
      "  0.131139\n",
      "  0.131109\n",
      "  0.131080\n",
      "  0.131050\n",
      "  0.131021\n",
      "  0.130991\n",
      "  0.130961\n",
      "  0.130932\n",
      "  0.130902\n",
      "  0.130873\n",
      "  0.130843\n",
      "  0.130814\n",
      "  0.130784\n",
      "  0.130754\n",
      "  0.130725\n",
      "  0.130695\n",
      "  0.130665\n",
      "  0.130635\n",
      "  0.130605\n",
      "  0.130574\n",
      "  0.130544\n",
      "  0.130513\n",
      "  0.130482\n",
      "  0.130452\n",
      "  0.130421\n",
      "  0.130389\n",
      "  0.130358\n",
      "  0.130326\n",
      "  0.130295\n",
      "  0.130263\n",
      "  0.130231\n",
      "  0.130198\n",
      "  0.130166\n",
      "  0.130133\n",
      "  0.130100\n",
      "  0.130067\n",
      "  0.130034\n",
      "  0.130000\n",
      "  0.129967\n",
      "  0.129933\n",
      "  0.129899\n",
      "  0.129864\n",
      "  0.129830\n",
      "  0.129795\n",
      "  0.129760\n",
      "  0.129724\n",
      "  0.129689\n",
      "  0.129653\n",
      "  0.129617\n",
      "  0.129581\n",
      "  0.129544\n",
      "  0.129508\n",
      "  0.129471\n",
      "  0.129434\n",
      "  0.129396\n",
      "  0.129359\n",
      "  0.129321\n",
      "  0.129283\n",
      "  0.129245\n",
      "  0.129206\n",
      "  0.129167\n",
      "  0.129128\n",
      "  0.129089\n",
      "  0.129050\n",
      "  0.129010\n",
      "  0.128970\n",
      "  0.128930\n",
      "  0.128890\n",
      "  0.128850\n",
      "  0.128809\n",
      "  0.128768\n",
      "  0.128727\n",
      "  0.128686\n",
      "  0.128644\n",
      "  0.128602\n",
      "  0.128561\n",
      "  0.128518\n",
      "  0.128476\n",
      "  0.128434\n",
      "  0.128391\n",
      "  0.128348\n",
      "  0.128305\n",
      "  0.128262\n",
      "  0.128218\n",
      "  0.128175\n",
      "  0.128131\n",
      "  0.128087\n",
      "  0.128043\n",
      "  0.127999\n",
      "  0.127954\n",
      "  0.127910\n",
      "  0.127865\n",
      "  0.127820\n",
      "  0.127775\n",
      "  0.127730\n",
      "  0.127684\n",
      "  0.127639\n",
      "  0.127593\n",
      "  0.127547\n",
      "  0.127501\n",
      "  0.127455\n",
      "  0.127409\n",
      "  0.127362\n",
      "  0.127316\n",
      "  0.127269\n",
      "  0.127222\n",
      "  0.127175\n",
      "  0.127128\n",
      "  0.127081\n",
      "  0.127033\n",
      "  0.126986\n",
      "  0.126938\n",
      "  0.126890\n",
      "  0.126842\n",
      "  0.126794\n",
      "  0.126746\n",
      "  0.126698\n",
      "  0.126650\n",
      "  0.126601\n",
      "  0.126553\n",
      "  0.126504\n",
      "  0.126455\n",
      "  0.126406\n",
      "  0.126357\n",
      "  0.126308\n",
      "  0.126259\n",
      "  0.126209\n",
      "  0.126160\n",
      "  0.126110\n",
      "  0.126060\n",
      "  0.126010\n",
      "  0.125960\n",
      "  0.125910\n",
      "  0.125860\n",
      "  0.125810\n",
      "  0.125759\n",
      "  0.125709\n",
      "  0.125658\n",
      "  0.125608\n",
      "  0.125557\n",
      "  0.125506\n",
      "  0.125455\n",
      "  0.125404\n",
      "  0.125352\n",
      "  0.125301\n",
      "  0.125250\n",
      "  0.125198\n",
      "  0.125146\n",
      "  0.125095\n",
      "  0.125043\n",
      "  0.124991\n",
      "  0.124939\n",
      "  0.124887\n",
      "  0.124835\n",
      "  0.124782\n",
      "  0.124730\n",
      "  0.124677\n",
      "  0.124625\n",
      "  0.124572\n",
      "  0.124519\n",
      "  0.124467\n",
      "  0.124414\n",
      "  0.124361\n",
      "  0.124308\n",
      "  0.124255\n",
      "  0.124202\n",
      "  0.124148\n",
      "  0.124095\n",
      "  0.124042\n",
      "  0.123988\n",
      "  0.123935\n",
      "  0.123881\n",
      "  0.123828\n",
      "  0.123774\n",
      "  0.123720\n",
      "  0.123667\n",
      "  0.123613\n",
      "  0.123559\n",
      "  0.123506\n",
      "  0.123452\n",
      "  0.123398\n",
      "  0.123344\n",
      "  0.123291\n",
      "  0.123237\n",
      "  0.123183\n",
      "  0.123129\n",
      "  0.123076\n",
      "  0.123022\n",
      "  0.122968\n",
      "  0.122915\n",
      "  0.122861\n",
      "  0.122808\n",
      "  0.122754\n",
      "  0.122701\n",
      "  0.122648\n",
      "  0.122595\n",
      "  0.122542\n",
      "  0.122489\n",
      "  0.122436\n",
      "  0.122383\n",
      "  0.122330\n",
      "  0.122278\n",
      "  0.122225\n",
      "  0.122173\n",
      "  0.122121\n",
      "  0.122069\n",
      "  0.122017\n",
      "  0.121966\n",
      "  0.121914\n",
      "  0.121863\n",
      "  0.121812\n",
      "  0.121761\n",
      "  0.121711\n",
      "  0.121660\n",
      "  0.121610\n",
      "  0.121560\n",
      "  0.121511\n",
      "  0.121461\n",
      "  0.121412\n",
      "  0.121363\n",
      "  0.121315\n",
      "  0.121266\n",
      "  0.121218\n",
      "  0.121170\n",
      "  0.121123\n",
      "  0.121076\n",
      "  0.121029\n",
      "  0.120982\n",
      "  0.120936\n",
      "  0.120890\n",
      "  0.120844\n",
      "  0.120799\n",
      "  0.120754\n",
      "  0.120710\n",
      "  0.120665\n",
      "  0.120621\n",
      "  0.120578\n",
      "  0.120535\n",
      "  0.120492\n",
      "  0.120449\n",
      "  0.120407\n",
      "  0.120365\n",
      "  0.120324\n",
      "  0.120283\n",
      "  0.120242\n",
      "  0.120202\n",
      "  0.120162\n",
      "  0.120122\n",
      "  0.120083\n",
      "  0.120044\n",
      "  0.120006\n",
      "  0.119967\n",
      "  0.119930\n",
      "  0.119892\n",
      "  0.119855\n",
      "  0.119819\n",
      "  0.119782\n",
      "  0.119746\n",
      "  0.119711\n",
      "  0.119675\n",
      "  0.119641\n",
      "  0.119606\n",
      "  0.119572\n",
      "  0.119538\n",
      "  0.119504\n",
      "  0.119471\n",
      "  0.119438\n",
      "  0.119406\n",
      "  0.119374\n",
      "  0.119342\n",
      "  0.119310\n",
      "  0.119279\n",
      "  0.119248\n",
      "  0.119218\n",
      "  0.119188\n",
      "  0.119158\n",
      "  0.119128\n",
      "  0.119099\n",
      "  0.119070\n",
      "  0.119041\n",
      "  0.119013\n",
      "  0.118985\n",
      "  0.118957\n",
      "  0.118929\n",
      "  0.118902\n",
      "  0.118875\n",
      "  0.118848\n",
      "  0.118822\n",
      "  0.118796\n",
      "  0.118770\n",
      "  0.118744\n",
      "  0.118719\n",
      "  0.118694\n",
      "  0.118669\n",
      "  0.118644\n",
      "  0.118620\n",
      "  0.118595\n",
      "  0.118571\n",
      "  0.118548\n",
      "  0.118524\n",
      "  0.118501\n",
      "  0.118478\n",
      "  0.118455\n",
      "  0.118432\n",
      "  0.118409\n",
      "  0.118387\n",
      "  0.118365\n",
      "  0.118343\n",
      "  0.118322\n",
      "  0.118300\n",
      "  0.118279\n",
      "  0.118258\n",
      "  0.118237\n",
      "  0.118216\n",
      "  0.118195\n",
      "  0.118175\n",
      "  0.118155\n",
      "  0.118134\n",
      "  0.118114\n",
      "  0.118095\n",
      "  0.118075\n",
      "  0.118056\n",
      "  0.118036\n",
      "  0.118017\n",
      "  0.117998\n",
      "  0.117979\n",
      "  0.117960\n",
      "  0.117942\n",
      "  0.117923\n",
      "  0.117905\n",
      "  0.117887\n",
      "  0.117869\n",
      "  0.117851\n",
      "  0.117833\n",
      "  0.117815\n",
      "  0.117798\n",
      "  0.117780\n",
      "  0.117763\n",
      "  0.117745\n",
      "  0.117728\n",
      "  0.117711\n",
      "  0.117694\n",
      "  0.117678\n",
      "  0.117661\n",
      "  0.117644\n",
      "  0.117628\n",
      "  0.117611\n",
      "  0.117595\n",
      "  0.117579\n",
      "  0.117563\n",
      "  0.117547\n",
      "  0.117531\n",
      "  0.117515\n",
      "  0.117499\n",
      "  0.117483\n",
      "  0.117468\n",
      "  0.117452\n",
      "  0.117437\n",
      "  0.117422\n",
      "  0.117406\n",
      "  0.117391\n",
      "  0.117376\n",
      "  0.117361\n",
      "  0.117346\n",
      "  0.117331\n",
      "  0.117316\n",
      "  0.117302\n",
      "  0.117287\n",
      "  0.117272\n",
      "  0.117258\n",
      "  0.117243\n",
      "  0.117229\n",
      "  0.117215\n",
      "  0.117200\n",
      "  0.117186\n",
      "  0.117172\n",
      "  0.117158\n",
      "  0.117144\n",
      "  0.117130\n",
      "  0.117116\n",
      "  0.117102\n",
      "  0.117088\n",
      "  0.117075\n",
      "  0.117061\n",
      "  0.117047\n",
      "  0.117034\n",
      "  0.117020\n",
      "  0.117007\n",
      "  0.116994\n",
      "  0.116980\n",
      "  0.116967\n",
      "  0.116954\n",
      "  0.116940\n",
      "  0.116927\n",
      "  0.116914\n",
      "  0.116901\n",
      "  0.116888\n",
      "  0.116875\n",
      "  0.116862\n",
      "  0.116849\n",
      "  0.116837\n",
      "  0.116824\n",
      "  0.116811\n",
      "  0.116798\n",
      "  0.116786\n",
      "  0.116773\n",
      "  0.116761\n",
      "  0.116748\n",
      "  0.116736\n",
      "  0.116723\n",
      "  0.116711\n",
      "  0.116698\n",
      "  0.116686\n",
      "  0.116674\n",
      "  0.116661\n",
      "  0.116649\n",
      "  0.116637\n",
      "  0.116625\n",
      " "
     ]
    }
   ],
   "source": [
    "coeffs_est = train_model(train_x, train_y, epochs=500, lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8455), tensor(0.7933), 0.7821229050279329)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(train_x, coeffs_est, train_y), acc(valid_x, coeffs_est, valid_y), accuracy_score(valid_y, reg.predict(valid_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(n_wts, hiddens):  \n",
    "    sizes = [n_wts] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers,consts\n",
    "\n",
    "def calc_preds(X, weights):\n",
    "    layers,consts = weights\n",
    "    n = len(layers)\n",
    "    res = X\n",
    "    for i,l in enumerate(layers):\n",
    "        res = res@l + consts[i]\n",
    "        if i!=n-1: res = F.mish(res)\n",
    "    return torch.sigmoid(res).flatten()\n",
    "\n",
    "def update_weights(weights, lr):\n",
    "    layers,consts = weights\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()\n",
    "\n",
    "def train_model(X, target, hiddens = [10, 10], epochs=30, lr=1e-3, verbose = 1):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_weights(X.shape[1], hiddens)\n",
    "    \n",
    "    for i in range(epochs): \n",
    "        if verbose != 0:\n",
    "            one_epoch(X, coeffs, target, lr=lr, verbose=verbose, i = i)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.242860\n",
      "  0.123036\n",
      "  0.118542\n",
      "  0.116180\n",
      "  0.114762\n",
      "  0.111998\n",
      "  0.111303\n",
      "  0.109473\n",
      "  0.109234\n",
      "  0.107875\n",
      "  0.106611\n",
      "  0.105218\n",
      "  0.104263\n",
      "  0.104574\n",
      "  0.102063\n",
      "  0.100089\n",
      "  0.099092\n",
      "  0.097936\n",
      "  0.097228\n",
      "  0.096454\n",
      " "
     ]
    }
   ],
   "source": [
    "coeffs_est = train_model(train_x, train_y, hiddens = [10, 10], epochs=500, lr=4, verbose=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_glm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.876405</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.782123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_test   acc_glm\n",
       "0   0.876405  0.798883  0.782123"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'acc_train': acc(train_x, coeffs_est, train_y).flatten(), \n",
    "    'acc_test': acc(valid_x, coeffs_est, valid_y).flatten(), \n",
    "    'acc_glm': accuracy_score(valid_y, reg.predict(valid_x)).round(6),\n",
    "    \n",
    "}, index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('xgb_lgb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8158d036b72d77975b18648f9fa7ae4a6c25950790cb1758425656b8f1c45f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
