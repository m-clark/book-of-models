{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_happiness = (\n",
    "    pd.read_csv('https://tinyurl.com/worldhappiness2018')\n",
    "    .dropna()\n",
    "    .rename(columns = {'happiness_score': 'happiness'})\n",
    "    .filter(regex = '_sc|country|happ')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE comparison between the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>5.086298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.637560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       MSE\n",
       "0     A  5.086298\n",
       "1     B  0.637560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_happiness['happiness']\n",
    "\n",
    "# Calculate the error for the guess of four\n",
    "prediction = np.min(df_happiness['happiness']) + 1 * df_happiness['life_exp_sc']\n",
    "mse_model_A   = np.mean((y - prediction)**2)\n",
    "\n",
    "# Calculate the error for our other guess\n",
    "prediction = y.mean() + .5 * df_happiness['life_exp_sc']\n",
    "mse_model_B  = np.mean((y - prediction)**2)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Model': ['A', 'B'],\n",
    "    'MSE': [mse_model_A, mse_model_B]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for later comparison\n",
    "model_lr_happy = smf.ols('happiness ~ life_exp_sc', data = df_happiness).fit()\n",
    "\n",
    "def ols(par, X, y):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate the predicted values\n",
    "    y_hat = X @ par  # @ is matrix multiplication\n",
    "    \n",
    "    # Calculate the mean of the squared errors\n",
    "    value = np.mean((y - y_hat)**2)\n",
    "    \n",
    "    # Return the objective value\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.77700449624871"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "guesses = pd.DataFrame(\n",
    "    product(\n",
    "        np.arange(1, 7, 0.1),\n",
    "        np.arange(-1, 1, 0.1)\n",
    "    ),\n",
    "    columns = ['b0', 'b1']\n",
    ")\n",
    "\n",
    "# Example for one guess\n",
    "ols(\n",
    "    par = guesses.iloc[0,:],\n",
    "    X = df_happiness['life_exp_sc'],\n",
    "    y = df_happiness['happiness']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>5.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.490675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b0   b1  objective\n",
       "899  5.4  0.9   0.490675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses['objective'] = guesses.apply(\n",
    "    lambda x: ols(\n",
    "        par = x, \n",
    "        X = df_happiness['life_exp_sc'], \n",
    "        y = df_happiness['happiness']\n",
    "    ),\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "min_loss = guesses[guesses['objective'] == guesses['objective'].min()]\n",
    "\n",
    "min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(const          5.444832\n",
       " life_exp_sc    0.887796\n",
       " dtype: float64,\n",
       " 0.4973994106686574)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_happy_life = sm.OLS(df_happiness['happiness'], sm.add_constant(df_happiness['life_exp_sc'])).fit()\n",
    "\n",
    "model_lr_happy_life.params, model_lr_happy_life.scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 0.48851727833528863\n",
       "        x: [ 5.445e+00  8.878e-01]\n",
       "      nit: 5\n",
       "      jac: [-7.451e-09  0.000e+00]\n",
       " hess_inv: [[ 5.000e-01  3.539e-06]\n",
       "            [ 3.539e-06  5.045e-01]]\n",
       "     nfev: 21\n",
       "     njev: 7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_ols_optim = minimize(\n",
    "    fun  = ols,\n",
    "    x0   = np.array([1., 0.]),\n",
    "    args = (\n",
    "        np.array(df_happiness['life_exp_sc']), \n",
    "        np.array(df_happiness['happiness'])\n",
    "    ),\n",
    "    method  = 'BFGS',   # optimization algorithm\n",
    "    tol     = 1e-6,     # tolerance\n",
    "    options = {\n",
    "        'maxiter': 500  # max iterations\n",
    "    }\n",
    ")\n",
    "\n",
    "our_ols_optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10798193, 0.22184167])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two example life expectancy scores, at the mean (0) and 1 sd above\n",
    "life_expectancy = np.array([0, 1])\n",
    "\n",
    "# observed happiness scores\n",
    "happiness = np.array([4, 5.2])\n",
    "\n",
    "# predicted happiness with rounded coefs\n",
    "mu = 5 + 1 * life_expectancy\n",
    "\n",
    "# just a guess for sigma\n",
    "sigma = .5\n",
    "\n",
    "# likelihood for each observation\n",
    "L = norm.pdf(happiness, loc = mu, scale = sigma)\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35819022,  5.44483214,  0.88779604])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_likelihood(par, X, y):\n",
    "    \n",
    "    # setup\n",
    "    X = np.c_[np.ones(X.shape[0]), X] # add a column of 1s for the intercept\n",
    "    beta   = par[1:]         # coefficients\n",
    "    sigma  = np.exp(par[0])  # error sd, exp keeps positive\n",
    "    N = X.shape[0]\n",
    "\n",
    "    LP = X @ beta            # linear predictor\n",
    "    mu = LP                  # identity link in the glm sense\n",
    "\n",
    "    # calculate (log) likelihood\n",
    "    ll = norm.logpdf(y, loc = mu, scale = sigma)\n",
    "\n",
    "    value = -np.sum(ll)      # negative for minimization\n",
    "\n",
    "    return value\n",
    "\n",
    "our_max_like = minimize(\n",
    "    fun  = max_likelihood,\n",
    "    x0   = np.array([1, 0, 0]),\n",
    "    args = (\n",
    "        np.array(df_happiness['life_exp_sc']), \n",
    "        np.array(df_happiness['happiness'])\n",
    "    )\n",
    ")\n",
    "\n",
    "our_max_like['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use lambda_ because lambda is a reserved word in python\n",
    "def ridge(par, X, y, lambda_ = 0):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate the predicted values\n",
    "    mu = X @ par\n",
    "    \n",
    "    # Calculate the error\n",
    "    value = np.sum((y - mu)**2)\n",
    "    \n",
    "    # Add the penalty\n",
    "    value = value + lambda_ * np.sum(par**2)\n",
    "    \n",
    "    return value\n",
    "\n",
    "our_ridge = minimize(\n",
    "    fun  = ridge,\n",
    "    x0   = np.array([0, 0, 0, 0]),\n",
    "    args = (\n",
    "        np.array(df_happiness.drop(columns=['happiness', 'country'])),\n",
    "        np.array(df_happiness['happiness']), \n",
    "        0.1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.439975  ,  0.52422716, -0.1053189 ,  0.43749604])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_ridge['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassification_rate(par, X, y, class_threshold = .5):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate the 'linear predictor'\n",
    "    mu = X @ par \n",
    "    \n",
    "    # Convert to a probability ('sigmoid' function)\n",
    "    p = 1 / (1 + np.exp(-mu))\n",
    "    \n",
    "    # Convert to a class\n",
    "    predicted_class = np.where(p > class_threshold, 1, 0)\n",
    "    \n",
    "    # Calculate the mean error\n",
    "    value = np.mean(y - predicted_class)\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(par, X, y):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate the predicted values\n",
    "    y_hat = X @ par\n",
    "    \n",
    "    # Convert to a probability ('sigmoid' function)\n",
    "    y_hat = 1 / (1 + np.exp(-y_hat))\n",
    "    \n",
    "    # likelihood\n",
    "    ll = y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)\n",
    "\n",
    "    value = -np.sum(ll)\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16365245,  1.81715104, -0.46478325,  1.13108169])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_happiness_bin = df_happiness.copy()\n",
    "df_happiness_bin['happiness'] = np.where(df_happiness['happiness'] > 5.5, 1, 0)\n",
    "\n",
    "model_logloss = minimize(\n",
    "    log_loss,\n",
    "    x0 = np.array([0, 0, 0, 0]),\n",
    "    args = (\n",
    "        df_happiness_bin[['life_exp_sc', 'corrupt_sc', 'gdp_pc_sc']],\n",
    "        df_happiness_bin['happiness']\n",
    "    )\n",
    ")\n",
    "\n",
    "model_glm = smf.glm(\n",
    "    'happiness ~ life_exp_sc + corrupt_sc + gdp_pc_sc',\n",
    "    data   = df_happiness_bin,\n",
    "    family = sm.families.Binomial()\n",
    ").fit()\n",
    "\n",
    "model_logloss['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    par, \n",
    "    X, \n",
    "    y, \n",
    "    tolerance = 1e-3, \n",
    "    maxit = 1000, \n",
    "    learning_rate = 1e-3\n",
    "):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "    \n",
    "    # initialize\n",
    "    beta = par\n",
    "    loss = np.sum((X @ beta - y)**2)\n",
    "    tol = 1\n",
    "    iter = 1\n",
    "\n",
    "    while (tol > tolerance and iter < maxit):\n",
    "        LP = X @ beta\n",
    "        grad = X.T @ (LP - y)\n",
    "        betaCurrent = beta - learning_rate * grad\n",
    "        tol = np.max(np.abs(betaCurrent - beta))\n",
    "        beta = betaCurrent\n",
    "        loss = np.append(loss, np.sum((LP - y)**2))\n",
    "        iter = iter + 1\n",
    "\n",
    "    output = {\n",
    "        'par': beta,\n",
    "        'loss': loss,\n",
    "        'MSE': np.mean((LP - y)**2),\n",
    "        'iter': iter,\n",
    "        'fitted': LP\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "our_gd = gradient_descent(\n",
    "    par = np.array([0, 0, 0, 0]),\n",
    "    X = df_happiness[['life_exp_sc', 'corrupt_sc', 'gdp_pc_sc']].to_numpy(),\n",
    "    y = df_happiness['happiness'].to_numpy(),\n",
    "    learning_rate = 1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.43691264,  0.52121949, -0.10746734,  0.43896778])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_gd['par']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x6/4jhswqxj0sqf_gkgq6lw6l880000gn/T/ipykernel_38163/2270994482.py:55: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fits[i] = LP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 5.42765734,  0.53391505, -0.15014284,  0.39964098]),\n",
       " 0.36857925293717886)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_gradient_descent(\n",
    "    par, # parameter estimates\n",
    "    X,   # model matrix\n",
    "    y,   # target variable\n",
    "    learning_rate = 1, # the learning rate\n",
    "    stepsize_tau = 0,  # if > 0, a check on the LR at early iterations\n",
    "    average = False    # a variation of the approach\n",
    "):\n",
    "    # initialize\n",
    "    np.random.seed(1234)\n",
    "\n",
    "    # shuffle the data\n",
    "    idx = np.random.choice(\n",
    "        df_happiness.shape[0], \n",
    "        df_happiness.shape[0], \n",
    "        replace = False\n",
    "    )\n",
    "    X = X[idx, :]\n",
    "    y = y[idx]\n",
    "    \n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "    beta = par\n",
    "\n",
    "    # Collect all estimates\n",
    "    betamat = np.zeros((X.shape[0], beta.shape[0]))\n",
    "\n",
    "    # Collect fitted values at each point))\n",
    "    fits = np.zeros(X.shape[0])\n",
    "\n",
    "    # Collect loss at each point\n",
    "    loss = np.zeros(X.shape[0])\n",
    "\n",
    "    # adagrad per parameter learning rate adjustment\n",
    "    s = 0\n",
    "\n",
    "    # a smoothing term to avoid division by zero\n",
    "    eps = 1e-8\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        Xi = X[None, i, :]\n",
    "        yi = y[i]\n",
    "\n",
    "        # matrix operations not necessary here,\n",
    "        # but makes consistent with previous gd func\n",
    "        LP = Xi @ beta\n",
    "        grad = Xi.T @ (LP - yi)\n",
    "        s = s + grad**2 # adagrad approach\n",
    "\n",
    "        # update\n",
    "        beta = beta - learning_rate / \\\n",
    "            (stepsize_tau + np.sqrt(s + eps)) * grad\n",
    "\n",
    "        betamat[i, :] = beta\n",
    "\n",
    "        fits[i] = LP\n",
    "        loss[i] = np.sum((LP - yi)**2)\n",
    "\n",
    "    LP = X @ beta\n",
    "    lastloss = np.sum((LP - y)**2)\n",
    "\n",
    "    output = {\n",
    "        'par': beta,          # final estimates\n",
    "        'par_chain': betamat, # estimates at each iteration\n",
    "        'MSE': lastloss / X.shape[0],\n",
    "        'predictions': LP\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "X = df_happiness[['life_exp_sc', 'corrupt_sc', 'gdp_pc_sc']].to_numpy()\n",
    "y = df_happiness['happiness'].to_numpy()\n",
    "\n",
    "our_sgd = stochastic_gradient_descent(\n",
    "    par = np.array([np.mean(df_happiness['happiness']), 0, 0, 0]),\n",
    "    X = X,\n",
    "    y = y,\n",
    "    learning_rate = .15,\n",
    "    stepsize_tau = .1\n",
    ")\n",
    "\n",
    "our_sgd['par'], our_sgd['MSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.987671</td>\n",
       "      <td>0.132758</td>\n",
       "      <td>3.724521</td>\n",
       "      <td>4.250820</td>\n",
       "      <td>2.736966</td>\n",
       "      <td>5.238375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.496638</td>\n",
       "      <td>0.104065</td>\n",
       "      <td>5.290363</td>\n",
       "      <td>5.702914</td>\n",
       "      <td>4.256653</td>\n",
       "      <td>6.736624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.676520</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>5.503139</td>\n",
       "      <td>5.849901</td>\n",
       "      <td>4.441580</td>\n",
       "      <td>6.911459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.406585</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>5.194492</td>\n",
       "      <td>5.618678</td>\n",
       "      <td>4.165618</td>\n",
       "      <td>6.647552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.966640</td>\n",
       "      <td>0.126756</td>\n",
       "      <td>6.715389</td>\n",
       "      <td>7.217892</td>\n",
       "      <td>5.718385</td>\n",
       "      <td>8.214896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5.861256</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>5.706850</td>\n",
       "      <td>6.015661</td>\n",
       "      <td>4.628837</td>\n",
       "      <td>7.093674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5.290368</td>\n",
       "      <td>0.147161</td>\n",
       "      <td>4.998669</td>\n",
       "      <td>5.582067</td>\n",
       "      <td>4.033347</td>\n",
       "      <td>6.547389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5.327998</td>\n",
       "      <td>0.083659</td>\n",
       "      <td>5.162170</td>\n",
       "      <td>5.493825</td>\n",
       "      <td>4.094096</td>\n",
       "      <td>6.561899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4.308105</td>\n",
       "      <td>0.101039</td>\n",
       "      <td>4.107828</td>\n",
       "      <td>4.508383</td>\n",
       "      <td>3.069103</td>\n",
       "      <td>5.547107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4.267325</td>\n",
       "      <td>0.098283</td>\n",
       "      <td>4.072511</td>\n",
       "      <td>4.462139</td>\n",
       "      <td>3.029194</td>\n",
       "      <td>5.505455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0    3.987671  0.132758       3.724521       4.250820      2.736966   \n",
       "1    5.496638  0.104065       5.290363       5.702914      4.256653   \n",
       "2    5.676520  0.087470       5.503139       5.849901      4.441580   \n",
       "3    5.406585  0.107000       5.194492       5.618678      4.165618   \n",
       "4    6.966640  0.126756       6.715389       7.217892      5.718385   \n",
       "..        ...       ...            ...            ...           ...   \n",
       "107  5.861256  0.077897       5.706850       6.015661      4.628837   \n",
       "108  5.290368  0.147161       4.998669       5.582067      4.033347   \n",
       "109  5.327998  0.083659       5.162170       5.493825      4.094096   \n",
       "110  4.308105  0.101039       4.107828       4.508383      3.069103   \n",
       "111  4.267325  0.098283       4.072511       4.462139      3.029194   \n",
       "\n",
       "     obs_ci_upper  \n",
       "0        5.238375  \n",
       "1        6.736624  \n",
       "2        6.911459  \n",
       "3        6.647552  \n",
       "4        8.214896  \n",
       "..            ...  \n",
       "107      7.093674  \n",
       "108      6.547389  \n",
       "109      6.561899  \n",
       "110      5.547107  \n",
       "111      5.505455  \n",
       "\n",
       "[112 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.ols(\n",
    "    'happiness ~ life_exp_sc + corrupt_sc + gdp_pc_sc',\n",
    "    data = df_happiness\n",
    ").fit()\n",
    "\n",
    "model.conf_int()\n",
    "\n",
    "model.get_prediction().summary_frame() # both 'confidence' and 'prediction' intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.987671</td>\n",
       "      <td>0.132758</td>\n",
       "      <td>3.724521</td>\n",
       "      <td>4.250820</td>\n",
       "      <td>2.736966</td>\n",
       "      <td>5.238375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.496638</td>\n",
       "      <td>0.104065</td>\n",
       "      <td>5.290363</td>\n",
       "      <td>5.702914</td>\n",
       "      <td>4.256653</td>\n",
       "      <td>6.736624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.676520</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>5.503139</td>\n",
       "      <td>5.849901</td>\n",
       "      <td>4.441580</td>\n",
       "      <td>6.911459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.406585</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>5.194492</td>\n",
       "      <td>5.618678</td>\n",
       "      <td>4.165618</td>\n",
       "      <td>6.647552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.966640</td>\n",
       "      <td>0.126756</td>\n",
       "      <td>6.715389</td>\n",
       "      <td>7.217892</td>\n",
       "      <td>5.718385</td>\n",
       "      <td>8.214896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5.861256</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>5.706850</td>\n",
       "      <td>6.015661</td>\n",
       "      <td>4.628837</td>\n",
       "      <td>7.093674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5.290368</td>\n",
       "      <td>0.147161</td>\n",
       "      <td>4.998669</td>\n",
       "      <td>5.582067</td>\n",
       "      <td>4.033347</td>\n",
       "      <td>6.547389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5.327998</td>\n",
       "      <td>0.083659</td>\n",
       "      <td>5.162170</td>\n",
       "      <td>5.493825</td>\n",
       "      <td>4.094096</td>\n",
       "      <td>6.561899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4.308105</td>\n",
       "      <td>0.101039</td>\n",
       "      <td>4.107828</td>\n",
       "      <td>4.508383</td>\n",
       "      <td>3.069103</td>\n",
       "      <td>5.547107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4.267325</td>\n",
       "      <td>0.098283</td>\n",
       "      <td>4.072511</td>\n",
       "      <td>4.462139</td>\n",
       "      <td>3.029194</td>\n",
       "      <td>5.505455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0    3.987671  0.132758       3.724521       4.250820      2.736966   \n",
       "1    5.496638  0.104065       5.290363       5.702914      4.256653   \n",
       "2    5.676520  0.087470       5.503139       5.849901      4.441580   \n",
       "3    5.406585  0.107000       5.194492       5.618678      4.165618   \n",
       "4    6.966640  0.126756       6.715389       7.217892      5.718385   \n",
       "..        ...       ...            ...            ...           ...   \n",
       "107  5.861256  0.077897       5.706850       6.015661      4.628837   \n",
       "108  5.290368  0.147161       4.998669       5.582067      4.033347   \n",
       "109  5.327998  0.083659       5.162170       5.493825      4.094096   \n",
       "110  4.308105  0.101039       4.107828       4.508383      3.069103   \n",
       "111  4.267325  0.098283       4.072511       4.462139      3.029194   \n",
       "\n",
       "     obs_ci_upper  \n",
       "0        5.238375  \n",
       "1        6.736624  \n",
       "2        6.911459  \n",
       "3        6.647552  \n",
       "4        8.214896  \n",
       "..            ...  \n",
       "107      7.093674  \n",
       "108      6.547389  \n",
       "109      6.561899  \n",
       "110      5.547107  \n",
       "111      5.505455  \n",
       "\n",
       "[112 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_prediction().summary_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use the model from the previous section\n",
    "model = smf.ols(\n",
    "    'happiness ~ life_exp_sc + corrupt_sc + gdp_pc_sc',\n",
    "    data = df_happiness\n",
    ").fit()\n",
    "\n",
    "def mc_predictions(model, nsim=2500, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    params_est = model.params\n",
    "    params = np.random.multivariate_normal(\n",
    "        mean = params_est,\n",
    "        cov = model.cov_params(),\n",
    "        size = nsim\n",
    "    )\n",
    "\n",
    "    sigma = model.mse_resid**.5\n",
    "    X = model.model.exog\n",
    "\n",
    "    y_hat = X @ params.T + np.random.normal(scale = sigma, size = (X.shape[0], nsim))\n",
    "\n",
    "    pred_int = np.quantile(y_hat, q = [.025, .975], axis = 1)\n",
    "\n",
    "    return pred_int\n",
    "\n",
    "our_mc = mc_predictions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed_value</th>\n",
       "      <th>prediction</th>\n",
       "      <th>simulated_lower</th>\n",
       "      <th>simulated_upper</th>\n",
       "      <th>statsmodels_lower</th>\n",
       "      <th>statsmodels_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.632</td>\n",
       "      <td>3.988</td>\n",
       "      <td>2.770</td>\n",
       "      <td>5.197</td>\n",
       "      <td>2.737</td>\n",
       "      <td>5.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.586</td>\n",
       "      <td>5.497</td>\n",
       "      <td>4.278</td>\n",
       "      <td>6.759</td>\n",
       "      <td>4.257</td>\n",
       "      <td>6.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.388</td>\n",
       "      <td>5.677</td>\n",
       "      <td>4.451</td>\n",
       "      <td>6.889</td>\n",
       "      <td>4.442</td>\n",
       "      <td>6.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.321</td>\n",
       "      <td>5.407</td>\n",
       "      <td>4.218</td>\n",
       "      <td>6.666</td>\n",
       "      <td>4.166</td>\n",
       "      <td>6.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.272</td>\n",
       "      <td>6.967</td>\n",
       "      <td>5.733</td>\n",
       "      <td>8.167</td>\n",
       "      <td>5.718</td>\n",
       "      <td>8.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6.379</td>\n",
       "      <td>5.861</td>\n",
       "      <td>4.670</td>\n",
       "      <td>7.090</td>\n",
       "      <td>4.629</td>\n",
       "      <td>7.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.096</td>\n",
       "      <td>5.290</td>\n",
       "      <td>4.057</td>\n",
       "      <td>6.547</td>\n",
       "      <td>4.033</td>\n",
       "      <td>6.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4.806</td>\n",
       "      <td>5.328</td>\n",
       "      <td>4.126</td>\n",
       "      <td>6.530</td>\n",
       "      <td>4.094</td>\n",
       "      <td>6.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4.377</td>\n",
       "      <td>4.308</td>\n",
       "      <td>3.097</td>\n",
       "      <td>5.531</td>\n",
       "      <td>3.069</td>\n",
       "      <td>5.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3.692</td>\n",
       "      <td>4.267</td>\n",
       "      <td>3.037</td>\n",
       "      <td>5.523</td>\n",
       "      <td>3.029</td>\n",
       "      <td>5.505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     observed_value  prediction  simulated_lower  simulated_upper  \\\n",
       "0             3.632       3.988            2.770            5.197   \n",
       "1             4.586       5.497            4.278            6.759   \n",
       "2             6.388       5.677            4.451            6.889   \n",
       "3             4.321       5.407            4.218            6.666   \n",
       "4             7.272       6.967            5.733            8.167   \n",
       "..              ...         ...              ...              ...   \n",
       "107           6.379       5.861            4.670            7.090   \n",
       "108           6.096       5.290            4.057            6.547   \n",
       "109           4.806       5.328            4.126            6.530   \n",
       "110           4.377       4.308            3.097            5.531   \n",
       "111           3.692       4.267            3.037            5.523   \n",
       "\n",
       "     statsmodels_lower  statsmodels_upper  \n",
       "0                2.737              5.238  \n",
       "1                4.257              6.737  \n",
       "2                4.442              6.911  \n",
       "3                4.166              6.648  \n",
       "4                5.718              8.215  \n",
       "..                 ...                ...  \n",
       "107              4.629              7.094  \n",
       "108              4.033              6.547  \n",
       "109              4.094              6.562  \n",
       "110              3.069              5.547  \n",
       "111              3.029              5.505  \n",
       "\n",
       "[112 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statsmodels Prediction Intervals\n",
    "prediction_intervals = model.get_prediction().summary_frame()\n",
    "statsmodels_lower = prediction_intervals['obs_ci_lower']\n",
    "statsmodels_upper = prediction_intervals['obs_ci_upper']\n",
    "\n",
    "\n",
    "pd.DataFrame({\n",
    "    'observed_value': df_happiness['happiness'],\n",
    "    'prediction': model.fittedvalues,\n",
    "    'simulated_lower': our_mc[0],\n",
    "    'simulated_upper': our_mc[1],\n",
    "    'statsmodels_lower': statsmodels_lower,\n",
    "    'statsmodels_upper': statsmodels_upper\n",
    "}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, y, nboot=100, seed=123):\n",
    "    # add a column of 1s for the intercept\n",
    "    X = np.c_[np.ones(X.shape[0]), X]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # initialize\n",
    "    beta = np.empty((nboot, X.shape[1]))\n",
    "    \n",
    "    # beta = pd.DataFrame(beta, columns=['Intercept'] + list(cn))\n",
    "    mse = np.empty(nboot)    \n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for i in range(nboot):\n",
    "        # sample with replacement\n",
    "        idx = np.random.randint(0, N, N)\n",
    "        Xi = X[idx, :]\n",
    "        yi = y[idx]\n",
    "\n",
    "        # estimate model\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        mod = model.fit(Xi, yi)\n",
    "\n",
    "        # save results\n",
    "        beta[i, :] = mod.coef_\n",
    "        mse[i] = np.sum((mod.predict(Xi) - yi)**2) / N\n",
    "\n",
    "    # given mean estimates, calculate MSE\n",
    "    y_hat = X @ beta.mean(axis=0)\n",
    "    final_mse = np.sum((y - y_hat)**2) / N\n",
    "\n",
    "    output = {\n",
    "        'par': beta,\n",
    "        'mse': mse,\n",
    "        'final_mse': final_mse\n",
    "    }\n",
    "\n",
    "    return output\n",
    "\n",
    "our_boot = bootstrap(\n",
    "    X = df_happiness[['life_exp_sc', 'corrupt_sc', 'gdp_pc_sc']],\n",
    "    y = df_happiness['happiness'],\n",
    "    nboot = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.34092479,  0.27665819, -0.29543964,  0.19114177])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(our_boot['par'], 2.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>mean</th>\n",
       "      <th>lwr</th>\n",
       "      <th>upr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>5.451703</td>\n",
       "      <td>5.340925</td>\n",
       "      <td>5.572782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>life_exp_sc</td>\n",
       "      <td>0.511917</td>\n",
       "      <td>0.276658</td>\n",
       "      <td>0.754842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corrupt_sc</td>\n",
       "      <td>-0.106482</td>\n",
       "      <td>-0.295440</td>\n",
       "      <td>0.080125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gdp_pc_sc</td>\n",
       "      <td>0.459829</td>\n",
       "      <td>0.191142</td>\n",
       "      <td>0.776553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         param      mean       lwr       upr\n",
       "0    Intercept  5.451703  5.340925  5.572782\n",
       "1  life_exp_sc  0.511917  0.276658  0.754842\n",
       "2   corrupt_sc -0.106482 -0.295440  0.080125\n",
       "3    gdp_pc_sc  0.459829  0.191142  0.776553"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'param': ['Intercept', 'life_exp_sc', 'corrupt_sc', 'gdp_pc_sc'],\n",
    "    'mean': our_boot['par'].mean(axis=0),\n",
    "    'lwr': np.percentile(our_boot['par'], 2.5, axis=0),\n",
    "    'upr': np.percentile(our_boot['par'], 97.5, axis=0)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x6/4jhswqxj0sqf_gkgq6lw6l880000gn/T/ipykernel_38163/1473881323.py:27: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  p_data_given_theta = np.math.comb(N, n_goal) * theta**n_goal * (1 - theta)**n_miss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.599999996503221"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "pk = np.array([\n",
    "    'goal','goal','goal','miss','miss',\n",
    "    'goal','goal','miss','goal','goal'\n",
    "])\n",
    "\n",
    "# convert to numeric, arbitrarily picking goal=1, miss=0\n",
    "N = len(pk)                     # sample size\n",
    "n_goal = np.sum(pk == 'goal')   # number of pk made\n",
    "n_miss = np.sum(pk == 'miss')   # number of those miss\n",
    "\n",
    "# grid of potential theta values\n",
    "theta = np.linspace(1 / (N + 1), N / (N + 1), 10)\n",
    "\n",
    "### prior distribution\n",
    "# beta prior with mean = .5, but fairly diffuse\n",
    "# examine the prior\n",
    "# theta = beta.rvs(5, 5, size = 1000)\n",
    "# plt.hist(theta, bins = 20, color = 'lightblue')\n",
    "p_theta = beta.pdf(theta, 5, 5)\n",
    "\n",
    "# Normalize so that values sum to 1\n",
    "p_theta = p_theta / np.sum(p_theta)\n",
    "\n",
    "# likelihood (binomial)\n",
    "p_data_given_theta = np.math.comb(N, n_goal) * theta**n_goal * (1 - theta)**n_miss\n",
    "\n",
    "# posterior (combination of prior and likelihood)\n",
    "# marginal probability of the data used for normalization\n",
    "p_data = np.sum(p_data_given_theta * p_theta) \n",
    "\n",
    "p_theta_given_data = p_data_given_theta * p_theta / p_data  # Bayes theorem\n",
    "\n",
    "# final estimate\n",
    "theta_est = np.sum(theta * p_theta_given_data)\n",
    "theta_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conformal(X, y, new_data, alpha = .05, calibration_split = .5):\n",
    "    # Splitting the data into training and calibration sets\n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(\n",
    "        X, \n",
    "        y,\n",
    "        test_size = calibration_split,\n",
    "        random_state = 123\n",
    "    )\n",
    "\n",
    "    N = X_train.shape[0]\n",
    "\n",
    "    # Train the base model\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Calculate residuals on calibration set\n",
    "    cal_preds = model.predict(X_cal)\n",
    "    residuals = np.abs(y_cal - cal_preds)\n",
    "\n",
    "    # Sort residuals and find the quantile corresponding to (1-alpha)\n",
    "    residuals = np.sort(residuals)\n",
    "\n",
    "    # The correction here is useful for small sample sizes\n",
    "    quantile  = np.quantile(residuals, (1 - alpha) * (N / (N + 1)))\n",
    "\n",
    "    # Make predictions on new data and calculate prediction intervals\n",
    "    preds = model.predict(new_data)\n",
    "    lower_bounds = preds - quantile\n",
    "    upper_bounds = preds + quantile\n",
    "\n",
    "    # Return predictions and prediction intervals\n",
    "    return {\n",
    "        'cp_error': quantile,\n",
    "        'preds': preds,\n",
    "        'lower_bounds': lower_bounds,\n",
    "        'upper_bounds': upper_bounds\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1358174413022732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>lower_bounds</th>\n",
       "      <th>upper_bounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.669552</td>\n",
       "      <td>3.533734</td>\n",
       "      <td>5.805369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.680675</td>\n",
       "      <td>3.544858</td>\n",
       "      <td>5.816493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.325134</td>\n",
       "      <td>5.189317</td>\n",
       "      <td>7.460952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.409876</td>\n",
       "      <td>2.274058</td>\n",
       "      <td>4.545693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.448433</td>\n",
       "      <td>3.312615</td>\n",
       "      <td>5.584250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      preds  lower_bounds  upper_bounds\n",
       "0  4.669552      3.533734      5.805369\n",
       "1  4.680675      3.544858      5.816493\n",
       "2  6.325134      5.189317      7.460952\n",
       "3  3.409876      2.274058      4.545693\n",
       "4  4.448433      3.312615      5.584250"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_happiness[['life_exp_sc', 'corrupt_sc', 'gdp_pc_sc']]\n",
    "y = df_happiness['happiness']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_happiness[['life_exp_sc', 'corrupt_sc', 'gdp_pc_sc']],\n",
    "    df_happiness['happiness'],\n",
    "    test_size = 0.5,\n",
    "    random_state = 1234\n",
    ")\n",
    "\n",
    "our_cp_error = split_conformal(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    alpha = .1\n",
    ")\n",
    "\n",
    "print(our_cp_error['cp_error'])\n",
    "\n",
    "pd.DataFrame({\n",
    "    'preds': our_cp_error['preds'],\n",
    "    'lower_bounds': our_cp_error['lower_bounds'],\n",
    "    'upper_bounds': our_cp_error['upper_bounds']\n",
    "}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.regression import MapieRegressor\n",
    "\n",
    "model = MapieRegressor(LinearRegression(), method = 'base', random_state=123)\n",
    "y_pred, y_pis = model.fit(X_train, y_train).predict(X_test, alpha = 0.1)\n",
    "\n",
    "# take the first difference between upper and lower bounds,\n",
    "# since it's constant for all predictions in this setting\n",
    "\n",
    "cp_error = (y_pis[0, 1, 0] - y_pis[0, 0, 0]) / 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.93113326, 6.15153942],\n",
       "       [3.93302836, 6.15343453],\n",
       "       [5.08887412, 7.30928028],\n",
       "       [2.7385576 , 4.95896377],\n",
       "       [3.73161544, 5.95202161]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pis[:5].reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1358174413022732, 1.1102030815534594)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_cp_error['cp_error'], cp_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-of-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
