{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heart = pd.read_csv('https://tinyurl.com/heartdiseaseprocessed')\n",
    "df_heart_num = pd.read_csv('https://tinyurl.com/heartdiseaseprocessednumeric')\n",
    "\n",
    "# convert appropriate features to categorical\n",
    "for col in df_heart.select_dtypes(include='object').columns:\n",
    "    df_heart[col] = df_heart[col].astype('category')\n",
    "\n",
    "X = df_heart_num.drop(columns=['heart_disease']).to_numpy()\n",
    "y = df_heart_num['heart_disease'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = np.mean(y)\n",
    "majority = np.max([prevalence, 1 - prevalence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Linear Models/Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elastic = LogisticRegression(\n",
    "    penalty='elasticnet',\n",
    "    solver='saga',\n",
    "    l1_ratio=0.5,\n",
    "    random_state=42,\n",
    "    max_iter=10000,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# use cross-validation to estimate performance\n",
    "cv_elastic = cross_validate(\n",
    "    model_elastic,\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.828 \n",
      "Guessing:  0.539\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Training accuracy: ',\n",
    "    np.round(cv_elastic['test_score'].mean(), 3),\n",
    "    '\\nGuessing: ',\n",
    "    np.round(majority, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_boost = LGBMClassifier(\n",
    "    n_estimators = 1000,\n",
    "    learning_rate = 1e-3,\n",
    "    max_depth = 5,\n",
    "    verbose = -1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model_boost_cv = cross_validate(\n",
    "    model_boost,\n",
    "    df_heart.drop(columns='heart_disease'),\n",
    "    df_heart['heart_disease'],\n",
    "    cv = 5,\n",
    "    scoring='accuracy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Training accuracy: ',\n",
    "    np.round(np.mean(model_boost_cv['test_score']), 3),\n",
    "    '\\nGuessing: ',\n",
    "    np.round(majority, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes = (200, 200, 200),  \n",
    "    learning_rate = 'adaptive',\n",
    "    learning_rate_init = 0.001,\n",
    "    shuffle = True,\n",
    "    random_state = 123,\n",
    "    warm_start = True,\n",
    "    nesterovs_momentum = True,\n",
    "    validation_fraction =  .2,\n",
    "    verbose = False,\n",
    ")\n",
    "\n",
    "# with the above settings, this will take a few seconds\n",
    "model_mlp_cv = cross_validate(\n",
    "    model_mlp, \n",
    "    X, \n",
    "    y, \n",
    "    cv = 5\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Training accuracy: ',\n",
    "    np.round(np.mean(model_mlp_cv['test_score']), 3),\n",
    "    '\\nGuessing: ',\n",
    "    np.round(majority, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Tuned Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_heart.drop(columns='heart_disease'), \n",
    "    df_heart_num['heart_disease'],\n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "model_boost = LGBMClassifier(\n",
    "    verbose = -1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    'learning_rate': [1e-3, 1e-2, 1e-1],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_child_samples': [1, 5, 10],\n",
    "}\n",
    "\n",
    "# this will take a few seconds\n",
    "model_boost_cv_tune = RandomizedSearchCV(\n",
    "    model_boost, \n",
    "    param_grid, \n",
    "    n_iter = 10,\n",
    "    cv = 5, \n",
    "    scoring = 'accuracy', \n",
    "    n_jobs = -1,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "model_boost_cv_tune.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = model_boost_cv_tune.predict(X_test)\n",
    "accuracy_score(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    tpr = recall_score(y_true, y_pred)  # True Positive Rate (Sensitivity)\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate (Specificity)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    ppv = precision_score(y_true, y_pred)  # Positive Predictive Value (Precision)\n",
    "    npv = tn / (tn + fn)  # Negative Predictive Value\n",
    "    return {\n",
    "        'acc': acc,\n",
    "        'tpr': tpr,\n",
    "        'tnr': tnr,\n",
    "        'f1': f1,\n",
    "        'ppv': ppv,\n",
    "        'npv': npv\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return calculate_metrics(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "model_glmnet = LogisticRegression(solver='saga', max_iter=10000, random_state=42)\n",
    "model_boost = LGBMClassifier(random_state=42)\n",
    "model_mlp = MLPClassifier(max_iter=10000, random_state=42)\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grid_glmnet = {\n",
    "    'penalty': ['elasticnet'],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "param_grid_boost = {\n",
    "    'n_estimators': [250, 500, 1000],\n",
    "    'learning_rate': [1e-3, 0.01, 0.1, 0.5],\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'min_child_samples': [1, 5, 10],\n",
    "    'colsample_bytree': [0.75, 1.0],\n",
    "    'reg_alpha': [0.0, 1],\n",
    "    'reg_lambda': [0.0, 1]\n",
    "}\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(100, 100), (200, 200), (100, 100, 100), (200, 200, 200)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search_glmnet = RandomizedSearchCV(model_glmnet, param_grid_glmnet, cv=10, scoring='accuracy')\n",
    "grid_search_boost = RandomizedSearchCV(model_boost, param_grid_boost, cv=10, scoring='accuracy')\n",
    "grid_search_mlp = RandomizedSearchCV(model_mlp, param_grid_mlp, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit the grid searches\n",
    "grid_search_glmnet.fit(X_train, y_train)\n",
    "grid_search_boost.fit(X_train, y_train)\n",
    "grid_search_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Get the best models\n",
    "best_glmnet = grid_search_glmnet.best_estimator_\n",
    "best_boost = grid_search_boost.best_estimator_\n",
    "best_mlp = grid_search_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best models on the test set\n",
    "results_glmnet = evaluate_model(best_glmnet, X_train, y_train, X_test, y_test)\n",
    "results_boost = evaluate_model(best_boost, X_train, y_train, X_test, y_test)\n",
    "results_mlp = evaluate_model(best_mlp, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Aggregate results into a DataFrame for comparison\n",
    "results_df = pd.DataFrame({\n",
    "    'GLMNet': results_glmnet,\n",
    "    'Boost': results_boost,\n",
    "    'MLP': results_mlp\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results_df.T.reset_index().rename(columns={'index': 'model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_csv('../ml/data/ml-common-py_model_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on the test set\n",
    "# y_pred_glmnet = best_glmnet.predict(X_test)\n",
    "# y_pred_boost = best_boost.predict(X_test)\n",
    "# y_pred_mlp = best_mlp.predict(X_test)\n",
    "\n",
    "# # Combine predictions with observed values into a DataFrame\n",
    "# df_predictions = pd.DataFrame({\n",
    "#     'Observed': y_test,\n",
    "#     'GLMNet_Predictions': y_pred_glmnet,\n",
    "#     'Boost_Predictions': y_pred_boost,\n",
    "#     'MLP_Predictions': y_pred_mlp\n",
    "# })\n",
    "\n",
    "# df_predictions.to_csv('../ml/data/ml-common-py_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_boost_cv_tune.best_estimator_\n",
    "best_model.feature_importances_\n",
    "\n",
    "# you remember which feature is which, right? if not, do this:\n",
    "pd.DataFrame({\n",
    "    'Feature': best_model.feature_name_,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(\n",
    "    model_boost_cv_tune, \n",
    "    df_heart.drop(columns='heart_disease'), \n",
    "    features=['cholesterol', 'male'], \n",
    "    categorical_features=['male'], \n",
    "    percentiles=(0, .9),\n",
    "    grid_resolution=75\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-of-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
